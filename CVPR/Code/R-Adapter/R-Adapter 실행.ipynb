{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da4a7b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a58c3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hbcho991/.conda/envs/R-Adapter/bin/python\n"
     ]
    }
   ],
   "source": [
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d7da8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd186c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a1a80f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.5\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaac3b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ln -s /home/dataset/imagenet1k/data ./datasets/data/ILSVRC2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "651cd39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cf1958c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/hbcho991/.conda/envs/R-Adapter/lib/python310.zip', '/home/hbcho991/.conda/envs/R-Adapter/lib/python3.10', '/home/hbcho991/.conda/envs/R-Adapter/lib/python3.10/lib-dynload', '', '/home/hbcho991/.conda/envs/R-Adapter/lib/python3.10/site-packages', '/home/hbcho991/.conda/envs/R-Adapter/lib/python3.10/site-packages/setuptools/_vendor']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39109c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0,'/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8327a4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd4c79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python datacreation_scripts/imagenet_csv_creator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf58796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3136caba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03ab504",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/modestyachts/ImageNetV2_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98428c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install open_clip_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf9def3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wilds braceexpand webdataset h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1fa675",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pycocotools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c664a1",
   "metadata": {},
   "source": [
    "## full-tuning 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27d8ae30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1029 20:13:21.077000 22986400442176 torch/distributed/run.py:779] \n",
      "W1029 20:13:21.077000 22986400442176 torch/distributed/run.py:779] *****************************************\n",
      "W1029 20:13:21.077000 22986400442176 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W1029 20:13:21.077000 22986400442176 torch/distributed/run.py:779] *****************************************\n",
      "WARNING:root:The WILDS package is out of date. Your version is 1.2.2, while the latest version is 2.0.0.\n",
      "WARNING:root:The WILDS package is out of date. Your version is 1.2.2, while the latest version is 2.0.0.\n",
      "WARNING:root:The WILDS package is out of date. Your version is 1.2.2, while the latest version is 2.0.0.\n",
      "WARNING:root:The WILDS package is out of date. Your version is 1.2.2, while the latest version is 2.0.0.\n",
      "/opt/anaconda3/2023.09-0/lib/python3.11/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/opt/anaconda3/2023.09-0/lib/python3.11/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/opt/anaconda3/2023.09-0/lib/python3.11/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/opt/anaconda3/2023.09-0/lib/python3.11/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "INFO:root:Running in distributed mode with multiple processes. Device: cuda:0.Process (global: 0, local 0), total 4.\n",
      "2024-10-29,20:13:24 | INFO | Running in distributed mode with multiple processes. Device: cuda:0.Process (global: 0, local 0), total 4.\n",
      "ViT-B/32\n",
      "INFO:root:Running in distributed mode with multiple processes. Device: cuda:3.Process (global: 3, local 3), total 4.\n",
      "2024-10-29,20:13:24 | INFO | Running in distributed mode with multiple processes. Device: cuda:3.Process (global: 3, local 3), total 4.\n",
      "ViT-B/32\n",
      "INFO:root:Running in distributed mode with multiple processes. Device: cuda:2.Process (global: 2, local 2), total 4.\n",
      "2024-10-29,20:13:24 | INFO | Running in distributed mode with multiple processes. Device: cuda:2.Process (global: 2, local 2), total 4.\n",
      "ViT-B/32\n",
      "INFO:root:Running in distributed mode with multiple processes. Device: cuda:1.Process (global: 1, local 1), total 4.\n",
      "2024-10-29,20:13:24 | INFO | Running in distributed mode with multiple processes. Device: cuda:1.Process (global: 1, local 1), total 4.\n",
      "ViT-B/32\n",
      "INFO:root:Namespace(data_location='./datasets/data/', eval_datasets=['ImageNet', 'ImageNetV2'], train_dataset='ImageNet', template='openai_imagenet_template', classnames='openai', alpha=[0.5], exp_name='ImageNet/R-Adapter_full_finetune', results_db=None, model='ViT-B/32', use_peft=True, lora=[-1, -1], adapter=[16, 16], drop_path=0.2, ema=0.999, bma=0, eval_scale=0.5, lock_image=False, lock_text=False, unlock_proj=False, unlock_ln=False, unlock_bias=False, unlock_cls=False, lock_classifier=False, batch_size=32, eval_batch_size=32, lr=0.0005, wd=0.0, ls=0.02, mg=0.05, warmup_length=500, num_classes=1000, epochs=10, eval_epoch=0, load=None, save='expt_logs/ViT-B/32/ImageNet/R-Adapter_full_finetune/_BS32_WD0.0_LR0.0005_run1', resume=None, freeze_encoder=False, cache_dir=None, fisher=None, fisher_floor=1e-08, ft_data='./datasets/csv/imagenet_classID.csv', ce_ablation=None, dataset_type='auto', train_num_samples=None, k=None, seed=0, workers=4, csv_separator='\\t', csv_img_key='filepath', csv_caption_key='title', supervised_label_key='class', precision='amp', horovod=False, gather_with_grad=False, dist_url='env://', dist_backend='nccl', grad_clip_norm=1.0, no_set_device_rank=False, clip_load=None, wise_ft=1, wise_save=None, run=1, get_labeled_csv=False, min_lr=1e-06, scheduler='cosine', device='cuda:0', distributed=True, world_size=4, rank=0, local_rank=0, log_level=20)\n",
      "2024-10-29,20:13:26 | INFO | Namespace(data_location='./datasets/data/', eval_datasets=['ImageNet', 'ImageNetV2'], train_dataset='ImageNet', template='openai_imagenet_template', classnames='openai', alpha=[0.5], exp_name='ImageNet/R-Adapter_full_finetune', results_db=None, model='ViT-B/32', use_peft=True, lora=[-1, -1], adapter=[16, 16], drop_path=0.2, ema=0.999, bma=0, eval_scale=0.5, lock_image=False, lock_text=False, unlock_proj=False, unlock_ln=False, unlock_bias=False, unlock_cls=False, lock_classifier=False, batch_size=32, eval_batch_size=32, lr=0.0005, wd=0.0, ls=0.02, mg=0.05, warmup_length=500, num_classes=1000, epochs=10, eval_epoch=0, load=None, save='expt_logs/ViT-B/32/ImageNet/R-Adapter_full_finetune/_BS32_WD0.0_LR0.0005_run1', resume=None, freeze_encoder=False, cache_dir=None, fisher=None, fisher_floor=1e-08, ft_data='./datasets/csv/imagenet_classID.csv', ce_ablation=None, dataset_type='auto', train_num_samples=None, k=None, seed=0, workers=4, csv_separator='\\t', csv_img_key='filepath', csv_caption_key='title', supervised_label_key='class', precision='amp', horovod=False, gather_with_grad=False, dist_url='env://', dist_backend='nccl', grad_clip_norm=1.0, no_set_device_rank=False, clip_load=None, wise_ft=1, wise_save=None, run=1, get_labeled_csv=False, min_lr=1e-06, scheduler='cosine', device='cuda:0', distributed=True, world_size=4, rank=0, local_rank=0, log_level=20)\n",
      "INFO:root:Fine-tuning Using R-Adapter\n",
      "2024-10-29,20:13:26 | INFO | Fine-tuning Using R-Adapter\n",
      "INFO:root:Training dataset ImageNet\n",
      "2024-10-29,20:13:26 | INFO | Training dataset ImageNet\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.0.adapter_attn.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.0.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.0.adapter_attn.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.0.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.0.adapter_attn.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.0.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.0.adapter_mlp.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.0.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.0.adapter_mlp.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.0.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.0.adapter_mlp.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.0.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.1.adapter_attn.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.1.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.1.adapter_attn.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.1.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.1.adapter_attn.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.1.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.1.adapter_mlp.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.1.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.1.adapter_mlp.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.1.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.1.adapter_mlp.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.1.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.2.adapter_attn.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.2.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.2.adapter_attn.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.2.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.2.adapter_attn.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.2.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.2.adapter_mlp.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.2.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.2.adapter_mlp.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.2.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.2.adapter_mlp.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.2.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.3.adapter_attn.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.3.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.3.adapter_attn.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.3.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.3.adapter_attn.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.3.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.3.adapter_mlp.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.3.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.3.adapter_mlp.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.3.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.3.adapter_mlp.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.3.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.4.adapter_attn.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.4.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.4.adapter_attn.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.4.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.4.adapter_attn.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.4.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.4.adapter_mlp.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.4.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.4.adapter_mlp.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.4.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.4.adapter_mlp.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.4.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.5.adapter_attn.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.5.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.5.adapter_attn.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.5.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.5.adapter_attn.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.5.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.5.adapter_mlp.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.5.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.5.adapter_mlp.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.5.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.5.adapter_mlp.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.5.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.6.adapter_attn.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.6.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.6.adapter_attn.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.6.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.6.adapter_attn.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.6.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.6.adapter_mlp.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.6.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.6.adapter_mlp.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.6.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.6.adapter_mlp.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.6.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.7.adapter_attn.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.7.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.7.adapter_attn.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.7.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.7.adapter_attn.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.7.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.7.adapter_mlp.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.7.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.7.adapter_mlp.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.7.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.7.adapter_mlp.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.7.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.8.adapter_attn.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.8.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.8.adapter_attn.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.8.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.8.adapter_attn.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.8.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.8.adapter_mlp.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.8.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.8.adapter_mlp.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.8.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.8.adapter_mlp.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.8.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.9.adapter_attn.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.9.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.9.adapter_attn.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.9.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.9.adapter_attn.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.9.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.9.adapter_mlp.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.9.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.9.adapter_mlp.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.9.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.9.adapter_mlp.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.9.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.10.adapter_attn.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.10.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.10.adapter_attn.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.10.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.10.adapter_attn.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.10.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.10.adapter_mlp.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.10.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.10.adapter_mlp.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.10.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.10.adapter_mlp.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.10.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.11.adapter_attn.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.11.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.11.adapter_attn.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.11.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.11.adapter_attn.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.11.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.11.adapter_mlp.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.11.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.11.adapter_mlp.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.11.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.11.adapter_mlp.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.visual.transformer.resblocks.11.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.0.adapter_attn.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.0.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.0.adapter_attn.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.0.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.0.adapter_attn.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.0.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.0.adapter_mlp.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.0.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.0.adapter_mlp.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.0.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.0.adapter_mlp.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.0.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.1.adapter_attn.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.1.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.1.adapter_attn.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.1.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.1.adapter_attn.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.1.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.1.adapter_mlp.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.1.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.1.adapter_mlp.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.1.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.1.adapter_mlp.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.1.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.2.adapter_attn.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.2.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.2.adapter_attn.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.2.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.2.adapter_attn.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.2.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.2.adapter_mlp.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.2.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.2.adapter_mlp.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.2.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.2.adapter_mlp.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.2.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.3.adapter_attn.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.3.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.3.adapter_attn.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.3.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.3.adapter_attn.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.3.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.3.adapter_mlp.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.3.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.3.adapter_mlp.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.3.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.3.adapter_mlp.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.3.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.4.adapter_attn.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.4.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.4.adapter_attn.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.4.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.4.adapter_attn.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.4.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.4.adapter_mlp.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.4.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.4.adapter_mlp.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.4.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.4.adapter_mlp.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.4.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.5.adapter_attn.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.5.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.5.adapter_attn.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.5.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.5.adapter_attn.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.5.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.5.adapter_mlp.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.5.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.5.adapter_mlp.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.5.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.5.adapter_mlp.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.5.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.6.adapter_attn.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.6.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.6.adapter_attn.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.6.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.6.adapter_attn.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.6.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.6.adapter_mlp.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.6.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.6.adapter_mlp.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.6.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.6.adapter_mlp.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.6.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.7.adapter_attn.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.7.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.7.adapter_attn.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.7.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.7.adapter_attn.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.7.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.7.adapter_mlp.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.7.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.7.adapter_mlp.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.7.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.7.adapter_mlp.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.7.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.8.adapter_attn.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.8.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.8.adapter_attn.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.8.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.8.adapter_attn.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.8.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.8.adapter_mlp.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.8.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.8.adapter_mlp.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.8.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.8.adapter_mlp.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.8.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.9.adapter_attn.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.9.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.9.adapter_attn.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.9.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.9.adapter_attn.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.9.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.9.adapter_mlp.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.9.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.9.adapter_mlp.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.9.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.9.adapter_mlp.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.9.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.10.adapter_attn.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.10.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.10.adapter_attn.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.10.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.10.adapter_attn.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.10.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.10.adapter_mlp.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.10.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.10.adapter_mlp.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.10.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.10.adapter_mlp.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.10.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.11.adapter_attn.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.11.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.11.adapter_attn.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.11.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.11.adapter_attn.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.11.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.11.adapter_mlp.s\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.11.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.11.adapter_mlp.d.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.11.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.11.adapter_mlp.u.weight\n",
      "2024-10-29,20:14:37 | INFO | Train: module.model.transformer.resblocks.11.adapter_mlp.u.weight\n",
      "INFO:root:Num_params: 0.98M\n",
      "2024-10-29,20:14:37 | INFO | Num_params: 0.98M\n",
      "/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py:138: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler() if args.precision == \"amp\" else None\n",
      "INFO:root:Start epoch 0\n",
      "2024-10-29,20:14:37 | INFO | Start epoch 0\n",
      "/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py:138: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler() if args.precision == \"amp\" else None\n",
      "/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py:138: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler() if args.precision == \"amp\" else None\n",
      "/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py:138: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler() if args.precision == \"amp\" else None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py:288: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py:288: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py:288: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py:288: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "[rank0]:I1029 20:14:47.637000 22580217919296 torch/nn/parallel/distributed.py:1524] Reducer buckets have been rebuilt in this iteration.\n",
      "[rank1]:I1029 20:14:47.642000 22669243107136 torch/nn/parallel/distributed.py:1524] Reducer buckets have been rebuilt in this iteration.\n",
      "[rank2]:I1029 20:14:47.648000 22690344634176 torch/nn/parallel/distributed.py:1524] Reducer buckets have been rebuilt in this iteration.\n",
      "[rank3]:I1029 20:14:47.648000 22618968729408 torch/nn/parallel/distributed.py:1524] Reducer buckets have been rebuilt in this iteration.\n",
      "INFO:root:Train Epoch: 0 [     32/1281167 (0%)] Data (t): 0.000 Batch (t): 0.068, 117.304/s LR: 0.000002 Logit Scale: 100.000 Loss: 2.3050 (2.3050)\n",
      "2024-10-29,20:14:47 | INFO | Train Epoch: 0 [     32/1281167 (0%)] Data (t): 0.000 Batch (t): 0.068, 117.304/s LR: 0.000002 Logit Scale: 100.000 Loss: 2.3050 (2.3050)\n",
      "100%|███████████████████████████████████████| 1000/1000 [00:18<00:00, 53.68it/s]\n",
      "Evaluating on ImageNet\n",
      "/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/models/eval.py:65: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "INFO:root:ImageNet Top-1 accuracy: 0.6377\n",
      "2024-10-29,20:17:27 | INFO | ImageNet Top-1 accuracy: 0.6377\n",
      "Evaluating on ImageNetV2\n",
      "Dataset matched-frequency not found on disk, downloading....\n",
      "100%|█████████████████████████████████████| 1.26G/1.26G [00:29<00:00, 42.2MiB/s]\n",
      "Extracting....\n",
      "INFO:root:ImageNetV2 Top-1 accuracy: 0.5626\n",
      "2024-10-29,20:18:34 | INFO | ImageNetV2 Top-1 accuracy: 0.5626\n",
      "INFO:root:Saving model toexpt_logs/ViT-B/32/ImageNet/R-Adapter_full_finetune/_BS32_WD0.0_LR0.0005_run1/checkpoint_1.pt\n",
      "2024-10-29,20:18:34 | INFO | Saving model toexpt_logs/ViT-B/32/ImageNet/R-Adapter_full_finetune/_BS32_WD0.0_LR0.0005_run1/checkpoint_1.pt\n",
      "INFO:root:Avg OOD Acc : 0.5626\n",
      "2024-10-29,20:18:37 | INFO | Avg OOD Acc : 0.5626\n",
      "INFO:root:Start epoch 1\n",
      "2024-10-29,20:18:37 | INFO | Start epoch 1\n",
      "INFO:root:Train Epoch: 1 [     32/1281167 (0%)] Data (t): 0.000 Batch (t): 0.074, 108.816/s LR: 0.000402 Logit Scale: 100.000 Loss: 1.3668 (1.3668)\n",
      "2024-10-29,20:18:44 | INFO | Train Epoch: 1 [     32/1281167 (0%)] Data (t): 0.000 Batch (t): 0.074, 108.816/s LR: 0.000402 Logit Scale: 100.000 Loss: 1.3668 (1.3668)\n",
      "^C\n",
      "W1029 20:18:52.582000 22986400442176 torch/distributed/elastic/agent/server/api.py:688] Received 2 death signal, shutting down workers\n",
      "W1029 20:18:52.582000 22986400442176 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 2219297 closing signal SIGINT\n",
      "W1029 20:18:52.582000 22986400442176 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 2219298 closing signal SIGINT\n",
      "W1029 20:18:52.582000 22986400442176 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 2219299 closing signal SIGINT\n",
      "W1029 20:18:52.582000 22986400442176 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 2219300 closing signal SIGINT\n",
      "[rank1]: Traceback (most recent call last):\n",
      "[rank1]:   File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "[rank1]:   File \"<frozen runpy>\", line 88, in _run_code\n",
      "[rank1]:   File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py\", line 363, in <module>\n",
      "[rank1]:     main(args)\n",
      "[rank1]:   File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py\", line 193, in main\n",
      "[rank1]:     train_one_epoch(model, dataset, ft_dataloader, clip_loss_fn, epoch, optimizer, scaler, scheduler, args)\n",
      "[rank1]:   File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py\", line 288, in train_one_epoch\n",
      "[rank1]:     with autocast():\n",
      "[rank1]:   File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/cuda/amp/autocast_mode.py\", line 43, in __exit__\n",
      "[rank1]:     def __exit__(self, exc_type: Any, exc_val: Any, exc_tb: Any):  # type: ignore[override]\n",
      "\n",
      "[rank1]: KeyboardInterrupt\n",
      "[rank2]: Traceback (most recent call last):\n",
      "[rank2]:   File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "[rank2]:   File \"<frozen runpy>\", line 88, in _run_code\n",
      "[rank2]:   File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py\", line 363, in <module>\n",
      "[rank2]:     main(args)\n",
      "[rank2]:   File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py\", line 193, in main\n",
      "[rank2]:     train_one_epoch(model, dataset, ft_dataloader, clip_loss_fn, epoch, optimizer, scaler, scheduler, args)\n",
      "[rank2]:   File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py\", line 292, in train_one_epoch\n",
      "[rank2]:     ft_clip_loss = loss(ft_image_features, ft_text_features, logit_scale, ground_labels=ft_label, label_smoothing=using_label)\n",
      "[rank2]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank2]:   File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "[rank2]:     return self._call_impl(*args, **kwargs)\n",
      "[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank2]:   File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "[rank2]:     return forward_call(*args, **kwargs)\n",
      "[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank2]:   File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/clip2/loss.py\", line 147, in forward\n",
      "[rank2]:     all_text_features = all_gather_with_grad(text_features)\n",
      "[rank2]:                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank2]:   File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/clip2/loss.py\", line 101, in all_gather_with_grad\n",
      "[rank2]:     tensor_all = GatherLayer.apply(tensors)\n",
      "[rank2]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank2]:   File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/autograd/function.py\", line 574, in apply\n",
      "[rank2]:     return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
      "[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank2]:   File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/clip2/loss.py\", line 79, in forward\n",
      "[rank2]:     output = [\n",
      "[rank2]:              ^\n",
      "[rank2]:   File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/clip2/loss.py\", line 80, in <listcomp>\n",
      "[rank2]:     torch.zeros_like(x) for _ in range(torch.distributed.get_world_size())\n",
      "[rank2]:     ^^^^^^^^^^^^^^^^^^^\n",
      "[rank2]: KeyboardInterrupt\n",
      "[rank1]:I1029 20:18:52.588000 22669243107136 torch/_dynamo/utils.py:335] TorchDynamo compilation metrics:\n",
      "[rank1]:I1029 20:18:52.588000 22669243107136 torch/_dynamo/utils.py:335] Function    Runtimes (s)\n",
      "[rank1]:I1029 20:18:52.588000 22669243107136 torch/_dynamo/utils.py:335] ----------  --------------\n",
      "[rank0]: Traceback (most recent call last):\n",
      "[rank0]:   File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "[rank0]:   File \"<frozen runpy>\", line 88, in _run_code\n",
      "[rank0]:   File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py\", line 363, in <module>\n",
      "[rank0]:     main(args)\n",
      "[rank0]:   File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py\", line 193, in main\n",
      "[rank0]:     train_one_epoch(model, dataset, ft_dataloader, clip_loss_fn, epoch, optimizer, scaler, scheduler, args)\n",
      "[rank0]:   File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py\", line 289, in train_one_epoch\n",
      "[rank0]:     ft_image_features, ft_text_features, logit_scale = model(ft_image, ft_text, steps=[step, num_batches * 10])\n",
      "[rank0]:                                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/nn/parallel/distributed.py\", line 1636, in forward\n",
      "[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)\n",
      "[rank0]:          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/nn/parallel/distributed.py\", line 1454, in _run_ddp_forward\n",
      "[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/models/modeling.py\", line 56, in forward\n",
      "[rank0]:     return self.model(images, text, steps=steps)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/clip2/model.py\", line 485, in forward\n",
      "[rank0]:     text_features = self.encode_text(text)\n",
      "[rank0]:                     ^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/clip2/model.py\", line 418, in encode_text\n",
      "[rank0]:     x = self.transformer(x)\n",
      "[rank0]:         ^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/clip2/model.py\", line 248, in forward\n",
      "[rank0]:     x = blk(x)\n",
      "[rank0]:         ^^^^^^\n",
      "[rank0]:   File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/clip2/loralib/utils.py\", line 53, in forward_vit_block_adapter\n",
      "[rank0]:     x = x + adapter_mlp(self.mlp(self.ln_2(x)))\n",
      "[rank0]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]: KeyboardInterrupt\n",
      "[rank2]:I1029 20:18:52.593000 22690344634176 torch/_dynamo/utils.py:335] TorchDynamo compilation metrics:\n",
      "[rank2]:I1029 20:18:52.593000 22690344634176 torch/_dynamo/utils.py:335] Function    Runtimes (s)\n",
      "[rank2]:I1029 20:18:52.593000 22690344634176 torch/_dynamo/utils.py:335] ----------  --------------\n",
      "[rank0]:I1029 20:18:52.597000 22580217919296 torch/_dynamo/utils.py:335] TorchDynamo compilation metrics:\n",
      "[rank0]:I1029 20:18:52.597000 22580217919296 torch/_dynamo/utils.py:335] Function    Runtimes (s)\n",
      "[rank0]:I1029 20:18:52.597000 22580217919296 torch/_dynamo/utils.py:335] ----------  --------------\n"
     ]
    }
   ],
   "source": [
    "!torchrun --master_port 29400 --nproc_per_node 4 -m src.main     --train-dataset=ImageNet     --epochs=10     --lr=5e-4     --wd=0     --workers=4     --batch-size=32     --model=ViT-B/32     --eval-datasets=ImageNet,ImageNetV2     --template=openai_imagenet_template     --save=./checkpoints/     --data-location=./datasets/data/     --ft_data=./datasets/csv/imagenet_classID.csv     --adapter=16,16     --drop-path=0.2     --ema=0.999     --eval-scale=0.5     --grad-clip-norm=1     --ls=0.02     --mg=0.05     --eval_epoch=0     --csv-img-key=filepath     --csv-caption-key=title     --supervised-label-key=class     --exp_name=ImageNet/R-Adapter_full_finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fdb0270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct 29 19:57:18 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 4090        Off | 00000000:17:00.0 Off |                  Off |\r\n",
      "| 33%   25C    P8              17W / 450W |      5MiB / 24564MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA GeForce RTX 4090        Off | 00000000:3D:00.0 Off |                  Off |\r\n",
      "| 72%   64C    P2             370W / 450W |  14821MiB / 24564MiB |     99%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   2  NVIDIA GeForce RTX 4090        Off | 00000000:50:00.0 Off |                  Off |\r\n",
      "| 71%   62C    P2             344W / 450W |  13645MiB / 24564MiB |     99%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   3  NVIDIA GeForce RTX 4090        Off | 00000000:63:00.0 Off |                  Off |\r\n",
      "| 32%   23C    P8              13W / 450W |      9MiB / 24564MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   4  NVIDIA GeForce RTX 4090        Off | 00000000:99:00.0 Off |                  Off |\r\n",
      "| 33%   24C    P8              18W / 450W |      7MiB / 24564MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   5  NVIDIA GeForce RTX 4090        Off | 00000000:BD:00.0 Off |                  Off |\r\n",
      "| 36%   47C    P2             185W / 450W |  22317MiB / 24564MiB |     39%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   6  NVIDIA GeForce RTX 4090        Off | 00000000:CF:00.0 Off |                  Off |\r\n",
      "| 32%   29C    P8              22W / 450W |  23361MiB / 24564MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   7  NVIDIA GeForce RTX 4090        Off | 00000000:E1:00.0 Off |                  Off |\r\n",
      "| 33%   30C    P2             120W / 450W |  23361MiB / 24564MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    1   N/A  N/A   1903912      C   python                                    14810MiB |\r\n",
      "|    2   N/A  N/A   1998383      C   python                                    13634MiB |\r\n",
      "|    5   N/A  N/A   2697206      C   ...onda/envs/incontext-diff/bin/python    22196MiB |\r\n",
      "|    6   N/A  N/A   2109415      C   python                                    23352MiB |\r\n",
      "|    7   N/A  N/A   2110830      C   python                                    23352MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f124e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5314c1dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8489da5d",
   "metadata": {},
   "source": [
    "## GMoE 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd0ac621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping tutel as it is not installed.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python3 -m pip uninstall tutel -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ed0555e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/microsoft/tutel@main\n",
      "  Cloning https://github.com/microsoft/tutel (to revision main) to /tmp/pip-req-build-r6u236_y\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/microsoft/tutel /tmp/pip-req-build-r6u236_y\n",
      "  Resolved https://github.com/microsoft/tutel to commit fc34436c54d98a5ed2422621a7f0a8e0a02458e5\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/hbcho991/.local/lib/python3.11/site-packages (from tutel==0.3) (1.26.4)\n",
      "Building wheels for collected packages: tutel\n",
      "  Building wheel for tutel (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tutel: filename=tutel-0.3-cp311-cp311-linux_x86_64.whl size=165147 sha256=a6ba8774efd29407fa460d894bafe389bc50b74e133cddb20a68e5e8ad3eee19\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-qcy736k7/wheels/39/41/87/a4f8853e23b074eafab1071b7fb2ba0ff2df1aa024294986f4\n",
      "Successfully built tutel\n",
      "Installing collected packages: tutel\n",
      "Successfully installed tutel-0.3\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --user --upgrade git+https://github.com/microsoft/tutel@main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03b9ed40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1029 21:31:52.700000 22626981287744 torch/distributed/run.py:779] \n",
      "W1029 21:31:52.700000 22626981287744 torch/distributed/run.py:779] *****************************************\n",
      "W1029 21:31:52.700000 22626981287744 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W1029 21:31:52.700000 22626981287744 torch/distributed/run.py:779] *****************************************\n",
      "WARNING:root:The WILDS package is out of date. Your version is 1.2.2, while the latest version is 2.0.0.\n",
      "WARNING:root:The WILDS package is out of date. Your version is 1.2.2, while the latest version is 2.0.0.\n",
      "WARNING:root:The WILDS package is out of date. Your version is 1.2.2, while the latest version is 2.0.0.\n",
      "WARNING:root:The WILDS package is out of date. Your version is 1.2.2, while the latest version is 2.0.0.\n",
      "/opt/anaconda3/2023.09-0/lib/python3.11/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/opt/anaconda3/2023.09-0/lib/python3.11/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/opt/anaconda3/2023.09-0/lib/python3.11/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/opt/anaconda3/2023.09-0/lib/python3.11/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py\", line 15, in <module>\n",
      "    from src.models.ce_ablation import ce_ablation\n",
      "  File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/models/ce_ablation.py\", line 22, in <module>\n",
      "    from src.models.modeling import ClassificationHead, CLIPEncoder, ImageClassifier\n",
      "  File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/models/modeling.py\", line 6, in <module>\n",
      "    import clip2.clip as clip\n",
      "  File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/clip2/clip.py\", line 15, in <module>\n",
      "    from clip2.model import build_model, convert_weights\n",
      "  File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/clip2/model.py\", line 27, in <module>\n",
      "    from tutel import moe as tutel_moe\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/tutel/moe.py\", line 6, in <module>\n",
      "    from .jit_kernels.gating import fast_cumsum_sub_one\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/tutel/jit_kernels/gating.py\", line 7, in <module>\n",
      "    from ..impls.jit_compiler import tutel_custom_kernel\n",
      "ImportError: cannot import name 'tutel_custom_kernel' from 'tutel.impls.jit_compiler' (/home/hbcho991/.local/lib/python3.11/site-packages/tutel/impls/jit_compiler.py)\n",
      "WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py\", line 15, in <module>\n",
      "    from src.models.ce_ablation import ce_ablation\n",
      "  File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/models/ce_ablation.py\", line 22, in <module>\n",
      "    from src.models.modeling import ClassificationHead, CLIPEncoder, ImageClassifier\n",
      "  File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/models/modeling.py\", line 6, in <module>\n",
      "    import clip2.clip as clip\n",
      "  File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/clip2/clip.py\", line 15, in <module>\n",
      "    from clip2.model import build_model, convert_weights\n",
      "  File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/clip2/model.py\", line 27, in <module>\n",
      "    from tutel import moe as tutel_moe\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/tutel/moe.py\", line 6, in <module>\n",
      "    from .jit_kernels.gating import fast_cumsum_sub_one\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/tutel/jit_kernels/gating.py\", line 7, in <module>\n",
      "    from ..impls.jit_compiler import tutel_custom_kernel\n",
      "ImportError: cannot import name 'tutel_custom_kernel' from 'tutel.impls.jit_compiler' (/home/hbcho991/.local/lib/python3.11/site-packages/tutel/impls/jit_compiler.py)\n",
      "WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py\", line 15, in <module>\n",
      "    from src.models.ce_ablation import ce_ablation\n",
      "  File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/models/ce_ablation.py\", line 22, in <module>\n",
      "    from src.models.modeling import ClassificationHead, CLIPEncoder, ImageClassifier\n",
      "  File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/models/modeling.py\", line 6, in <module>\n",
      "    import clip2.clip as clip\n",
      "  File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/clip2/clip.py\", line 15, in <module>\n",
      "    from clip2.model import build_model, convert_weights\n",
      "  File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/clip2/model.py\", line 27, in <module>\n",
      "    from tutel import moe as tutel_moe\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/tutel/moe.py\", line 6, in <module>\n",
      "    from .jit_kernels.gating import fast_cumsum_sub_one\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/tutel/jit_kernels/gating.py\", line 7, in <module>\n",
      "    from ..impls.jit_compiler import tutel_custom_kernel\n",
      "ImportError: cannot import name 'tutel_custom_kernel' from 'tutel.impls.jit_compiler' (/home/hbcho991/.local/lib/python3.11/site-packages/tutel/impls/jit_compiler.py)\n",
      "WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py\", line 15, in <module>\n",
      "    from src.models.ce_ablation import ce_ablation\n",
      "  File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/models/ce_ablation.py\", line 22, in <module>\n",
      "    from src.models.modeling import ClassificationHead, CLIPEncoder, ImageClassifier\n",
      "  File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/models/modeling.py\", line 6, in <module>\n",
      "    import clip2.clip as clip\n",
      "  File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/clip2/clip.py\", line 15, in <module>\n",
      "    from clip2.model import build_model, convert_weights\n",
      "  File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/clip2/model.py\", line 27, in <module>\n",
      "    from tutel import moe as tutel_moe\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/tutel/moe.py\", line 6, in <module>\n",
      "    from .jit_kernels.gating import fast_cumsum_sub_one\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/tutel/jit_kernels/gating.py\", line 7, in <module>\n",
      "    from ..impls.jit_compiler import tutel_custom_kernel\n",
      "ImportError: cannot import name 'tutel_custom_kernel' from 'tutel.impls.jit_compiler' (/home/hbcho991/.local/lib/python3.11/site-packages/tutel/impls/jit_compiler.py)\n",
      "W1029 21:31:56.714000 22626981287744 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 2280790 closing signal SIGTERM\n",
      "W1029 21:31:56.714000 22626981287744 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 2280791 closing signal SIGTERM\n",
      "W1029 21:31:56.715000 22626981287744 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 2280792 closing signal SIGTERM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1029 21:31:56.788000 22626981287744 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 3 (pid: 2280793) of binary: /opt/anaconda3/2023.09-0/bin/python\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/hbcho991/.local/bin/torchrun\", line 8, in <module>\r\n",
      "    sys.exit(main())\r\n",
      "             ^^^^^^\r\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 348, in wrapper\r\n",
      "    return f(*args, **kwargs)\r\n",
      "           ^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/distributed/run.py\", line 901, in main\r\n",
      "    run(args)\r\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/distributed/run.py\", line 892, in run\r\n",
      "    elastic_launch(\r\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/distributed/launcher/api.py\", line 133, in __call__\r\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/distributed/launcher/api.py\", line 264, in launch_agent\r\n",
      "    raise ChildFailedError(\r\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \r\n",
      "============================================================\r\n",
      "src.main FAILED\r\n",
      "------------------------------------------------------------\r\n",
      "Failures:\r\n",
      "  <NO_OTHER_FAILURES>\r\n",
      "------------------------------------------------------------\r\n",
      "Root Cause (first observed failure):\r\n",
      "[0]:\r\n",
      "  time      : 2024-10-29_21:31:56\r\n",
      "  host      : UTL1\r\n",
      "  rank      : 3 (local_rank: 3)\r\n",
      "  exitcode  : 1 (pid: 2280793)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "============================================================\r\n"
     ]
    }
   ],
   "source": [
    "!torchrun --master_port 29400 --nproc_per_node 4 -m src.main     --train-dataset=ImageNet     --epochs=10     --lr=5e-4     --wd=0     --workers=4     --batch-size=32     --model=ViT-B/32     --eval-datasets=ImageNet,ImageNetV2     --template=openai_imagenet_template     --save=./checkpoints/     --data-location=./datasets/data/     --ft_data=./datasets/csv/imagenet_classID.csv     --adapter=16,16     --drop-path=0.2     --ema=0.999     --eval-scale=0.5     --grad-clip-norm=1     --ls=0.02     --mg=0.05     --eval_epoch=0     --csv-img-key=filepath     --csv-caption-key=title     --supervised-label-key=class     --exp_name=ImageNet/R-Adapter_full_finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ddff527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot import JIT optimized kernels. CUDA extension will be disabled.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'tutel_custom_kernel' from 'tutel.impls.jit_compiler' (/home/hbcho991/.local/lib/python3.10/site-packages/tutel/impls/jit_compiler.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtutel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m moe \u001b[38;5;28;01mas\u001b[39;00m tutel_moe\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tutel/moe.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Microsoft Corporation.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Licensed under the MIT license.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Low-level Ops\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjit_kernels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgating\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fast_cumsum_sub_one\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpls\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfast_dispatch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fast_dispatcher, extract_critical, fast_encode, fast_decode\n\u001b[1;32m      9\u001b[0m top_k_routing \u001b[38;5;241m=\u001b[39m extract_critical\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tutel/jit_kernels/gating.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpls\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjit_compiler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tutel_custom_kernel\n\u001b[1;32m      9\u001b[0m torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mload_library(tutel_custom_kernel\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__file__\u001b[39m)\n\u001b[1;32m     11\u001b[0m use_fast_cumsum \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mint\u001b[39m(os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFAST_CUMSUM\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'tutel_custom_kernel' from 'tutel.impls.jit_compiler' (/home/hbcho991/.local/lib/python3.10/site-packages/tutel/impls/jit_compiler.py)"
     ]
    }
   ],
   "source": [
    "from tutel import moe as tutel_moe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9684a6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14533cfd",
   "metadata": {},
   "source": [
    "## few-shot 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2022cbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!torchrun --master_port 29400 --nproc_per_node 4 -m src.few_shot     --train-dataset=ImageNet     --epochs=50     --lr=5e-4     --wd=0     --workers=4     --batch-size=32     --model=ViT-B/16     --eval-datasets=ImageNet,ImageNetV2,ImageNetR,ImageNetSketch,ImageNetA     --template=openai_imagenet_template     --save=./checkpoints/     --data-location=./datasets/data/     --ft_data=./datasets/csv/imagenet_classID.csv     --adapter=4,4     --drop-path=0.2     --ema=0.999     --eval-scale=0.5     --grad-clip-norm=1     --ls=0.02     --mg=0.05     --csv-img-key=filepath     --csv-caption-key=title     --supervised-label-key=class     --warmup_length=0     --k=16     --exp_name=ImageNet/R-Adapter_few_shot_16shot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dd0975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94621aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4422725b",
   "metadata": {},
   "source": [
    "## base-to-novel 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7d33a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ln -s /home/dataset/flowers ./datasets/data/flowers102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127efd64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ce8552",
   "metadata": {},
   "outputs": [],
   "source": [
    "!torchrun --master_port 29400 --nproc_per_node 4 -m src.main_few_shot_novel         --train-dataset=flowers102        --epochs=101         --lr=5e-4         --wd=0         --workers=4         --batch-size=32         --model=ViT-B/16         --template=openai_imagenet_template         --save=./checkpoints/         --data-location=./datasets/data/         --adapter=4,4         --drop-path=0.2         --ema=0.9         --eval-scale=0.5         --grad-clip-norm=1         --ls=0         --mg=0.1         --csv-img-key=filepath         --csv-caption-key=title         --supervised-label-key=class         --warmup_length=500         --k=16         --save=False         --exp_name=${dataset}/R-Adapter_few_shot_16shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f92b40b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00b6ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed272ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86129bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a5b211",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R-Adapter",
   "language": "python",
   "name": "r-adapter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
