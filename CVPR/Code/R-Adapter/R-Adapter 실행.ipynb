{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da4a7b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a58c3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hbcho991/.conda/envs/R-Adapter/bin/python\n"
     ]
    }
   ],
   "source": [
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d7da8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd186c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a1a80f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.5\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaac3b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ln -s /home/dataset/imagenet1k/data ./datasets/data/ILSVRC2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "651cd39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cf1958c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/hbcho991/.conda/envs/R-Adapter/lib/python310.zip', '/home/hbcho991/.conda/envs/R-Adapter/lib/python3.10', '/home/hbcho991/.conda/envs/R-Adapter/lib/python3.10/lib-dynload', '', '/home/hbcho991/.conda/envs/R-Adapter/lib/python3.10/site-packages', '/home/hbcho991/.conda/envs/R-Adapter/lib/python3.10/site-packages/setuptools/_vendor']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39109c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0,'/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8327a4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd4c79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python datacreation_scripts/imagenet_csv_creator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf58796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3136caba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03ab504",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/modestyachts/ImageNetV2_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98428c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install open_clip_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf9def3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wilds braceexpand webdataset h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1fa675",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pycocotools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c664a1",
   "metadata": {},
   "source": [
    "## full-tuning 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89396870",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27d8ae30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1027 20:43:24.216000 23068408969024 torch/distributed/run.py:779] \n",
      "W1027 20:43:24.216000 23068408969024 torch/distributed/run.py:779] *****************************************\n",
      "W1027 20:43:24.216000 23068408969024 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W1027 20:43:24.216000 23068408969024 torch/distributed/run.py:779] *****************************************\n",
      "WARNING:root:The WILDS package is out of date. Your version is 1.2.2, while the latest version is 2.0.0.\n",
      "WARNING:root:The WILDS package is out of date. Your version is 1.2.2, while the latest version is 2.0.0.\n",
      "WARNING:root:The WILDS package is out of date. Your version is 1.2.2, while the latest version is 2.0.0.\n",
      "WARNING:root:The WILDS package is out of date. Your version is 1.2.2, while the latest version is 2.0.0.\n",
      "/opt/anaconda3/2023.09-0/lib/python3.11/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/opt/anaconda3/2023.09-0/lib/python3.11/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/opt/anaconda3/2023.09-0/lib/python3.11/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/opt/anaconda3/2023.09-0/lib/python3.11/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "INFO:root:Running in distributed mode with multiple processes. Device: cuda:1.Process (global: 1, local 1), total 4.\n",
      "2024-10-27,20:43:27 | INFO | Running in distributed mode with multiple processes. Device: cuda:1.Process (global: 1, local 1), total 4.\n",
      "ViT-B/16\n",
      "INFO:root:Running in distributed mode with multiple processes. Device: cuda:3.Process (global: 3, local 3), total 4.\n",
      "2024-10-27,20:43:27 | INFO | Running in distributed mode with multiple processes. Device: cuda:3.Process (global: 3, local 3), total 4.\n",
      "ViT-B/16\n",
      "INFO:root:Running in distributed mode with multiple processes. Device: cuda:0.Process (global: 0, local 0), total 4.\n",
      "2024-10-27,20:43:27 | INFO | Running in distributed mode with multiple processes. Device: cuda:0.Process (global: 0, local 0), total 4.\n",
      "ViT-B/16\n",
      "INFO:root:Running in distributed mode with multiple processes. Device: cuda:2.Process (global: 2, local 2), total 4.\n",
      "2024-10-27,20:43:27 | INFO | Running in distributed mode with multiple processes. Device: cuda:2.Process (global: 2, local 2), total 4.\n",
      "ViT-B/16\n",
      "INFO:root:Namespace(data_location='./datasets/data/', eval_datasets=['ImageNet', 'ImageNetV2'], train_dataset='ImageNet', template='openai_imagenet_template', classnames='openai', alpha=[0.5], exp_name='ImageNet/R-Adapter_full_finetune', results_db=None, model='ViT-B/16', use_peft=True, lora=[-1, -1], adapter=[128, 128], drop_path=0.2, ema=0.999, bma=0, eval_scale=0.5, lock_image=False, lock_text=False, unlock_proj=False, unlock_ln=False, unlock_bias=False, unlock_cls=False, lock_classifier=False, batch_size=32, eval_batch_size=32, lr=0.0005, wd=0.0, ls=0.02, mg=0.05, warmup_length=500, num_classes=1000, epochs=10, eval_epoch=0, load=None, save='expt_logs/ViT-B/16/ImageNet/R-Adapter_full_finetune/_BS32_WD0.0_LR0.0005_run1', resume=None, freeze_encoder=False, cache_dir=None, fisher=None, fisher_floor=1e-08, ft_data='./datasets/csv/imagenet_classID.csv', ce_ablation=None, dataset_type='auto', train_num_samples=None, k=None, seed=0, workers=4, csv_separator='\\t', csv_img_key='filepath', csv_caption_key='title', supervised_label_key='class', precision='amp', horovod=False, gather_with_grad=False, dist_url='env://', dist_backend='nccl', grad_clip_norm=1.0, no_set_device_rank=False, clip_load=None, wise_ft=1, wise_save=None, run=1, get_labeled_csv=False, min_lr=1e-06, scheduler='cosine', device='cuda:0', distributed=True, world_size=4, rank=0, local_rank=0, log_level=20)\n",
      "2024-10-27,20:43:30 | INFO | Namespace(data_location='./datasets/data/', eval_datasets=['ImageNet', 'ImageNetV2'], train_dataset='ImageNet', template='openai_imagenet_template', classnames='openai', alpha=[0.5], exp_name='ImageNet/R-Adapter_full_finetune', results_db=None, model='ViT-B/16', use_peft=True, lora=[-1, -1], adapter=[128, 128], drop_path=0.2, ema=0.999, bma=0, eval_scale=0.5, lock_image=False, lock_text=False, unlock_proj=False, unlock_ln=False, unlock_bias=False, unlock_cls=False, lock_classifier=False, batch_size=32, eval_batch_size=32, lr=0.0005, wd=0.0, ls=0.02, mg=0.05, warmup_length=500, num_classes=1000, epochs=10, eval_epoch=0, load=None, save='expt_logs/ViT-B/16/ImageNet/R-Adapter_full_finetune/_BS32_WD0.0_LR0.0005_run1', resume=None, freeze_encoder=False, cache_dir=None, fisher=None, fisher_floor=1e-08, ft_data='./datasets/csv/imagenet_classID.csv', ce_ablation=None, dataset_type='auto', train_num_samples=None, k=None, seed=0, workers=4, csv_separator='\\t', csv_img_key='filepath', csv_caption_key='title', supervised_label_key='class', precision='amp', horovod=False, gather_with_grad=False, dist_url='env://', dist_backend='nccl', grad_clip_norm=1.0, no_set_device_rank=False, clip_load=None, wise_ft=1, wise_save=None, run=1, get_labeled_csv=False, min_lr=1e-06, scheduler='cosine', device='cuda:0', distributed=True, world_size=4, rank=0, local_rank=0, log_level=20)\n",
      "INFO:root:Fine-tuning Using R-Adapter\n",
      "2024-10-27,20:43:30 | INFO | Fine-tuning Using R-Adapter\n",
      "INFO:root:Training dataset ImageNet\n",
      "2024-10-27,20:43:30 | INFO | Training dataset ImageNet\n",
      "/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py:138: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler() if args.precision == \"amp\" else None\n",
      "/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py:138: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler() if args.precision == \"amp\" else None\n",
      "/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py:138: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler() if args.precision == \"amp\" else None\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.0.adapter_attn.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.0.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.0.adapter_attn.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.0.adapter_attn.f.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.0.adapter_mlp.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.0.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.0.adapter_mlp.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.0.adapter_mlp.f.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.1.adapter_attn.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.1.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.1.adapter_attn.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.1.adapter_attn.f.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.1.adapter_mlp.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.1.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.1.adapter_mlp.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.1.adapter_mlp.f.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.2.adapter_attn.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.2.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.2.adapter_attn.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.2.adapter_attn.f.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.2.adapter_mlp.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.2.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.2.adapter_mlp.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.2.adapter_mlp.f.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.3.adapter_attn.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.3.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.3.adapter_attn.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.3.adapter_attn.f.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.3.adapter_mlp.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.3.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.3.adapter_mlp.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.3.adapter_mlp.f.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.4.adapter_attn.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.4.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.4.adapter_attn.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.4.adapter_attn.f.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.4.adapter_mlp.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.4.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.4.adapter_mlp.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.4.adapter_mlp.f.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.5.adapter_attn.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.5.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.5.adapter_attn.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.5.adapter_attn.f.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.5.adapter_mlp.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.5.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.5.adapter_mlp.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.5.adapter_mlp.f.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.6.adapter_attn.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.6.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.6.adapter_attn.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.6.adapter_attn.f.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.6.adapter_mlp.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.6.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.6.adapter_mlp.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.6.adapter_mlp.f.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.7.adapter_attn.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.7.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.7.adapter_attn.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.7.adapter_attn.f.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.7.adapter_mlp.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.7.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.7.adapter_mlp.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.7.adapter_mlp.f.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.8.adapter_attn.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.8.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.8.adapter_attn.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.8.adapter_attn.f.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.8.adapter_mlp.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.8.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.8.adapter_mlp.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.8.adapter_mlp.f.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.9.adapter_attn.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.9.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.9.adapter_attn.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.9.adapter_attn.f.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.9.adapter_mlp.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.9.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.9.adapter_mlp.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.9.adapter_mlp.f.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.10.adapter_attn.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.10.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.10.adapter_attn.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.10.adapter_attn.f.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.10.adapter_mlp.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.10.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.10.adapter_mlp.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.10.adapter_mlp.f.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.11.adapter_attn.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.11.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.11.adapter_attn.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.11.adapter_attn.f.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.11.adapter_mlp.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.11.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.11.adapter_mlp.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.visual.transformer.resblocks.11.adapter_mlp.f.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.0.adapter_attn.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.0.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.0.adapter_attn.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.0.adapter_attn.f.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.0.adapter_mlp.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.0.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.0.adapter_mlp.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.0.adapter_mlp.f.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.1.adapter_attn.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.1.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.1.adapter_attn.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.1.adapter_attn.f.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.1.adapter_mlp.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.1.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.1.adapter_mlp.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.1.adapter_mlp.f.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.2.adapter_attn.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.2.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.2.adapter_attn.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.2.adapter_attn.f.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.2.adapter_mlp.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.2.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.2.adapter_mlp.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.2.adapter_mlp.f.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.3.adapter_attn.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.3.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.3.adapter_attn.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.3.adapter_attn.f.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.3.adapter_mlp.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.3.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.3.adapter_mlp.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.3.adapter_mlp.f.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.4.adapter_attn.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.4.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.4.adapter_attn.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.4.adapter_attn.f.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.4.adapter_mlp.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.4.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.4.adapter_mlp.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.4.adapter_mlp.f.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.5.adapter_attn.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.5.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.5.adapter_attn.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.5.adapter_attn.f.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.5.adapter_mlp.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.5.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.5.adapter_mlp.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.5.adapter_mlp.f.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.6.adapter_attn.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.6.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.6.adapter_attn.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.6.adapter_attn.f.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.6.adapter_mlp.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.6.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.6.adapter_mlp.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.6.adapter_mlp.f.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.7.adapter_attn.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.7.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.7.adapter_attn.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.7.adapter_attn.f.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.7.adapter_mlp.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.7.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.7.adapter_mlp.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.7.adapter_mlp.f.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.8.adapter_attn.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.8.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.8.adapter_attn.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.8.adapter_attn.f.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.8.adapter_mlp.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.8.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.8.adapter_mlp.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.8.adapter_mlp.f.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.9.adapter_attn.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.9.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.9.adapter_attn.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.9.adapter_attn.f.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.9.adapter_mlp.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.9.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.9.adapter_mlp.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.9.adapter_mlp.f.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.10.adapter_attn.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.10.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.10.adapter_attn.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.10.adapter_attn.f.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.10.adapter_mlp.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.10.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.10.adapter_mlp.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.10.adapter_mlp.f.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.11.adapter_attn.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.11.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.11.adapter_attn.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.11.adapter_attn.f.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.11.adapter_mlp.s\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.11.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.11.adapter_mlp.f.weight\n",
      "2024-10-27,20:44:53 | INFO | Train: module.model.transformer.resblocks.11.adapter_mlp.f.weight\n",
      "INFO:root:Num_params: 20.45M\n",
      "2024-10-27,20:44:53 | INFO | Num_params: 20.45M\n",
      "/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py:138: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler() if args.precision == \"amp\" else None\n",
      "INFO:root:Start epoch 0\n",
      "2024-10-27,20:44:53 | INFO | Start epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py:287: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py:287: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py:287: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py:287: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "[rank0]:I1027 20:45:01.763000 22998487881536 torch/nn/parallel/distributed.py:1524] Reducer buckets have been rebuilt in this iteration.\n",
      "[rank1]:I1027 20:45:01.766000 22397037303616 torch/nn/parallel/distributed.py:1524] Reducer buckets have been rebuilt in this iteration.\n",
      "[rank2]:I1027 20:45:01.772000 22428205213504 torch/nn/parallel/distributed.py:1524] Reducer buckets have been rebuilt in this iteration.\n",
      "[rank3]:I1027 20:45:01.772000 23282723374912 torch/nn/parallel/distributed.py:1524] Reducer buckets have been rebuilt in this iteration.\n",
      "INFO:root:Train Epoch: 0 [     32/1281167 (0%)] Data (t): 0.000 Batch (t): 0.153, 52.4147/s LR: 0.000002 Logit Scale: 100.000 Loss: 2.0449 (2.0449)\n",
      "2024-10-27,20:45:01 | INFO | Train Epoch: 0 [     32/1281167 (0%)] Data (t): 0.000 Batch (t): 0.153, 52.4147/s LR: 0.000002 Logit Scale: 100.000 Loss: 2.0449 (2.0449)\n",
      "INFO:root:Train Epoch: 0 [  16032/1281167 (1%)] Data (t): 0.000 Batch (t): 0.100, 79.7305/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.48267 (1.2638)\n",
      "2024-10-27,20:45:50 | INFO | Train Epoch: 0 [  16032/1281167 (1%)] Data (t): 0.000 Batch (t): 0.100, 79.7305/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.48267 (1.2638)\n",
      "INFO:root:Train Epoch: 0 [  32032/1281167 (3%)] Data (t): 0.000 Batch (t): 0.066, 121.453/s LR: 0.000501 Logit Scale: 100.000 Loss: 1.2448 (1.2575)\n",
      "2024-10-27,20:46:27 | INFO | Train Epoch: 0 [  32032/1281167 (3%)] Data (t): 0.000 Batch (t): 0.066, 121.453/s LR: 0.000501 Logit Scale: 100.000 Loss: 1.2448 (1.2575)\n",
      "INFO:root:Train Epoch: 0 [  48032/1281167 (4%)] Data (t): 0.000 Batch (t): 0.067, 119.625/s LR: 0.000501 Logit Scale: 100.000 Loss: 1.1803 (1.2382)\n",
      "2024-10-27,20:47:03 | INFO | Train Epoch: 0 [  48032/1281167 (4%)] Data (t): 0.000 Batch (t): 0.067, 119.625/s LR: 0.000501 Logit Scale: 100.000 Loss: 1.1803 (1.2382)\n",
      "INFO:root:Train Epoch: 0 [  64032/1281167 (5%)] Data (t): 0.000 Batch (t): 0.066, 120.874/s LR: 0.000501 Logit Scale: 100.000 Loss: 1.2456 (1.2397)\n",
      "2024-10-27,20:47:36 | INFO | Train Epoch: 0 [  64032/1281167 (5%)] Data (t): 0.000 Batch (t): 0.066, 120.874/s LR: 0.000501 Logit Scale: 100.000 Loss: 1.2456 (1.2397)\n",
      "INFO:root:Train Epoch: 0 [  80032/1281167 (6%)] Data (t): 0.000 Batch (t): 0.087, 91.6798/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.93065 (1.1882)\n",
      "2024-10-27,20:48:08 | INFO | Train Epoch: 0 [  80032/1281167 (6%)] Data (t): 0.000 Batch (t): 0.087, 91.6798/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.93065 (1.1882)\n",
      "INFO:root:Train Epoch: 0 [  96032/1281167 (7%)] Data (t): 0.000 Batch (t): 0.059, 134.622/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.36349 (1.0703)\n",
      "2024-10-27,20:48:41 | INFO | Train Epoch: 0 [  96032/1281167 (7%)] Data (t): 0.000 Batch (t): 0.059, 134.622/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.36349 (1.0703)\n",
      "INFO:root:Train Epoch: 0 [ 112032/1281167 (9%)] Data (t): 0.000 Batch (t): 0.060, 133.247/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.74213 (1.0293)\n",
      "2024-10-27,20:49:15 | INFO | Train Epoch: 0 [ 112032/1281167 (9%)] Data (t): 0.000 Batch (t): 0.060, 133.247/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.74213 (1.0293)\n",
      "INFO:root:Train Epoch: 0 [ 128032/1281167 (10%)] Data (t): 0.000 Batch (t): 0.067, 119.302/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.60854 (0.98256)\n",
      "2024-10-27,20:49:51 | INFO | Train Epoch: 0 [ 128032/1281167 (10%)] Data (t): 0.000 Batch (t): 0.067, 119.302/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.60854 (0.98256)\n",
      "INFO:root:Train Epoch: 0 [ 144032/1281167 (11%)] Data (t): 0.000 Batch (t): 0.058, 138.871/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.81472 (0.96578)\n",
      "2024-10-27,20:50:24 | INFO | Train Epoch: 0 [ 144032/1281167 (11%)] Data (t): 0.000 Batch (t): 0.058, 138.871/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.81472 (0.96578)\n",
      "INFO:root:Train Epoch: 0 [ 160032/1281167 (12%)] Data (t): 0.000 Batch (t): 0.071, 112.640/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.78909 (0.94972)\n",
      "2024-10-27,20:50:59 | INFO | Train Epoch: 0 [ 160032/1281167 (12%)] Data (t): 0.000 Batch (t): 0.071, 112.640/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.78909 (0.94972)\n",
      "INFO:root:Train Epoch: 0 [ 176032/1281167 (14%)] Data (t): 0.000 Batch (t): 0.053, 150.155/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.92946 (0.94803)\n",
      "2024-10-27,20:51:33 | INFO | Train Epoch: 0 [ 176032/1281167 (14%)] Data (t): 0.000 Batch (t): 0.053, 150.155/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.92946 (0.94803)\n",
      "INFO:root:Train Epoch: 0 [ 192032/1281167 (15%)] Data (t): 0.000 Batch (t): 0.080, 100.245/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.93993 (0.94741)\n",
      "2024-10-27,20:52:08 | INFO | Train Epoch: 0 [ 192032/1281167 (15%)] Data (t): 0.000 Batch (t): 0.080, 100.245/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.93993 (0.94741)\n",
      "INFO:root:Train Epoch: 0 [ 208032/1281167 (16%)] Data (t): 0.000 Batch (t): 0.076, 105.381/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.76229 (0.93418)\n",
      "2024-10-27,20:52:45 | INFO | Train Epoch: 0 [ 208032/1281167 (16%)] Data (t): 0.000 Batch (t): 0.076, 105.381/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.76229 (0.93418)\n",
      "INFO:root:Train Epoch: 0 [ 224032/1281167 (17%)] Data (t): 0.000 Batch (t): 0.070, 113.790/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.67608 (0.91698)\n",
      "2024-10-27,20:53:23 | INFO | Train Epoch: 0 [ 224032/1281167 (17%)] Data (t): 0.000 Batch (t): 0.070, 113.790/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.67608 (0.91698)\n",
      "INFO:root:Train Epoch: 0 [ 240032/1281167 (19%)] Data (t): 0.000 Batch (t): 0.068, 118.472/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.34419 (0.88118)\n",
      "2024-10-27,20:54:00 | INFO | Train Epoch: 0 [ 240032/1281167 (19%)] Data (t): 0.000 Batch (t): 0.068, 118.472/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.34419 (0.88118)\n",
      "INFO:root:Train Epoch: 0 [ 256032/1281167 (20%)] Data (t): 0.000 Batch (t): 0.061, 131.326/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.61024 (0.86524)\n",
      "2024-10-27,20:54:37 | INFO | Train Epoch: 0 [ 256032/1281167 (20%)] Data (t): 0.000 Batch (t): 0.061, 131.326/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.61024 (0.86524)\n",
      "INFO:root:Train Epoch: 0 [ 272032/1281167 (21%)] Data (t): 0.000 Batch (t): 0.074, 108.720/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.65267 (0.85343)\n",
      "2024-10-27,20:55:08 | INFO | Train Epoch: 0 [ 272032/1281167 (21%)] Data (t): 0.000 Batch (t): 0.074, 108.720/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.65267 (0.85343)\n",
      "INFO:root:Train Epoch: 0 [ 288032/1281167 (22%)] Data (t): 0.000 Batch (t): 0.080, 100.470/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.45238 (0.83232)\n",
      "2024-10-27,20:55:45 | INFO | Train Epoch: 0 [ 288032/1281167 (22%)] Data (t): 0.000 Batch (t): 0.080, 100.470/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.45238 (0.83232)\n",
      "INFO:root:Train Epoch: 0 [ 304032/1281167 (24%)] Data (t): 0.000 Batch (t): 0.070, 114.734/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.71390 (0.82640)\n",
      "2024-10-27,20:56:21 | INFO | Train Epoch: 0 [ 304032/1281167 (24%)] Data (t): 0.000 Batch (t): 0.070, 114.734/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.71390 (0.82640)\n",
      "INFO:root:Train Epoch: 0 [ 320032/1281167 (25%)] Data (t): 0.000 Batch (t): 0.068, 118.385/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.44792 (0.80838)\n",
      "2024-10-27,20:56:54 | INFO | Train Epoch: 0 [ 320032/1281167 (25%)] Data (t): 0.000 Batch (t): 0.068, 118.385/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.44792 (0.80838)\n",
      "INFO:root:Train Epoch: 0 [ 336032/1281167 (26%)] Data (t): 0.000 Batch (t): 0.074, 107.812/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.71182 (0.80399)\n",
      "2024-10-27,20:57:30 | INFO | Train Epoch: 0 [ 336032/1281167 (26%)] Data (t): 0.000 Batch (t): 0.074, 107.812/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.71182 (0.80399)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Train Epoch: 0 [ 352032/1281167 (27%)] Data (t): 0.000 Batch (t): 0.076, 104.729/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.45706 (0.78890)\n",
      "2024-10-27,20:58:08 | INFO | Train Epoch: 0 [ 352032/1281167 (27%)] Data (t): 0.000 Batch (t): 0.076, 104.729/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.45706 (0.78890)\n",
      "INFO:root:Train Epoch: 0 [ 368032/1281167 (29%)] Data (t): 0.000 Batch (t): 0.083, 96.1244/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.45321 (0.77492)\n",
      "2024-10-27,20:58:47 | INFO | Train Epoch: 0 [ 368032/1281167 (29%)] Data (t): 0.000 Batch (t): 0.083, 96.1244/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.45321 (0.77492)\n",
      "INFO:root:Train Epoch: 0 [ 384032/1281167 (30%)] Data (t): 0.000 Batch (t): 0.100, 79.7199/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.99397 (0.78368)\n",
      "2024-10-27,20:59:26 | INFO | Train Epoch: 0 [ 384032/1281167 (30%)] Data (t): 0.000 Batch (t): 0.100, 79.7199/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.99397 (0.78368)\n",
      "INFO:root:Train Epoch: 0 [ 400032/1281167 (31%)] Data (t): 0.000 Batch (t): 0.076, 105.472/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.62687 (0.77765)\n",
      "2024-10-27,21:00:05 | INFO | Train Epoch: 0 [ 400032/1281167 (31%)] Data (t): 0.000 Batch (t): 0.076, 105.472/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.62687 (0.77765)\n",
      "INFO:root:Train Epoch: 0 [ 416032/1281167 (32%)] Data (t): 0.000 Batch (t): 0.070, 114.315/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.70499 (0.77496)\n",
      "2024-10-27,21:00:43 | INFO | Train Epoch: 0 [ 416032/1281167 (32%)] Data (t): 0.000 Batch (t): 0.070, 114.315/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.70499 (0.77496)\n",
      "INFO:root:Train Epoch: 0 [ 432032/1281167 (34%)] Data (t): 0.000 Batch (t): 0.070, 114.345/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.54699 (0.76682)\n",
      "2024-10-27,21:01:22 | INFO | Train Epoch: 0 [ 432032/1281167 (34%)] Data (t): 0.000 Batch (t): 0.070, 114.345/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.54699 (0.76682)\n",
      "INFO:root:Train Epoch: 0 [ 448032/1281167 (35%)] Data (t): 0.000 Batch (t): 0.073, 108.949/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.82186 (0.76871)\n",
      "2024-10-27,21:02:00 | INFO | Train Epoch: 0 [ 448032/1281167 (35%)] Data (t): 0.000 Batch (t): 0.073, 108.949/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.82186 (0.76871)\n",
      "INFO:root:Train Epoch: 0 [ 464032/1281167 (36%)] Data (t): 0.000 Batch (t): 0.068, 116.805/s LR: 0.000499 Logit Scale: 100.000 Loss: 0.64791 (0.76469)\n",
      "2024-10-27,21:02:37 | INFO | Train Epoch: 0 [ 464032/1281167 (36%)] Data (t): 0.000 Batch (t): 0.068, 116.805/s LR: 0.000499 Logit Scale: 100.000 Loss: 0.64791 (0.76469)\n",
      "INFO:root:Train Epoch: 0 [ 480032/1281167 (37%)] Data (t): 0.000 Batch (t): 0.089, 89.7041/s LR: 0.000499 Logit Scale: 100.000 Loss: 0.54364 (0.75756)\n",
      "2024-10-27,21:03:14 | INFO | Train Epoch: 0 [ 480032/1281167 (37%)] Data (t): 0.000 Batch (t): 0.089, 89.7041/s LR: 0.000499 Logit Scale: 100.000 Loss: 0.54364 (0.75756)\n",
      "INFO:root:Train Epoch: 0 [ 496032/1281167 (39%)] Data (t): 0.000 Batch (t): 0.092, 87.0845/s LR: 0.000499 Logit Scale: 100.000 Loss: 0.80355 (0.75899)\n",
      "2024-10-27,21:03:51 | INFO | Train Epoch: 0 [ 496032/1281167 (39%)] Data (t): 0.000 Batch (t): 0.092, 87.0845/s LR: 0.000499 Logit Scale: 100.000 Loss: 0.80355 (0.75899)\n",
      "INFO:root:Train Epoch: 0 [ 512032/1281167 (40%)] Data (t): 0.000 Batch (t): 0.068, 117.312/s LR: 0.000499 Logit Scale: 100.000 Loss: 0.93870 (0.76444)\n",
      "2024-10-27,21:04:30 | INFO | Train Epoch: 0 [ 512032/1281167 (40%)] Data (t): 0.000 Batch (t): 0.068, 117.312/s LR: 0.000499 Logit Scale: 100.000 Loss: 0.93870 (0.76444)\n",
      "INFO:root:Train Epoch: 0 [ 528032/1281167 (41%)] Data (t): 0.000 Batch (t): 0.079, 101.186/s LR: 0.000499 Logit Scale: 100.000 Loss: 0.80273 (0.76557)\n",
      "2024-10-27,21:05:08 | INFO | Train Epoch: 0 [ 528032/1281167 (41%)] Data (t): 0.000 Batch (t): 0.079, 101.186/s LR: 0.000499 Logit Scale: 100.000 Loss: 0.80273 (0.76557)\n",
      "INFO:root:Train Epoch: 0 [ 544032/1281167 (42%)] Data (t): 0.000 Batch (t): 0.073, 109.078/s LR: 0.000499 Logit Scale: 100.000 Loss: 1.3502 (0.78227)\n",
      "2024-10-27,21:05:47 | INFO | Train Epoch: 0 [ 544032/1281167 (42%)] Data (t): 0.000 Batch (t): 0.073, 109.078/s LR: 0.000499 Logit Scale: 100.000 Loss: 1.3502 (0.78227)\n",
      "INFO:root:Train Epoch: 0 [ 560032/1281167 (44%)] Data (t): 0.000 Batch (t): 0.066, 121.738/s LR: 0.000499 Logit Scale: 100.000 Loss: 0.53479 (0.77540)\n",
      "2024-10-27,21:06:26 | INFO | Train Epoch: 0 [ 560032/1281167 (44%)] Data (t): 0.000 Batch (t): 0.066, 121.738/s LR: 0.000499 Logit Scale: 100.000 Loss: 0.53479 (0.77540)\n",
      "INFO:root:Train Epoch: 0 [ 576032/1281167 (45%)] Data (t): 0.000 Batch (t): 0.059, 135.655/s LR: 0.000499 Logit Scale: 100.000 Loss: 0.69887 (0.77333)\n",
      "2024-10-27,21:07:01 | INFO | Train Epoch: 0 [ 576032/1281167 (45%)] Data (t): 0.000 Batch (t): 0.059, 135.655/s LR: 0.000499 Logit Scale: 100.000 Loss: 0.69887 (0.77333)\n",
      "INFO:root:Train Epoch: 0 [ 592032/1281167 (46%)] Data (t): 0.000 Batch (t): 0.065, 122.928/s LR: 0.000499 Logit Scale: 100.000 Loss: 0.49503 (0.76600)\n",
      "2024-10-27,21:07:34 | INFO | Train Epoch: 0 [ 592032/1281167 (46%)] Data (t): 0.000 Batch (t): 0.065, 122.928/s LR: 0.000499 Logit Scale: 100.000 Loss: 0.49503 (0.76600)\n",
      "INFO:root:Train Epoch: 0 [ 608032/1281167 (47%)] Data (t): 0.000 Batch (t): 0.054, 147.455/s LR: 0.000498 Logit Scale: 100.000 Loss: 0.65305 (0.76311)\n",
      "2024-10-27,21:08:07 | INFO | Train Epoch: 0 [ 608032/1281167 (47%)] Data (t): 0.000 Batch (t): 0.054, 147.455/s LR: 0.000498 Logit Scale: 100.000 Loss: 0.65305 (0.76311)\n",
      "INFO:root:Train Epoch: 0 [ 624032/1281167 (49%)] Data (t): 0.000 Batch (t): 0.051, 155.464/s LR: 0.000498 Logit Scale: 100.000 Loss: 0.33923 (0.75251)\n",
      "2024-10-27,21:08:40 | INFO | Train Epoch: 0 [ 624032/1281167 (49%)] Data (t): 0.000 Batch (t): 0.051, 155.464/s LR: 0.000498 Logit Scale: 100.000 Loss: 0.33923 (0.75251)\n",
      "INFO:root:Train Epoch: 0 [ 640032/1281167 (50%)] Data (t): 0.000 Batch (t): 0.069, 115.113/s LR: 0.000498 Logit Scale: 100.000 Loss: 0.56076 (0.74783)\n",
      "2024-10-27,21:09:13 | INFO | Train Epoch: 0 [ 640032/1281167 (50%)] Data (t): 0.000 Batch (t): 0.069, 115.113/s LR: 0.000498 Logit Scale: 100.000 Loss: 0.56076 (0.74783)\n",
      "INFO:root:Train Epoch: 0 [ 656032/1281167 (51%)] Data (t): 0.000 Batch (t): 0.048, 167.302/s LR: 0.000498 Logit Scale: 100.000 Loss: 0.51143 (0.74221)\n",
      "2024-10-27,21:09:47 | INFO | Train Epoch: 0 [ 656032/1281167 (51%)] Data (t): 0.000 Batch (t): 0.048, 167.302/s LR: 0.000498 Logit Scale: 100.000 Loss: 0.51143 (0.74221)\n",
      "INFO:root:Train Epoch: 0 [ 672032/1281167 (52%)] Data (t): 0.000 Batch (t): 0.055, 144.652/s LR: 0.000498 Logit Scale: 100.000 Loss: 0.33812 (0.73281)\n",
      "2024-10-27,21:10:19 | INFO | Train Epoch: 0 [ 672032/1281167 (52%)] Data (t): 0.000 Batch (t): 0.055, 144.652/s LR: 0.000498 Logit Scale: 100.000 Loss: 0.33812 (0.73281)\n",
      "INFO:root:Train Epoch: 0 [ 688032/1281167 (54%)] Data (t): 0.000 Batch (t): 0.059, 135.581/s LR: 0.000498 Logit Scale: 100.000 Loss: 1.0016 (0.73892)\n",
      "2024-10-27,21:10:51 | INFO | Train Epoch: 0 [ 688032/1281167 (54%)] Data (t): 0.000 Batch (t): 0.059, 135.581/s LR: 0.000498 Logit Scale: 100.000 Loss: 1.0016 (0.73892)\n",
      "INFO:root:Train Epoch: 0 [ 704032/1281167 (55%)] Data (t): 0.000 Batch (t): 0.081, 99.2118/s LR: 0.000497 Logit Scale: 100.000 Loss: 0.34059 (0.73006)\n",
      "2024-10-27,21:11:25 | INFO | Train Epoch: 0 [ 704032/1281167 (55%)] Data (t): 0.000 Batch (t): 0.081, 99.2118/s LR: 0.000497 Logit Scale: 100.000 Loss: 0.34059 (0.73006)\n",
      "INFO:root:Train Epoch: 0 [ 720032/1281167 (56%)] Data (t): 0.000 Batch (t): 0.061, 131.633/s LR: 0.000497 Logit Scale: 100.000 Loss: 0.70189 (0.72945)\n",
      "2024-10-27,21:12:00 | INFO | Train Epoch: 0 [ 720032/1281167 (56%)] Data (t): 0.000 Batch (t): 0.061, 131.633/s LR: 0.000497 Logit Scale: 100.000 Loss: 0.70189 (0.72945)\n",
      "INFO:root:Train Epoch: 0 [ 736032/1281167 (57%)] Data (t): 0.000 Batch (t): 0.059, 134.657/s LR: 0.000497 Logit Scale: 100.000 Loss: 0.76108 (0.73012)\n",
      "2024-10-27,21:12:32 | INFO | Train Epoch: 0 [ 736032/1281167 (57%)] Data (t): 0.000 Batch (t): 0.059, 134.657/s LR: 0.000497 Logit Scale: 100.000 Loss: 0.76108 (0.73012)\n",
      "INFO:root:Train Epoch: 0 [ 752032/1281167 (59%)] Data (t): 0.000 Batch (t): 0.065, 122.909/s LR: 0.000497 Logit Scale: 100.000 Loss: 0.61584 (0.72774)\n",
      "2024-10-27,21:13:05 | INFO | Train Epoch: 0 [ 752032/1281167 (59%)] Data (t): 0.000 Batch (t): 0.065, 122.909/s LR: 0.000497 Logit Scale: 100.000 Loss: 0.61584 (0.72774)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Train Epoch: 0 [ 768032/1281167 (60%)] Data (t): 0.000 Batch (t): 0.056, 143.545/s LR: 0.000497 Logit Scale: 100.000 Loss: 0.33962 (0.71982)\n",
      "2024-10-27,21:13:39 | INFO | Train Epoch: 0 [ 768032/1281167 (60%)] Data (t): 0.000 Batch (t): 0.056, 143.545/s LR: 0.000497 Logit Scale: 100.000 Loss: 0.33962 (0.71982)\n",
      "INFO:root:Train Epoch: 0 [ 784032/1281167 (61%)] Data (t): 0.000 Batch (t): 0.056, 142.551/s LR: 0.000497 Logit Scale: 100.000 Loss: 0.67168 (0.71886)\n",
      "2024-10-27,21:14:12 | INFO | Train Epoch: 0 [ 784032/1281167 (61%)] Data (t): 0.000 Batch (t): 0.056, 142.551/s LR: 0.000497 Logit Scale: 100.000 Loss: 0.67168 (0.71886)\n",
      "INFO:root:Train Epoch: 0 [ 800032/1281167 (62%)] Data (t): 0.000 Batch (t): 0.070, 114.280/s LR: 0.000496 Logit Scale: 100.000 Loss: 0.36884 (0.71200)\n",
      "2024-10-27,21:14:48 | INFO | Train Epoch: 0 [ 800032/1281167 (62%)] Data (t): 0.000 Batch (t): 0.070, 114.280/s LR: 0.000496 Logit Scale: 100.000 Loss: 0.36884 (0.71200)\n",
      "INFO:root:Train Epoch: 0 [ 816032/1281167 (64%)] Data (t): 0.000 Batch (t): 0.069, 115.512/s LR: 0.000496 Logit Scale: 100.000 Loss: 0.36260 (0.70528)\n",
      "2024-10-27,21:15:21 | INFO | Train Epoch: 0 [ 816032/1281167 (64%)] Data (t): 0.000 Batch (t): 0.069, 115.512/s LR: 0.000496 Logit Scale: 100.000 Loss: 0.36260 (0.70528)\n",
      "INFO:root:Train Epoch: 0 [ 832032/1281167 (65%)] Data (t): 0.000 Batch (t): 0.058, 138.469/s LR: 0.000496 Logit Scale: 100.000 Loss: 0.33366 (0.69827)\n",
      "2024-10-27,21:15:53 | INFO | Train Epoch: 0 [ 832032/1281167 (65%)] Data (t): 0.000 Batch (t): 0.058, 138.469/s LR: 0.000496 Logit Scale: 100.000 Loss: 0.33366 (0.69827)\n",
      "INFO:root:Train Epoch: 0 [ 848032/1281167 (66%)] Data (t): 0.000 Batch (t): 0.064, 125.054/s LR: 0.000496 Logit Scale: 100.000 Loss: 0.32044 (0.69127)\n",
      "2024-10-27,21:16:26 | INFO | Train Epoch: 0 [ 848032/1281167 (66%)] Data (t): 0.000 Batch (t): 0.064, 125.054/s LR: 0.000496 Logit Scale: 100.000 Loss: 0.32044 (0.69127)\n",
      "INFO:root:Train Epoch: 0 [ 864032/1281167 (67%)] Data (t): 0.000 Batch (t): 0.071, 113.391/s LR: 0.000496 Logit Scale: 100.000 Loss: 0.58673 (0.68937)\n",
      "2024-10-27,21:16:59 | INFO | Train Epoch: 0 [ 864032/1281167 (67%)] Data (t): 0.000 Batch (t): 0.071, 113.391/s LR: 0.000496 Logit Scale: 100.000 Loss: 0.58673 (0.68937)\n",
      "INFO:root:Train Epoch: 0 [ 880032/1281167 (69%)] Data (t): 0.000 Batch (t): 0.058, 136.907/s LR: 0.000495 Logit Scale: 100.000 Loss: 0.82841 (0.69185)\n",
      "2024-10-27,21:17:31 | INFO | Train Epoch: 0 [ 880032/1281167 (69%)] Data (t): 0.000 Batch (t): 0.058, 136.907/s LR: 0.000495 Logit Scale: 100.000 Loss: 0.82841 (0.69185)\n",
      "INFO:root:Train Epoch: 0 [ 896032/1281167 (70%)] Data (t): 0.000 Batch (t): 0.056, 143.904/s LR: 0.000495 Logit Scale: 100.000 Loss: 0.48893 (0.68829)\n",
      "2024-10-27,21:18:08 | INFO | Train Epoch: 0 [ 896032/1281167 (70%)] Data (t): 0.000 Batch (t): 0.056, 143.904/s LR: 0.000495 Logit Scale: 100.000 Loss: 0.48893 (0.68829)\n",
      "INFO:root:Train Epoch: 0 [ 912032/1281167 (71%)] Data (t): 0.000 Batch (t): 0.057, 139.704/s LR: 0.000495 Logit Scale: 100.000 Loss: 0.32228 (0.68198)\n",
      "2024-10-27,21:18:45 | INFO | Train Epoch: 0 [ 912032/1281167 (71%)] Data (t): 0.000 Batch (t): 0.057, 139.704/s LR: 0.000495 Logit Scale: 100.000 Loss: 0.32228 (0.68198)\n",
      "INFO:root:Train Epoch: 0 [ 928032/1281167 (72%)] Data (t): 0.000 Batch (t): 0.056, 144.135/s LR: 0.000495 Logit Scale: 100.000 Loss: 0.45393 (0.67812)\n",
      "2024-10-27,21:19:17 | INFO | Train Epoch: 0 [ 928032/1281167 (72%)] Data (t): 0.000 Batch (t): 0.056, 144.135/s LR: 0.000495 Logit Scale: 100.000 Loss: 0.45393 (0.67812)\n",
      "INFO:root:Train Epoch: 0 [ 944032/1281167 (74%)] Data (t): 0.000 Batch (t): 0.069, 115.148/s LR: 0.000495 Logit Scale: 100.000 Loss: 0.45371 (0.67438)\n",
      "2024-10-27,21:19:48 | INFO | Train Epoch: 0 [ 944032/1281167 (74%)] Data (t): 0.000 Batch (t): 0.069, 115.148/s LR: 0.000495 Logit Scale: 100.000 Loss: 0.45371 (0.67438)\n",
      "INFO:root:Train Epoch: 0 [ 960032/1281167 (75%)] Data (t): 0.000 Batch (t): 0.055, 144.349/s LR: 0.000494 Logit Scale: 100.000 Loss: 0.42292 (0.67025)\n",
      "2024-10-27,21:20:22 | INFO | Train Epoch: 0 [ 960032/1281167 (75%)] Data (t): 0.000 Batch (t): 0.055, 144.349/s LR: 0.000494 Logit Scale: 100.000 Loss: 0.42292 (0.67025)\n",
      "INFO:root:Train Epoch: 0 [ 976032/1281167 (76%)] Data (t): 0.000 Batch (t): 0.070, 115.021/s LR: 0.000494 Logit Scale: 100.000 Loss: 0.49817 (0.66748)\n",
      "2024-10-27,21:20:56 | INFO | Train Epoch: 0 [ 976032/1281167 (76%)] Data (t): 0.000 Batch (t): 0.070, 115.021/s LR: 0.000494 Logit Scale: 100.000 Loss: 0.49817 (0.66748)\n",
      "INFO:root:Train Epoch: 0 [ 992032/1281167 (77%)] Data (t): 0.000 Batch (t): 0.070, 114.178/s LR: 0.000494 Logit Scale: 100.000 Loss: 0.67388 (0.66758)\n",
      "2024-10-27,21:21:30 | INFO | Train Epoch: 0 [ 992032/1281167 (77%)] Data (t): 0.000 Batch (t): 0.070, 114.178/s LR: 0.000494 Logit Scale: 100.000 Loss: 0.67388 (0.66758)\n",
      "INFO:root:Train Epoch: 0 [1008032/1281167 (79%)] Data (t): 0.000 Batch (t): 0.069, 115.170/s LR: 0.000494 Logit Scale: 100.000 Loss: 0.41836 (0.66369)\n",
      "2024-10-27,21:22:04 | INFO | Train Epoch: 0 [1008032/1281167 (79%)] Data (t): 0.000 Batch (t): 0.069, 115.170/s LR: 0.000494 Logit Scale: 100.000 Loss: 0.41836 (0.66369)\n",
      "INFO:root:Train Epoch: 0 [1024032/1281167 (80%)] Data (t): 0.000 Batch (t): 0.059, 136.640/s LR: 0.000493 Logit Scale: 100.000 Loss: 0.65106 (0.66349)\n",
      "2024-10-27,21:22:37 | INFO | Train Epoch: 0 [1024032/1281167 (80%)] Data (t): 0.000 Batch (t): 0.059, 136.640/s LR: 0.000493 Logit Scale: 100.000 Loss: 0.65106 (0.66349)\n",
      "INFO:root:Train Epoch: 0 [1040032/1281167 (81%)] Data (t): 0.000 Batch (t): 0.064, 125.469/s LR: 0.000493 Logit Scale: 100.000 Loss: 0.74992 (0.66480)\n",
      "2024-10-27,21:23:11 | INFO | Train Epoch: 0 [1040032/1281167 (81%)] Data (t): 0.000 Batch (t): 0.064, 125.469/s LR: 0.000493 Logit Scale: 100.000 Loss: 0.74992 (0.66480)\n",
      "INFO:root:Train Epoch: 0 [1056032/1281167 (82%)] Data (t): 0.000 Batch (t): 0.071, 112.996/s LR: 0.000493 Logit Scale: 100.000 Loss: 0.88964 (0.66816)\n",
      "2024-10-27,21:23:45 | INFO | Train Epoch: 0 [1056032/1281167 (82%)] Data (t): 0.000 Batch (t): 0.071, 112.996/s LR: 0.000493 Logit Scale: 100.000 Loss: 0.88964 (0.66816)\n",
      "INFO:root:Train Epoch: 0 [1072032/1281167 (84%)] Data (t): 0.000 Batch (t): 0.063, 127.691/s LR: 0.000493 Logit Scale: 100.000 Loss: 0.56913 (0.66670)\n",
      "2024-10-27,21:24:19 | INFO | Train Epoch: 0 [1072032/1281167 (84%)] Data (t): 0.000 Batch (t): 0.063, 127.691/s LR: 0.000493 Logit Scale: 100.000 Loss: 0.56913 (0.66670)\n",
      "INFO:root:Train Epoch: 0 [1088032/1281167 (85%)] Data (t): 0.000 Batch (t): 0.071, 113.399/s LR: 0.000492 Logit Scale: 100.000 Loss: 0.90103 (0.67010)\n",
      "2024-10-27,21:24:53 | INFO | Train Epoch: 0 [1088032/1281167 (85%)] Data (t): 0.000 Batch (t): 0.071, 113.399/s LR: 0.000492 Logit Scale: 100.000 Loss: 0.90103 (0.67010)\n",
      "INFO:root:Train Epoch: 0 [1104032/1281167 (86%)] Data (t): 0.000 Batch (t): 0.061, 130.194/s LR: 0.000492 Logit Scale: 100.000 Loss: 0.69473 (0.67045)\n",
      "2024-10-27,21:25:27 | INFO | Train Epoch: 0 [1104032/1281167 (86%)] Data (t): 0.000 Batch (t): 0.061, 130.194/s LR: 0.000492 Logit Scale: 100.000 Loss: 0.69473 (0.67045)\n",
      "INFO:root:Train Epoch: 0 [1120032/1281167 (87%)] Data (t): 0.000 Batch (t): 0.068, 118.151/s LR: 0.000492 Logit Scale: 100.000 Loss: 0.59307 (0.66936)\n",
      "2024-10-27,21:26:01 | INFO | Train Epoch: 0 [1120032/1281167 (87%)] Data (t): 0.000 Batch (t): 0.068, 118.151/s LR: 0.000492 Logit Scale: 100.000 Loss: 0.59307 (0.66936)\n",
      "INFO:root:Train Epoch: 0 [1136032/1281167 (89%)] Data (t): 0.000 Batch (t): 0.059, 135.329/s LR: 0.000492 Logit Scale: 100.000 Loss: 0.46871 (0.66657)\n",
      "2024-10-27,21:26:34 | INFO | Train Epoch: 0 [1136032/1281167 (89%)] Data (t): 0.000 Batch (t): 0.059, 135.329/s LR: 0.000492 Logit Scale: 100.000 Loss: 0.46871 (0.66657)\n",
      "INFO:root:Train Epoch: 0 [1152032/1281167 (90%)] Data (t): 0.000 Batch (t): 0.087, 91.9088/s LR: 0.000491 Logit Scale: 100.000 Loss: 0.49013 (0.66415)\n",
      "2024-10-27,21:27:11 | INFO | Train Epoch: 0 [1152032/1281167 (90%)] Data (t): 0.000 Batch (t): 0.087, 91.9088/s LR: 0.000491 Logit Scale: 100.000 Loss: 0.49013 (0.66415)\n",
      "INFO:root:Train Epoch: 0 [1168032/1281167 (91%)] Data (t): 0.000 Batch (t): 0.050, 160.548/s LR: 0.000491 Logit Scale: 100.000 Loss: 0.48603 (0.66175)\n",
      "2024-10-27,21:27:39 | INFO | Train Epoch: 0 [1168032/1281167 (91%)] Data (t): 0.000 Batch (t): 0.050, 160.548/s LR: 0.000491 Logit Scale: 100.000 Loss: 0.48603 (0.66175)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Train Epoch: 0 [1184032/1281167 (92%)] Data (t): 0.000 Batch (t): 0.072, 111.410/s LR: 0.000491 Logit Scale: 100.000 Loss: 0.47928 (0.65931)\n",
      "2024-10-27,21:28:08 | INFO | Train Epoch: 0 [1184032/1281167 (92%)] Data (t): 0.000 Batch (t): 0.072, 111.410/s LR: 0.000491 Logit Scale: 100.000 Loss: 0.47928 (0.65931)\n",
      "INFO:root:Train Epoch: 0 [1200032/1281167 (94%)] Data (t): 0.000 Batch (t): 0.066, 120.775/s LR: 0.000491 Logit Scale: 100.000 Loss: 0.50579 (0.65729)\n",
      "2024-10-27,21:28:41 | INFO | Train Epoch: 0 [1200032/1281167 (94%)] Data (t): 0.000 Batch (t): 0.066, 120.775/s LR: 0.000491 Logit Scale: 100.000 Loss: 0.50579 (0.65729)\n",
      "INFO:root:Train Epoch: 0 [1216032/1281167 (95%)] Data (t): 0.000 Batch (t): 0.059, 135.685/s LR: 0.000490 Logit Scale: 100.000 Loss: 0.55147 (0.65592)\n",
      "2024-10-27,21:29:13 | INFO | Train Epoch: 0 [1216032/1281167 (95%)] Data (t): 0.000 Batch (t): 0.059, 135.685/s LR: 0.000490 Logit Scale: 100.000 Loss: 0.55147 (0.65592)\n",
      "INFO:root:Train Epoch: 0 [1232032/1281167 (96%)] Data (t): 0.000 Batch (t): 0.063, 126.116/s LR: 0.000490 Logit Scale: 100.000 Loss: 1.0722 (0.66126)\n",
      "2024-10-27,21:29:45 | INFO | Train Epoch: 0 [1232032/1281167 (96%)] Data (t): 0.000 Batch (t): 0.063, 126.116/s LR: 0.000490 Logit Scale: 100.000 Loss: 1.0722 (0.66126)\n",
      "INFO:root:Train Epoch: 0 [1248032/1281167 (97%)] Data (t): 0.000 Batch (t): 0.071, 113.119/s LR: 0.000490 Logit Scale: 100.000 Loss: 0.97741 (0.66526)\n",
      "2024-10-27,21:30:17 | INFO | Train Epoch: 0 [1248032/1281167 (97%)] Data (t): 0.000 Batch (t): 0.071, 113.119/s LR: 0.000490 Logit Scale: 100.000 Loss: 0.97741 (0.66526)\n",
      "INFO:root:Train Epoch: 0 [1264032/1281167 (99%)] Data (t): 0.000 Batch (t): 0.064, 125.866/s LR: 0.000489 Logit Scale: 100.000 Loss: 0.31107 (0.66083)\n",
      "2024-10-27,21:30:49 | INFO | Train Epoch: 0 [1264032/1281167 (99%)] Data (t): 0.000 Batch (t): 0.064, 125.866/s LR: 0.000489 Logit Scale: 100.000 Loss: 0.31107 (0.66083)\n",
      "INFO:root:Train Epoch: 0 [1280032/1281167 (100%)] Data (t): 0.000 Batch (t): 0.069, 115.502/s LR: 0.000489 Logit Scale: 100.000 Loss: 0.33564 (0.65682)\n",
      "2024-10-27,21:31:21 | INFO | Train Epoch: 0 [1280032/1281167 (100%)] Data (t): 0.000 Batch (t): 0.069, 115.502/s LR: 0.000489 Logit Scale: 100.000 Loss: 0.33564 (0.65682)\n",
      "[rank2]: Traceback (most recent call last):\n",
      "[rank2]:   File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "[rank2]:   File \"<frozen runpy>\", line 88, in _run_code\n",
      "[rank2]:   File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py\", line 362, in <module>\n",
      "[rank2]:     main(args)\n",
      "[rank2]:   File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py\", line 199, in main\n",
      "[rank2]:     adapt_utils.Rep_AdaptWeight(model.module.model, args)\n",
      "[rank2]:   File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/clip2/loralib/utils.py\", line 124, in Rep_AdaptWeight\n",
      "[rank2]:     merged_weight, _ = reparameterize(adapter_attn.d.weight.squeeze().T, adapter_attn.u.weight.squeeze().T)\n",
      "[rank2]:                                       ^^^^^^^^^^^^^^\n",
      "[rank2]:   File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1729, in __getattr__\n",
      "[rank2]:     raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{name}'\")\n",
      "[rank2]: AttributeError: 'StochasticAdapter' object has no attribute 'd'\n",
      "[rank2]:I1027 21:31:24.987000 22428205213504 torch/_dynamo/utils.py:335] TorchDynamo compilation metrics:\n",
      "[rank2]:I1027 21:31:24.987000 22428205213504 torch/_dynamo/utils.py:335] Function    Runtimes (s)\n",
      "[rank2]:I1027 21:31:24.987000 22428205213504 torch/_dynamo/utils.py:335] ----------  --------------\n",
      "[rank3]: Traceback (most recent call last):\n",
      "[rank3]:   File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "[rank3]:   File \"<frozen runpy>\", line 88, in _run_code\n",
      "[rank3]:   File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py\", line 362, in <module>\n",
      "[rank3]:     main(args)\n",
      "[rank3]:   File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py\", line 199, in main\n",
      "[rank3]:     adapt_utils.Rep_AdaptWeight(model.module.model, args)\n",
      "[rank3]:   File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/clip2/loralib/utils.py\", line 124, in Rep_AdaptWeight\n",
      "[rank3]:     merged_weight, _ = reparameterize(adapter_attn.d.weight.squeeze().T, adapter_attn.u.weight.squeeze().T)\n",
      "[rank3]:                                       ^^^^^^^^^^^^^^\n",
      "[rank3]:   File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1729, in __getattr__\n",
      "[rank3]:     raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{name}'\")\n",
      "[rank3]: AttributeError: 'StochasticAdapter' object has no attribute 'd'\n",
      "[rank3]:I1027 21:31:25.005000 23282723374912 torch/_dynamo/utils.py:335] TorchDynamo compilation metrics:\n",
      "[rank3]:I1027 21:31:25.005000 23282723374912 torch/_dynamo/utils.py:335] Function    Runtimes (s)\n",
      "[rank3]:I1027 21:31:25.005000 23282723374912 torch/_dynamo/utils.py:335] ----------  --------------\n",
      "[rank1]: Traceback (most recent call last):\n",
      "[rank1]:   File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "[rank1]:   File \"<frozen runpy>\", line 88, in _run_code\n",
      "[rank1]:   File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py\", line 362, in <module>\n",
      "[rank1]:     main(args)\n",
      "[rank1]:   File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py\", line 199, in main\n",
      "[rank1]:     adapt_utils.Rep_AdaptWeight(model.module.model, args)\n",
      "[rank1]:   File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/clip2/loralib/utils.py\", line 124, in Rep_AdaptWeight\n",
      "[rank1]:     merged_weight, _ = reparameterize(adapter_attn.d.weight.squeeze().T, adapter_attn.u.weight.squeeze().T)\n",
      "[rank1]:                                       ^^^^^^^^^^^^^^\n",
      "[rank1]:   File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1729, in __getattr__\n",
      "[rank1]:     raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{name}'\")\n",
      "[rank1]: AttributeError: 'StochasticAdapter' object has no attribute 'd'\n",
      "[rank1]:I1027 21:31:25.032000 22397037303616 torch/_dynamo/utils.py:335] TorchDynamo compilation metrics:\n",
      "[rank1]:I1027 21:31:25.032000 22397037303616 torch/_dynamo/utils.py:335] Function    Runtimes (s)\n",
      "[rank1]:I1027 21:31:25.032000 22397037303616 torch/_dynamo/utils.py:335] ----------  --------------\n",
      "[rank0]: Traceback (most recent call last):\n",
      "[rank0]:   File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "[rank0]:   File \"<frozen runpy>\", line 88, in _run_code\n",
      "[rank0]:   File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py\", line 362, in <module>\n",
      "[rank0]:     main(args)\n",
      "[rank0]:   File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py\", line 199, in main\n",
      "[rank0]:     adapt_utils.Rep_AdaptWeight(model.module.model, args)\n",
      "[rank0]:   File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/clip2/loralib/utils.py\", line 124, in Rep_AdaptWeight\n",
      "[rank0]:     merged_weight, _ = reparameterize(adapter_attn.d.weight.squeeze().T, adapter_attn.u.weight.squeeze().T)\n",
      "[rank0]:                                       ^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1729, in __getattr__\n",
      "[rank0]:     raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{name}'\")\n",
      "[rank0]: AttributeError: 'StochasticAdapter' object has no attribute 'd'\n",
      "[rank0]:I1027 21:31:25.090000 22998487881536 torch/_dynamo/utils.py:335] TorchDynamo compilation metrics:\n",
      "[rank0]:I1027 21:31:25.090000 22998487881536 torch/_dynamo/utils.py:335] Function    Runtimes (s)\n",
      "[rank0]:I1027 21:31:25.090000 22998487881536 torch/_dynamo/utils.py:335] ----------  --------------\n",
      "W1027 21:31:28.592000 23068408969024 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 167402 closing signal SIGTERM\n",
      "W1027 21:31:28.593000 23068408969024 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 167403 closing signal SIGTERM\n",
      "W1027 21:31:28.594000 23068408969024 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 167405 closing signal SIGTERM\n",
      "E1027 21:31:28.872000 23068408969024 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 2 (pid: 167404) of binary: /opt/anaconda3/2023.09-0/bin/python\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hbcho991/.local/bin/torchrun\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "             ^^^^^^\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 348, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/distributed/run.py\", line 901, in main\n",
      "    run(args)\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/distributed/run.py\", line 892, in run\n",
      "    elastic_launch(\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/distributed/launcher/api.py\", line 133, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/distributed/launcher/api.py\", line 264, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "src.main FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2024-10-27_21:31:28\n",
      "  host      : UTL1\n",
      "  rank      : 2 (local_rank: 2)\n",
      "  exitcode  : 1 (pid: 167404)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "!torchrun --master_port 29400 --nproc_per_node 4 -m src.main     --train-dataset=ImageNet     --epochs=10     --lr=5e-4     --wd=0     --workers=4     --batch-size=32     --model=ViT-B/16     --eval-datasets=ImageNet,ImageNetV2     --template=openai_imagenet_template     --save=./checkpoints/     --data-location=./datasets/data/     --ft_data=./datasets/csv/imagenet_classID.csv     --adapter=128,128     --drop-path=0.2     --ema=0.999     --eval-scale=0.5     --grad-clip-norm=1     --ls=0.02     --mg=0.05     --eval_epoch=0     --csv-img-key=filepath     --csv-caption-key=title     --supervised-label-key=class     --exp_name=ImageNet/R-Adapter_full_finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdb0270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671a580e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14533cfd",
   "metadata": {},
   "source": [
    "## few-shot 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2022cbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!torchrun --master_port 29400 --nproc_per_node 4 -m src.few_shot     --train-dataset=ImageNet     --epochs=50     --lr=5e-4     --wd=0     --workers=4     --batch-size=32     --model=ViT-B/16     --eval-datasets=ImageNet,ImageNetV2,ImageNetR,ImageNetSketch,ImageNetA     --template=openai_imagenet_template     --save=./checkpoints/     --data-location=./datasets/data/     --ft_data=./datasets/csv/imagenet_classID.csv     --adapter=4,4     --drop-path=0.2     --ema=0.999     --eval-scale=0.5     --grad-clip-norm=1     --ls=0.02     --mg=0.05     --csv-img-key=filepath     --csv-caption-key=title     --supervised-label-key=class     --warmup_length=0     --k=16     --exp_name=ImageNet/R-Adapter_few_shot_16shot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dd0975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94621aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4422725b",
   "metadata": {},
   "source": [
    "## base-to-novel 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7d33a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ln -s /home/dataset/flowers ./datasets/data/flowers102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127efd64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ce8552",
   "metadata": {},
   "outputs": [],
   "source": [
    "!torchrun --master_port 29400 --nproc_per_node 4 -m src.main_few_shot_novel         --train-dataset=flowers102        --epochs=101         --lr=5e-4         --wd=0         --workers=4         --batch-size=32         --model=ViT-B/16         --template=openai_imagenet_template         --save=./checkpoints/         --data-location=./datasets/data/         --adapter=4,4         --drop-path=0.2         --ema=0.9         --eval-scale=0.5         --grad-clip-norm=1         --ls=0         --mg=0.1         --csv-img-key=filepath         --csv-caption-key=title         --supervised-label-key=class         --warmup_length=500         --k=16         --save=False         --exp_name=${dataset}/R-Adapter_few_shot_16shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f92b40b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00b6ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed272ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86129bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a5b211",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radapter",
   "language": "python",
   "name": "radapter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
