{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da4a7b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a58c3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hbcho991/.conda/envs/R-Adapter/bin/python\n"
     ]
    }
   ],
   "source": [
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d7da8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd186c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a1a80f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.5\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaac3b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ln -s /home/dataset/imagenet1k/data ./datasets/data/ILSVRC2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "651cd39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cf1958c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/hbcho991/.conda/envs/R-Adapter/lib/python310.zip', '/home/hbcho991/.conda/envs/R-Adapter/lib/python3.10', '/home/hbcho991/.conda/envs/R-Adapter/lib/python3.10/lib-dynload', '', '/home/hbcho991/.conda/envs/R-Adapter/lib/python3.10/site-packages', '/home/hbcho991/.conda/envs/R-Adapter/lib/python3.10/site-packages/setuptools/_vendor']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39109c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0,'/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8327a4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd4c79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python datacreation_scripts/imagenet_csv_creator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf58796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3136caba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03ab504",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/modestyachts/ImageNetV2_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98428c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install open_clip_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf9def3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wilds braceexpand webdataset h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1fa675",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pycocotools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c664a1",
   "metadata": {},
   "source": [
    "## full-tuning 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27d8ae30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:root:The WILDS package is out of date. Your version is 1.2.2, while the latest version is 2.0.0.\n",
      "/opt/anaconda3/2023.09-0/lib/python3.11/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "INFO:root:Running with a single process. Device cuda:4.\n",
      "2024-10-28,21:17:10 | INFO | Running with a single process. Device cuda:4.\n",
      "ViT-B/32\n",
      "100%|███████████████████████████████████████| 354M/354M [00:09<00:00, 38.5MiB/s]\n",
      "INFO:root:Namespace(data_location='./datasets/data/', eval_datasets=['ImageNet', 'ImageNetV2'], train_dataset='ImageNet', template='openai_imagenet_template', classnames='openai', alpha=[0.5], exp_name='ImageNet/R-Adapter_full_finetune', results_db=None, model='ViT-B/32', use_peft=True, lora=[-1, -1], adapter=[16, 16], drop_path=0.2, ema=0.999, bma=0, eval_scale=0.5, lock_image=False, lock_text=False, unlock_proj=False, unlock_ln=False, unlock_bias=False, unlock_cls=False, lock_classifier=False, batch_size=32, eval_batch_size=32, lr=0.0005, wd=0.0, ls=0.02, mg=0.05, warmup_length=500, num_classes=1000, epochs=10, eval_epoch=0, load=None, save='expt_logs/ViT-B/32/ImageNet/R-Adapter_full_finetune/_BS32_WD0.0_LR0.0005_run1', resume=None, freeze_encoder=False, cache_dir=None, fisher=None, fisher_floor=1e-08, ft_data='./datasets/csv/imagenet_classID.csv', ce_ablation=None, dataset_type='auto', train_num_samples=None, k=None, seed=0, workers=4, csv_separator='\\t', csv_img_key='filepath', csv_caption_key='title', supervised_label_key='class', precision='amp', horovod=False, gather_with_grad=False, dist_url='env://', dist_backend='nccl', grad_clip_norm=1.0, no_set_device_rank=False, clip_load=None, wise_ft=1, wise_save=None, run=1, get_labeled_csv=False, min_lr=1e-06, scheduler='cosine', device='cuda:4', distributed=False, world_size=1, rank=0, local_rank=0, log_level=20)\n",
      "2024-10-28,21:17:23 | INFO | Namespace(data_location='./datasets/data/', eval_datasets=['ImageNet', 'ImageNetV2'], train_dataset='ImageNet', template='openai_imagenet_template', classnames='openai', alpha=[0.5], exp_name='ImageNet/R-Adapter_full_finetune', results_db=None, model='ViT-B/32', use_peft=True, lora=[-1, -1], adapter=[16, 16], drop_path=0.2, ema=0.999, bma=0, eval_scale=0.5, lock_image=False, lock_text=False, unlock_proj=False, unlock_ln=False, unlock_bias=False, unlock_cls=False, lock_classifier=False, batch_size=32, eval_batch_size=32, lr=0.0005, wd=0.0, ls=0.02, mg=0.05, warmup_length=500, num_classes=1000, epochs=10, eval_epoch=0, load=None, save='expt_logs/ViT-B/32/ImageNet/R-Adapter_full_finetune/_BS32_WD0.0_LR0.0005_run1', resume=None, freeze_encoder=False, cache_dir=None, fisher=None, fisher_floor=1e-08, ft_data='./datasets/csv/imagenet_classID.csv', ce_ablation=None, dataset_type='auto', train_num_samples=None, k=None, seed=0, workers=4, csv_separator='\\t', csv_img_key='filepath', csv_caption_key='title', supervised_label_key='class', precision='amp', horovod=False, gather_with_grad=False, dist_url='env://', dist_backend='nccl', grad_clip_norm=1.0, no_set_device_rank=False, clip_load=None, wise_ft=1, wise_save=None, run=1, get_labeled_csv=False, min_lr=1e-06, scheduler='cosine', device='cuda:4', distributed=False, world_size=1, rank=0, local_rank=0, log_level=20)\n",
      "INFO:root:Fine-tuning Using R-Adapter\n",
      "2024-10-28,21:17:23 | INFO | Fine-tuning Using R-Adapter\n",
      "INFO:root:Training dataset ImageNet\n",
      "2024-10-28,21:17:23 | INFO | Training dataset ImageNet\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.0.adapter_attn.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.0.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.0.adapter_attn.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.0.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.0.adapter_attn.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.0.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.0.adapter_mlp.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.0.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.0.adapter_mlp.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.0.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.0.adapter_mlp.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.0.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.1.adapter_attn.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.1.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.1.adapter_attn.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.1.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.1.adapter_attn.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.1.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.1.adapter_mlp.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.1.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.1.adapter_mlp.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.1.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.1.adapter_mlp.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.1.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.2.adapter_attn.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.2.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.2.adapter_attn.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.2.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.2.adapter_attn.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.2.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.2.adapter_mlp.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.2.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.2.adapter_mlp.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.2.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.2.adapter_mlp.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.2.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.3.adapter_attn.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.3.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.3.adapter_attn.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.3.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.3.adapter_attn.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.3.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.3.adapter_mlp.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.3.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.3.adapter_mlp.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.3.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.3.adapter_mlp.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.3.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.4.adapter_attn.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.4.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.4.adapter_attn.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.4.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.4.adapter_attn.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.4.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.4.adapter_mlp.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.4.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.4.adapter_mlp.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.4.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.4.adapter_mlp.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.4.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.5.adapter_attn.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.5.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.5.adapter_attn.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.5.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.5.adapter_attn.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.5.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.5.adapter_mlp.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.5.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.5.adapter_mlp.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.5.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.5.adapter_mlp.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.5.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.6.adapter_attn.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.6.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.6.adapter_attn.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.6.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.6.adapter_attn.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.6.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.6.adapter_mlp.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.6.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.6.adapter_mlp.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.6.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.6.adapter_mlp.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.6.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.7.adapter_attn.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.7.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.7.adapter_attn.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.7.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.7.adapter_attn.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.7.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.7.adapter_mlp.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.7.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.7.adapter_mlp.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.7.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.7.adapter_mlp.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.7.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.8.adapter_attn.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.8.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.8.adapter_attn.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.8.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.8.adapter_attn.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.8.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.8.adapter_mlp.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.8.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.8.adapter_mlp.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.8.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.8.adapter_mlp.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.8.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.9.adapter_attn.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.9.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.9.adapter_attn.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.9.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.9.adapter_attn.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.9.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.9.adapter_mlp.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.9.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.9.adapter_mlp.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.9.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.9.adapter_mlp.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.9.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.10.adapter_attn.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.10.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.10.adapter_attn.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.10.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.10.adapter_attn.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.10.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.10.adapter_mlp.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.10.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.10.adapter_mlp.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.10.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.10.adapter_mlp.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.10.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.11.adapter_attn.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.11.adapter_attn.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.11.adapter_attn.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.11.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.11.adapter_attn.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.11.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.11.adapter_mlp.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.11.adapter_mlp.s\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.11.adapter_mlp.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.11.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.visual.transformer.resblocks.11.adapter_mlp.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.visual.transformer.resblocks.11.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.0.adapter_attn.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.0.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.0.adapter_attn.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.0.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.0.adapter_attn.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.0.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.0.adapter_mlp.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.0.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.0.adapter_mlp.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.0.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.0.adapter_mlp.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.0.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.1.adapter_attn.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.1.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.1.adapter_attn.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.1.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.1.adapter_attn.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.1.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.1.adapter_mlp.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.1.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.1.adapter_mlp.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.1.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.1.adapter_mlp.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.1.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.2.adapter_attn.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.2.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.2.adapter_attn.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.2.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.2.adapter_attn.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.2.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.2.adapter_mlp.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.2.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.2.adapter_mlp.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.2.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.2.adapter_mlp.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.2.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.3.adapter_attn.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.3.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.3.adapter_attn.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.3.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.3.adapter_attn.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.3.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.3.adapter_mlp.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.3.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.3.adapter_mlp.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.3.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.3.adapter_mlp.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.3.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.4.adapter_attn.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.4.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.4.adapter_attn.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.4.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.4.adapter_attn.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.4.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.4.adapter_mlp.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.4.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.4.adapter_mlp.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.4.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.4.adapter_mlp.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.4.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.5.adapter_attn.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.5.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.5.adapter_attn.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.5.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.5.adapter_attn.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.5.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.5.adapter_mlp.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.5.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.5.adapter_mlp.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.5.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.5.adapter_mlp.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.5.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.6.adapter_attn.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.6.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.6.adapter_attn.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.6.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.6.adapter_attn.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.6.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.6.adapter_mlp.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.6.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.6.adapter_mlp.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.6.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.6.adapter_mlp.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.6.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.7.adapter_attn.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.7.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.7.adapter_attn.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.7.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.7.adapter_attn.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.7.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.7.adapter_mlp.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.7.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.7.adapter_mlp.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.7.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.7.adapter_mlp.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.7.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.8.adapter_attn.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.8.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.8.adapter_attn.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.8.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.8.adapter_attn.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.8.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.8.adapter_mlp.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.8.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.8.adapter_mlp.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.8.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.8.adapter_mlp.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.8.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.9.adapter_attn.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.9.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.9.adapter_attn.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.9.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.9.adapter_attn.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.9.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.9.adapter_mlp.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.9.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.9.adapter_mlp.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.9.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.9.adapter_mlp.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.9.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.10.adapter_attn.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.10.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.10.adapter_attn.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.10.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.10.adapter_attn.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.10.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.10.adapter_mlp.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.10.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.10.adapter_mlp.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.10.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.10.adapter_mlp.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.10.adapter_mlp.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.11.adapter_attn.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.11.adapter_attn.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.11.adapter_attn.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.11.adapter_attn.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.11.adapter_attn.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.11.adapter_attn.u.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.11.adapter_mlp.s\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.11.adapter_mlp.s\n",
      "INFO:root:Train: module.model.transformer.resblocks.11.adapter_mlp.d.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.11.adapter_mlp.d.weight\n",
      "INFO:root:Train: module.model.transformer.resblocks.11.adapter_mlp.u.weight\n",
      "2024-10-28,21:19:09 | INFO | Train: module.model.transformer.resblocks.11.adapter_mlp.u.weight\n",
      "INFO:root:Num_params: 0.98M\n",
      "2024-10-28,21:19:09 | INFO | Num_params: 0.98M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py:138: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler() if args.precision == \"amp\" else None\n",
      "INFO:root:Start epoch 0\n",
      "2024-10-28,21:19:10 | INFO | Start epoch 0\n",
      "/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py:287: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "INFO:root:Train Epoch: 0 [     32/1281167 (0%)] Data (t): 0.000 Batch (t): 0.110, 290.690/s LR: 0.000002 Logit Scale: 100.000 Loss: 2.1933 (2.1933)\n",
      "2024-10-28,21:19:17 | INFO | Train Epoch: 0 [     32/1281167 (0%)] Data (t): 0.000 Batch (t): 0.110, 290.690/s LR: 0.000002 Logit Scale: 100.000 Loss: 2.1933 (2.1933)\n",
      "INFO:root:Train Epoch: 0 [  16032/1281167 (1%)] Data (t): 0.000 Batch (t): 0.056, 573.117/s LR: 0.000501 Logit Scale: 100.000 Loss: 1.3069 (1.7501)\n",
      "2024-10-28,21:19:51 | INFO | Train Epoch: 0 [  16032/1281167 (1%)] Data (t): 0.000 Batch (t): 0.056, 573.117/s LR: 0.000501 Logit Scale: 100.000 Loss: 1.3069 (1.7501)\n",
      "INFO:root:Train Epoch: 0 [  32032/1281167 (3%)] Data (t): 0.000 Batch (t): 0.055, 584.521/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.69787 (1.3993)\n",
      "2024-10-28,21:20:19 | INFO | Train Epoch: 0 [  32032/1281167 (3%)] Data (t): 0.000 Batch (t): 0.055, 584.521/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.69787 (1.3993)\n",
      "INFO:root:Train Epoch: 0 [  48032/1281167 (4%)] Data (t): 0.000 Batch (t): 0.053, 608.576/s LR: 0.000501 Logit Scale: 100.000 Loss: 1.3005 (1.3746)\n",
      "2024-10-28,21:20:46 | INFO | Train Epoch: 0 [  48032/1281167 (4%)] Data (t): 0.000 Batch (t): 0.053, 608.576/s LR: 0.000501 Logit Scale: 100.000 Loss: 1.3005 (1.3746)\n",
      "INFO:root:Train Epoch: 0 [  64032/1281167 (5%)] Data (t): 0.000 Batch (t): 0.053, 609.432/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.74804 (1.2493)\n",
      "2024-10-28,21:21:14 | INFO | Train Epoch: 0 [  64032/1281167 (5%)] Data (t): 0.000 Batch (t): 0.053, 609.432/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.74804 (1.2493)\n",
      "INFO:root:Train Epoch: 0 [  80032/1281167 (6%)] Data (t): 0.000 Batch (t): 0.052, 610.752/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.77062 (1.1695)\n",
      "2024-10-28,21:21:42 | INFO | Train Epoch: 0 [  80032/1281167 (6%)] Data (t): 0.000 Batch (t): 0.052, 610.752/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.77062 (1.1695)\n",
      "INFO:root:Train Epoch: 0 [  96032/1281167 (7%)] Data (t): 0.000 Batch (t): 0.051, 624.853/s LR: 0.000501 Logit Scale: 100.000 Loss: 1.1713 (1.1698)\n",
      "2024-10-28,21:22:10 | INFO | Train Epoch: 0 [  96032/1281167 (7%)] Data (t): 0.000 Batch (t): 0.051, 624.853/s LR: 0.000501 Logit Scale: 100.000 Loss: 1.1713 (1.1698)\n",
      "INFO:root:Train Epoch: 0 [ 112032/1281167 (9%)] Data (t): 0.000 Batch (t): 0.051, 626.694/s LR: 0.000501 Logit Scale: 100.000 Loss: 1.2151 (1.1754)\n",
      "2024-10-28,21:22:37 | INFO | Train Epoch: 0 [ 112032/1281167 (9%)] Data (t): 0.000 Batch (t): 0.051, 626.694/s LR: 0.000501 Logit Scale: 100.000 Loss: 1.2151 (1.1754)\n",
      "INFO:root:Train Epoch: 0 [ 128032/1281167 (10%)] Data (t): 0.000 Batch (t): 0.057, 563.301/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.44504 (1.0943)\n",
      "2024-10-28,21:23:05 | INFO | Train Epoch: 0 [ 128032/1281167 (10%)] Data (t): 0.000 Batch (t): 0.057, 563.301/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.44504 (1.0943)\n",
      "INFO:root:Train Epoch: 0 [ 144032/1281167 (11%)] Data (t): 0.000 Batch (t): 0.056, 571.691/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.49418 (1.0343)\n",
      "2024-10-28,21:23:35 | INFO | Train Epoch: 0 [ 144032/1281167 (11%)] Data (t): 0.000 Batch (t): 0.056, 571.691/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.49418 (1.0343)\n",
      "INFO:root:Train Epoch: 0 [ 160032/1281167 (12%)] Data (t): 0.000 Batch (t): 0.055, 578.049/s LR: 0.000501 Logit Scale: 100.000 Loss: 1.1551 (1.0453)\n",
      "2024-10-28,21:24:03 | INFO | Train Epoch: 0 [ 160032/1281167 (12%)] Data (t): 0.000 Batch (t): 0.055, 578.049/s LR: 0.000501 Logit Scale: 100.000 Loss: 1.1551 (1.0453)\n",
      "INFO:root:Train Epoch: 0 [ 176032/1281167 (14%)] Data (t): 0.000 Batch (t): 0.057, 562.350/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.76138 (1.0216)\n",
      "2024-10-28,21:24:33 | INFO | Train Epoch: 0 [ 176032/1281167 (14%)] Data (t): 0.000 Batch (t): 0.057, 562.350/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.76138 (1.0216)\n",
      "INFO:root:Train Epoch: 0 [ 192032/1281167 (15%)] Data (t): 0.000 Batch (t): 0.051, 628.046/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.51418 (0.98257)\n",
      "2024-10-28,21:25:02 | INFO | Train Epoch: 0 [ 192032/1281167 (15%)] Data (t): 0.000 Batch (t): 0.051, 628.046/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.51418 (0.98257)\n",
      "INFO:root:Train Epoch: 0 [ 208032/1281167 (16%)] Data (t): 0.000 Batch (t): 0.050, 644.444/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.52244 (0.94970)\n",
      "2024-10-28,21:25:30 | INFO | Train Epoch: 0 [ 208032/1281167 (16%)] Data (t): 0.000 Batch (t): 0.050, 644.444/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.52244 (0.94970)\n",
      "INFO:root:Train Epoch: 0 [ 224032/1281167 (17%)] Data (t): 0.000 Batch (t): 0.053, 600.718/s LR: 0.000501 Logit Scale: 100.000 Loss: 1.0343 (0.95534)\n",
      "2024-10-28,21:25:59 | INFO | Train Epoch: 0 [ 224032/1281167 (17%)] Data (t): 0.000 Batch (t): 0.053, 600.718/s LR: 0.000501 Logit Scale: 100.000 Loss: 1.0343 (0.95534)\n",
      "INFO:root:Train Epoch: 0 [ 240032/1281167 (19%)] Data (t): 0.000 Batch (t): 0.053, 602.643/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.48200 (0.92576)\n",
      "2024-10-28,21:26:28 | INFO | Train Epoch: 0 [ 240032/1281167 (19%)] Data (t): 0.000 Batch (t): 0.053, 602.643/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.48200 (0.92576)\n",
      "INFO:root:Train Epoch: 0 [ 256032/1281167 (20%)] Data (t): 0.000 Batch (t): 0.052, 620.884/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.81162 (0.91904)\n",
      "2024-10-28,21:26:57 | INFO | Train Epoch: 0 [ 256032/1281167 (20%)] Data (t): 0.000 Batch (t): 0.052, 620.884/s LR: 0.000501 Logit Scale: 100.000 Loss: 0.81162 (0.91904)\n",
      "INFO:root:Train Epoch: 0 [ 272032/1281167 (21%)] Data (t): 0.000 Batch (t): 0.056, 571.799/s LR: 0.000501 Logit Scale: 100.000 Loss: 1.4025 (0.94590)\n",
      "2024-10-28,21:27:26 | INFO | Train Epoch: 0 [ 272032/1281167 (21%)] Data (t): 0.000 Batch (t): 0.056, 571.799/s LR: 0.000501 Logit Scale: 100.000 Loss: 1.4025 (0.94590)\n",
      "INFO:root:Train Epoch: 0 [ 288032/1281167 (22%)] Data (t): 0.000 Batch (t): 0.051, 630.933/s LR: 0.000500 Logit Scale: 100.000 Loss: 1.1075 (0.95441)\n",
      "2024-10-28,21:27:54 | INFO | Train Epoch: 0 [ 288032/1281167 (22%)] Data (t): 0.000 Batch (t): 0.051, 630.933/s LR: 0.000500 Logit Scale: 100.000 Loss: 1.1075 (0.95441)\n",
      "INFO:root:Train Epoch: 0 [ 304032/1281167 (24%)] Data (t): 0.000 Batch (t): 0.067, 476.620/s LR: 0.000500 Logit Scale: 100.000 Loss: 1.1359 (0.96348)\n",
      "2024-10-28,21:28:23 | INFO | Train Epoch: 0 [ 304032/1281167 (24%)] Data (t): 0.000 Batch (t): 0.067, 476.620/s LR: 0.000500 Logit Scale: 100.000 Loss: 1.1359 (0.96348)\n",
      "INFO:root:Train Epoch: 0 [ 320032/1281167 (25%)] Data (t): 0.000 Batch (t): 0.051, 622.705/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.63873 (0.94802)\n",
      "2024-10-28,21:28:52 | INFO | Train Epoch: 0 [ 320032/1281167 (25%)] Data (t): 0.000 Batch (t): 0.051, 622.705/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.63873 (0.94802)\n",
      "INFO:root:Train Epoch: 0 [ 336032/1281167 (26%)] Data (t): 0.000 Batch (t): 0.050, 640.401/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.76745 (0.93981)\n",
      "2024-10-28,21:29:20 | INFO | Train Epoch: 0 [ 336032/1281167 (26%)] Data (t): 0.000 Batch (t): 0.050, 640.401/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.76745 (0.93981)\n",
      "INFO:root:Train Epoch: 0 [ 352032/1281167 (27%)] Data (t): 0.000 Batch (t): 0.054, 590.417/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.90831 (0.93844)\n",
      "2024-10-28,21:29:49 | INFO | Train Epoch: 0 [ 352032/1281167 (27%)] Data (t): 0.000 Batch (t): 0.054, 590.417/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.90831 (0.93844)\n",
      "INFO:root:Train Epoch: 0 [ 368032/1281167 (29%)] Data (t): 0.000 Batch (t): 0.052, 615.491/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.79605 (0.93251)\n",
      "2024-10-28,21:30:17 | INFO | Train Epoch: 0 [ 368032/1281167 (29%)] Data (t): 0.000 Batch (t): 0.052, 615.491/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.79605 (0.93251)\n",
      "INFO:root:Train Epoch: 0 [ 384032/1281167 (30%)] Data (t): 0.000 Batch (t): 0.051, 632.229/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.43705 (0.91269)\n",
      "2024-10-28,21:30:45 | INFO | Train Epoch: 0 [ 384032/1281167 (30%)] Data (t): 0.000 Batch (t): 0.051, 632.229/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.43705 (0.91269)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Train Epoch: 0 [ 400032/1281167 (31%)] Data (t): 0.000 Batch (t): 0.052, 612.676/s LR: 0.000500 Logit Scale: 100.000 Loss: 1.4288 (0.93254)\n",
      "2024-10-28,21:31:14 | INFO | Train Epoch: 0 [ 400032/1281167 (31%)] Data (t): 0.000 Batch (t): 0.052, 612.676/s LR: 0.000500 Logit Scale: 100.000 Loss: 1.4288 (0.93254)\n",
      "INFO:root:Train Epoch: 0 [ 416032/1281167 (32%)] Data (t): 0.000 Batch (t): 0.057, 557.832/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.82140 (0.92842)\n",
      "2024-10-28,21:31:43 | INFO | Train Epoch: 0 [ 416032/1281167 (32%)] Data (t): 0.000 Batch (t): 0.057, 557.832/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.82140 (0.92842)\n",
      "INFO:root:Train Epoch: 0 [ 432032/1281167 (34%)] Data (t): 0.000 Batch (t): 0.052, 620.646/s LR: 0.000500 Logit Scale: 100.000 Loss: 1.4547 (0.94722)\n",
      "2024-10-28,21:32:10 | INFO | Train Epoch: 0 [ 432032/1281167 (34%)] Data (t): 0.000 Batch (t): 0.052, 620.646/s LR: 0.000500 Logit Scale: 100.000 Loss: 1.4547 (0.94722)\n",
      "INFO:root:Train Epoch: 0 [ 448032/1281167 (35%)] Data (t): 0.000 Batch (t): 0.052, 611.671/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.88910 (0.94521)\n",
      "2024-10-28,21:32:37 | INFO | Train Epoch: 0 [ 448032/1281167 (35%)] Data (t): 0.000 Batch (t): 0.052, 611.671/s LR: 0.000500 Logit Scale: 100.000 Loss: 0.88910 (0.94521)\n",
      "INFO:root:Train Epoch: 0 [ 464032/1281167 (36%)] Data (t): 0.000 Batch (t): 0.051, 626.059/s LR: 0.000499 Logit Scale: 100.000 Loss: 0.96492 (0.94587)\n",
      "2024-10-28,21:33:06 | INFO | Train Epoch: 0 [ 464032/1281167 (36%)] Data (t): 0.000 Batch (t): 0.051, 626.059/s LR: 0.000499 Logit Scale: 100.000 Loss: 0.96492 (0.94587)\n",
      "INFO:root:Train Epoch: 0 [ 480032/1281167 (37%)] Data (t): 0.000 Batch (t): 0.049, 653.147/s LR: 0.000499 Logit Scale: 100.000 Loss: 0.98490 (0.94713)\n",
      "2024-10-28,21:33:34 | INFO | Train Epoch: 0 [ 480032/1281167 (37%)] Data (t): 0.000 Batch (t): 0.049, 653.147/s LR: 0.000499 Logit Scale: 100.000 Loss: 0.98490 (0.94713)\n",
      "INFO:root:Train Epoch: 0 [ 496032/1281167 (39%)] Data (t): 0.000 Batch (t): 0.052, 618.709/s LR: 0.000499 Logit Scale: 100.000 Loss: 0.68600 (0.93897)\n",
      "2024-10-28,21:34:04 | INFO | Train Epoch: 0 [ 496032/1281167 (39%)] Data (t): 0.000 Batch (t): 0.052, 618.709/s LR: 0.000499 Logit Scale: 100.000 Loss: 0.68600 (0.93897)\n",
      "INFO:root:Train Epoch: 0 [ 512032/1281167 (40%)] Data (t): 0.000 Batch (t): 0.056, 572.574/s LR: 0.000499 Logit Scale: 100.000 Loss: 1.3644 (0.95186)\n",
      "2024-10-28,21:34:33 | INFO | Train Epoch: 0 [ 512032/1281167 (40%)] Data (t): 0.000 Batch (t): 0.056, 572.574/s LR: 0.000499 Logit Scale: 100.000 Loss: 1.3644 (0.95186)\n",
      "INFO:root:Train Epoch: 0 [ 528032/1281167 (41%)] Data (t): 0.000 Batch (t): 0.053, 607.331/s LR: 0.000499 Logit Scale: 100.000 Loss: 0.69000 (0.94416)\n",
      "2024-10-28,21:35:02 | INFO | Train Epoch: 0 [ 528032/1281167 (41%)] Data (t): 0.000 Batch (t): 0.053, 607.331/s LR: 0.000499 Logit Scale: 100.000 Loss: 0.69000 (0.94416)\n",
      "INFO:root:Train Epoch: 0 [ 544032/1281167 (42%)] Data (t): 0.000 Batch (t): 0.054, 596.921/s LR: 0.000499 Logit Scale: 100.000 Loss: 1.0333 (0.94671)\n",
      "2024-10-28,21:35:31 | INFO | Train Epoch: 0 [ 544032/1281167 (42%)] Data (t): 0.000 Batch (t): 0.054, 596.921/s LR: 0.000499 Logit Scale: 100.000 Loss: 1.0333 (0.94671)\n",
      "INFO:root:Train Epoch: 0 [ 560032/1281167 (44%)] Data (t): 0.000 Batch (t): 0.052, 618.427/s LR: 0.000499 Logit Scale: 100.000 Loss: 0.55550 (0.93584)\n",
      "2024-10-28,21:35:59 | INFO | Train Epoch: 0 [ 560032/1281167 (44%)] Data (t): 0.000 Batch (t): 0.052, 618.427/s LR: 0.000499 Logit Scale: 100.000 Loss: 0.55550 (0.93584)\n",
      "INFO:root:Train Epoch: 0 [ 576032/1281167 (45%)] Data (t): 0.000 Batch (t): 0.053, 604.203/s LR: 0.000499 Logit Scale: 100.000 Loss: 0.99958 (0.93756)\n",
      "2024-10-28,21:36:27 | INFO | Train Epoch: 0 [ 576032/1281167 (45%)] Data (t): 0.000 Batch (t): 0.053, 604.203/s LR: 0.000499 Logit Scale: 100.000 Loss: 0.99958 (0.93756)\n",
      "INFO:root:Train Epoch: 0 [ 592032/1281167 (46%)] Data (t): 0.000 Batch (t): 0.052, 617.547/s LR: 0.000499 Logit Scale: 100.000 Loss: 0.41630 (0.92385)\n",
      "2024-10-28,21:36:55 | INFO | Train Epoch: 0 [ 592032/1281167 (46%)] Data (t): 0.000 Batch (t): 0.052, 617.547/s LR: 0.000499 Logit Scale: 100.000 Loss: 0.41630 (0.92385)\n",
      "INFO:root:Train Epoch: 0 [ 608032/1281167 (47%)] Data (t): 0.000 Batch (t): 0.053, 609.286/s LR: 0.000498 Logit Scale: 100.000 Loss: 1.2906 (0.93325)\n",
      "2024-10-28,21:37:25 | INFO | Train Epoch: 0 [ 608032/1281167 (47%)] Data (t): 0.000 Batch (t): 0.053, 609.286/s LR: 0.000498 Logit Scale: 100.000 Loss: 1.2906 (0.93325)\n",
      "INFO:root:Train Epoch: 0 [ 624032/1281167 (49%)] Data (t): 0.000 Batch (t): 0.057, 566.265/s LR: 0.000498 Logit Scale: 100.000 Loss: 0.51553 (0.92281)\n",
      "2024-10-28,21:37:54 | INFO | Train Epoch: 0 [ 624032/1281167 (49%)] Data (t): 0.000 Batch (t): 0.057, 566.265/s LR: 0.000498 Logit Scale: 100.000 Loss: 0.51553 (0.92281)\n",
      "INFO:root:Train Epoch: 0 [ 640032/1281167 (50%)] Data (t): 0.000 Batch (t): 0.053, 600.591/s LR: 0.000498 Logit Scale: 100.000 Loss: 0.87247 (0.92158)\n",
      "2024-10-28,21:38:22 | INFO | Train Epoch: 0 [ 640032/1281167 (50%)] Data (t): 0.000 Batch (t): 0.053, 600.591/s LR: 0.000498 Logit Scale: 100.000 Loss: 0.87247 (0.92158)\n",
      "INFO:root:Train Epoch: 0 [ 656032/1281167 (51%)] Data (t): 0.000 Batch (t): 0.055, 577.924/s LR: 0.000498 Logit Scale: 100.000 Loss: 0.45841 (0.91055)\n",
      "2024-10-28,21:38:51 | INFO | Train Epoch: 0 [ 656032/1281167 (51%)] Data (t): 0.000 Batch (t): 0.055, 577.924/s LR: 0.000498 Logit Scale: 100.000 Loss: 0.45841 (0.91055)\n",
      "INFO:root:Train Epoch: 0 [ 672032/1281167 (52%)] Data (t): 0.000 Batch (t): 0.052, 618.199/s LR: 0.000498 Logit Scale: 100.000 Loss: 1.0229 (0.91317)\n",
      "2024-10-28,21:39:19 | INFO | Train Epoch: 0 [ 672032/1281167 (52%)] Data (t): 0.000 Batch (t): 0.052, 618.199/s LR: 0.000498 Logit Scale: 100.000 Loss: 1.0229 (0.91317)\n",
      "INFO:root:Train Epoch: 0 [ 688032/1281167 (54%)] Data (t): 0.000 Batch (t): 0.055, 580.926/s LR: 0.000498 Logit Scale: 100.000 Loss: 0.65033 (0.90719)\n",
      "2024-10-28,21:39:48 | INFO | Train Epoch: 0 [ 688032/1281167 (54%)] Data (t): 0.000 Batch (t): 0.055, 580.926/s LR: 0.000498 Logit Scale: 100.000 Loss: 0.65033 (0.90719)\n",
      "INFO:root:Train Epoch: 0 [ 704032/1281167 (55%)] Data (t): 0.000 Batch (t): 0.050, 634.866/s LR: 0.000497 Logit Scale: 100.000 Loss: 0.66837 (0.90188)\n",
      "2024-10-28,21:40:16 | INFO | Train Epoch: 0 [ 704032/1281167 (55%)] Data (t): 0.000 Batch (t): 0.050, 634.866/s LR: 0.000497 Logit Scale: 100.000 Loss: 0.66837 (0.90188)\n",
      "INFO:root:Train Epoch: 0 [ 720032/1281167 (56%)] Data (t): 0.000 Batch (t): 0.054, 589.678/s LR: 0.000497 Logit Scale: 100.000 Loss: 0.78473 (0.89934)\n",
      "2024-10-28,21:40:45 | INFO | Train Epoch: 0 [ 720032/1281167 (56%)] Data (t): 0.000 Batch (t): 0.054, 589.678/s LR: 0.000497 Logit Scale: 100.000 Loss: 0.78473 (0.89934)\n",
      "INFO:root:Train Epoch: 0 [ 736032/1281167 (57%)] Data (t): 0.000 Batch (t): 0.056, 569.571/s LR: 0.000497 Logit Scale: 100.000 Loss: 0.98798 (0.90122)\n",
      "2024-10-28,21:41:14 | INFO | Train Epoch: 0 [ 736032/1281167 (57%)] Data (t): 0.000 Batch (t): 0.056, 569.571/s LR: 0.000497 Logit Scale: 100.000 Loss: 0.98798 (0.90122)\n",
      "INFO:root:Train Epoch: 0 [ 752032/1281167 (59%)] Data (t): 0.000 Batch (t): 0.053, 601.420/s LR: 0.000497 Logit Scale: 100.000 Loss: 0.57503 (0.89443)\n",
      "2024-10-28,21:41:43 | INFO | Train Epoch: 0 [ 752032/1281167 (59%)] Data (t): 0.000 Batch (t): 0.053, 601.420/s LR: 0.000497 Logit Scale: 100.000 Loss: 0.57503 (0.89443)\n",
      "INFO:root:Train Epoch: 0 [ 768032/1281167 (60%)] Data (t): 0.000 Batch (t): 0.053, 603.090/s LR: 0.000497 Logit Scale: 100.000 Loss: 0.50395 (0.88646)\n",
      "2024-10-28,21:42:12 | INFO | Train Epoch: 0 [ 768032/1281167 (60%)] Data (t): 0.000 Batch (t): 0.053, 603.090/s LR: 0.000497 Logit Scale: 100.000 Loss: 0.50395 (0.88646)\n",
      "INFO:root:Train Epoch: 0 [ 784032/1281167 (61%)] Data (t): 0.000 Batch (t): 0.057, 563.051/s LR: 0.000497 Logit Scale: 100.000 Loss: 1.0539 (0.88981)\n",
      "2024-10-28,21:42:40 | INFO | Train Epoch: 0 [ 784032/1281167 (61%)] Data (t): 0.000 Batch (t): 0.057, 563.051/s LR: 0.000497 Logit Scale: 100.000 Loss: 1.0539 (0.88981)\n",
      "INFO:root:Train Epoch: 0 [ 800032/1281167 (62%)] Data (t): 0.000 Batch (t): 0.052, 609.781/s LR: 0.000496 Logit Scale: 100.000 Loss: 1.1468 (0.89485)\n",
      "2024-10-28,21:43:08 | INFO | Train Epoch: 0 [ 800032/1281167 (62%)] Data (t): 0.000 Batch (t): 0.052, 609.781/s LR: 0.000496 Logit Scale: 100.000 Loss: 1.1468 (0.89485)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Train Epoch: 0 [ 816032/1281167 (64%)] Data (t): 0.000 Batch (t): 0.054, 594.871/s LR: 0.000496 Logit Scale: 100.000 Loss: 0.87734 (0.89451)\n",
      "2024-10-28,21:43:42 | INFO | Train Epoch: 0 [ 816032/1281167 (64%)] Data (t): 0.000 Batch (t): 0.054, 594.871/s LR: 0.000496 Logit Scale: 100.000 Loss: 0.87734 (0.89451)\n",
      "INFO:root:Train Epoch: 0 [ 832032/1281167 (65%)] Data (t): 0.000 Batch (t): 0.054, 590.622/s LR: 0.000496 Logit Scale: 100.000 Loss: 1.1380 (0.89910)\n",
      "2024-10-28,21:44:10 | INFO | Train Epoch: 0 [ 832032/1281167 (65%)] Data (t): 0.000 Batch (t): 0.054, 590.622/s LR: 0.000496 Logit Scale: 100.000 Loss: 1.1380 (0.89910)\n",
      "INFO:root:Train Epoch: 0 [ 848032/1281167 (66%)] Data (t): 0.000 Batch (t): 0.052, 613.138/s LR: 0.000496 Logit Scale: 100.000 Loss: 0.57093 (0.89303)\n",
      "2024-10-28,21:44:38 | INFO | Train Epoch: 0 [ 848032/1281167 (66%)] Data (t): 0.000 Batch (t): 0.052, 613.138/s LR: 0.000496 Logit Scale: 100.000 Loss: 0.57093 (0.89303)\n",
      "INFO:root:Train Epoch: 0 [ 864032/1281167 (67%)] Data (t): 0.000 Batch (t): 0.050, 634.980/s LR: 0.000496 Logit Scale: 100.000 Loss: 0.52716 (0.88638)\n",
      "2024-10-28,21:45:06 | INFO | Train Epoch: 0 [ 864032/1281167 (67%)] Data (t): 0.000 Batch (t): 0.050, 634.980/s LR: 0.000496 Logit Scale: 100.000 Loss: 0.52716 (0.88638)\n",
      "INFO:root:Train Epoch: 0 [ 880032/1281167 (69%)] Data (t): 0.000 Batch (t): 0.054, 594.286/s LR: 0.000495 Logit Scale: 100.000 Loss: 0.85440 (0.88580)\n",
      "2024-10-28,21:45:34 | INFO | Train Epoch: 0 [ 880032/1281167 (69%)] Data (t): 0.000 Batch (t): 0.054, 594.286/s LR: 0.000495 Logit Scale: 100.000 Loss: 0.85440 (0.88580)\n",
      "INFO:root:Train Epoch: 0 [ 896032/1281167 (70%)] Data (t): 0.000 Batch (t): 0.057, 562.442/s LR: 0.000495 Logit Scale: 100.000 Loss: 1.0572 (0.88881)\n",
      "2024-10-28,21:46:04 | INFO | Train Epoch: 0 [ 896032/1281167 (70%)] Data (t): 0.000 Batch (t): 0.057, 562.442/s LR: 0.000495 Logit Scale: 100.000 Loss: 1.0572 (0.88881)\n",
      "INFO:root:Train Epoch: 0 [ 912032/1281167 (71%)] Data (t): 0.000 Batch (t): 0.055, 582.509/s LR: 0.000495 Logit Scale: 100.000 Loss: 0.95322 (0.88992)\n",
      "2024-10-28,21:46:33 | INFO | Train Epoch: 0 [ 912032/1281167 (71%)] Data (t): 0.000 Batch (t): 0.055, 582.509/s LR: 0.000495 Logit Scale: 100.000 Loss: 0.95322 (0.88992)\n",
      "INFO:root:Train Epoch: 0 [ 928032/1281167 (72%)] Data (t): 0.000 Batch (t): 0.052, 614.418/s LR: 0.000495 Logit Scale: 100.000 Loss: 0.88971 (0.88992)\n",
      "2024-10-28,21:47:01 | INFO | Train Epoch: 0 [ 928032/1281167 (72%)] Data (t): 0.000 Batch (t): 0.052, 614.418/s LR: 0.000495 Logit Scale: 100.000 Loss: 0.88971 (0.88992)\n",
      "INFO:root:Train Epoch: 0 [ 944032/1281167 (74%)] Data (t): 0.000 Batch (t): 0.051, 626.989/s LR: 0.000495 Logit Scale: 100.000 Loss: 0.76367 (0.88781)\n",
      "2024-10-28,21:47:30 | INFO | Train Epoch: 0 [ 944032/1281167 (74%)] Data (t): 0.000 Batch (t): 0.051, 626.989/s LR: 0.000495 Logit Scale: 100.000 Loss: 0.76367 (0.88781)\n",
      "INFO:root:Train Epoch: 0 [ 960032/1281167 (75%)] Data (t): 0.000 Batch (t): 0.052, 613.729/s LR: 0.000494 Logit Scale: 100.000 Loss: 0.60655 (0.88320)\n",
      "2024-10-28,21:47:58 | INFO | Train Epoch: 0 [ 960032/1281167 (75%)] Data (t): 0.000 Batch (t): 0.052, 613.729/s LR: 0.000494 Logit Scale: 100.000 Loss: 0.60655 (0.88320)\n",
      "INFO:root:Train Epoch: 0 [ 976032/1281167 (76%)] Data (t): 0.000 Batch (t): 0.053, 602.295/s LR: 0.000494 Logit Scale: 100.000 Loss: 0.86184 (0.88286)\n",
      "2024-10-28,21:48:26 | INFO | Train Epoch: 0 [ 976032/1281167 (76%)] Data (t): 0.000 Batch (t): 0.053, 602.295/s LR: 0.000494 Logit Scale: 100.000 Loss: 0.86184 (0.88286)\n",
      "INFO:root:Train Epoch: 0 [ 992032/1281167 (77%)] Data (t): 0.000 Batch (t): 0.052, 615.288/s LR: 0.000494 Logit Scale: 100.000 Loss: 0.89421 (0.88304)\n",
      "2024-10-28,21:48:55 | INFO | Train Epoch: 0 [ 992032/1281167 (77%)] Data (t): 0.000 Batch (t): 0.052, 615.288/s LR: 0.000494 Logit Scale: 100.000 Loss: 0.89421 (0.88304)\n",
      "INFO:root:Train Epoch: 0 [1008032/1281167 (79%)] Data (t): 0.000 Batch (t): 0.053, 607.669/s LR: 0.000494 Logit Scale: 100.000 Loss: 0.64301 (0.87929)\n",
      "2024-10-28,21:49:23 | INFO | Train Epoch: 0 [1008032/1281167 (79%)] Data (t): 0.000 Batch (t): 0.053, 607.669/s LR: 0.000494 Logit Scale: 100.000 Loss: 0.64301 (0.87929)\n",
      "INFO:root:Train Epoch: 0 [1024032/1281167 (80%)] Data (t): 0.000 Batch (t): 0.051, 631.435/s LR: 0.000493 Logit Scale: 100.000 Loss: 1.3702 (0.88684)\n",
      "2024-10-28,21:49:51 | INFO | Train Epoch: 0 [1024032/1281167 (80%)] Data (t): 0.000 Batch (t): 0.051, 631.435/s LR: 0.000493 Logit Scale: 100.000 Loss: 1.3702 (0.88684)\n",
      "INFO:root:Train Epoch: 0 [1040032/1281167 (81%)] Data (t): 0.000 Batch (t): 0.063, 508.948/s LR: 0.000493 Logit Scale: 100.000 Loss: 0.54795 (0.88170)\n",
      "2024-10-28,21:50:19 | INFO | Train Epoch: 0 [1040032/1281167 (81%)] Data (t): 0.000 Batch (t): 0.063, 508.948/s LR: 0.000493 Logit Scale: 100.000 Loss: 0.54795 (0.88170)\n",
      "INFO:root:Train Epoch: 0 [1056032/1281167 (82%)] Data (t): 0.000 Batch (t): 0.052, 610.822/s LR: 0.000493 Logit Scale: 100.000 Loss: 0.57114 (0.87707)\n",
      "2024-10-28,21:50:47 | INFO | Train Epoch: 0 [1056032/1281167 (82%)] Data (t): 0.000 Batch (t): 0.052, 610.822/s LR: 0.000493 Logit Scale: 100.000 Loss: 0.57114 (0.87707)\n",
      "INFO:root:Train Epoch: 0 [1072032/1281167 (84%)] Data (t): 0.000 Batch (t): 0.051, 628.716/s LR: 0.000493 Logit Scale: 100.000 Loss: 1.1143 (0.88056)\n",
      "2024-10-28,21:51:15 | INFO | Train Epoch: 0 [1072032/1281167 (84%)] Data (t): 0.000 Batch (t): 0.051, 628.716/s LR: 0.000493 Logit Scale: 100.000 Loss: 1.1143 (0.88056)\n",
      "INFO:root:Train Epoch: 0 [1088032/1281167 (85%)] Data (t): 0.000 Batch (t): 0.050, 635.519/s LR: 0.000492 Logit Scale: 100.000 Loss: 0.53901 (0.87561)\n",
      "2024-10-28,21:51:43 | INFO | Train Epoch: 0 [1088032/1281167 (85%)] Data (t): 0.000 Batch (t): 0.050, 635.519/s LR: 0.000492 Logit Scale: 100.000 Loss: 0.53901 (0.87561)\n",
      "INFO:root:Train Epoch: 0 [1104032/1281167 (86%)] Data (t): 0.000 Batch (t): 0.052, 618.019/s LR: 0.000492 Logit Scale: 100.000 Loss: 1.4539 (0.88387)\n",
      "2024-10-28,21:52:12 | INFO | Train Epoch: 0 [1104032/1281167 (86%)] Data (t): 0.000 Batch (t): 0.052, 618.019/s LR: 0.000492 Logit Scale: 100.000 Loss: 1.4539 (0.88387)\n",
      "INFO:root:Train Epoch: 0 [1120032/1281167 (87%)] Data (t): 0.000 Batch (t): 0.051, 628.881/s LR: 0.000492 Logit Scale: 100.000 Loss: 0.83269 (0.88315)\n",
      "2024-10-28,21:52:42 | INFO | Train Epoch: 0 [1120032/1281167 (87%)] Data (t): 0.000 Batch (t): 0.051, 628.881/s LR: 0.000492 Logit Scale: 100.000 Loss: 0.83269 (0.88315)\n",
      "INFO:root:Train Epoch: 0 [1136032/1281167 (89%)] Data (t): 0.000 Batch (t): 0.050, 639.099/s LR: 0.000492 Logit Scale: 100.000 Loss: 0.86842 (0.88294)\n",
      "2024-10-28,21:53:10 | INFO | Train Epoch: 0 [1136032/1281167 (89%)] Data (t): 0.000 Batch (t): 0.050, 639.099/s LR: 0.000492 Logit Scale: 100.000 Loss: 0.86842 (0.88294)\n",
      "INFO:root:Train Epoch: 0 [1152032/1281167 (90%)] Data (t): 0.000 Batch (t): 0.052, 619.237/s LR: 0.000491 Logit Scale: 100.000 Loss: 0.79324 (0.88171)\n",
      "2024-10-28,21:53:38 | INFO | Train Epoch: 0 [1152032/1281167 (90%)] Data (t): 0.000 Batch (t): 0.052, 619.237/s LR: 0.000491 Logit Scale: 100.000 Loss: 0.79324 (0.88171)\n",
      "INFO:root:Train Epoch: 0 [1168032/1281167 (91%)] Data (t): 0.000 Batch (t): 0.052, 610.636/s LR: 0.000491 Logit Scale: 100.000 Loss: 0.52121 (0.87684)\n",
      "2024-10-28,21:54:06 | INFO | Train Epoch: 0 [1168032/1281167 (91%)] Data (t): 0.000 Batch (t): 0.052, 610.636/s LR: 0.000491 Logit Scale: 100.000 Loss: 0.52121 (0.87684)\n",
      "INFO:root:Train Epoch: 0 [1184032/1281167 (92%)] Data (t): 0.000 Batch (t): 0.056, 566.496/s LR: 0.000491 Logit Scale: 100.000 Loss: 0.81927 (0.87607)\n",
      "2024-10-28,21:54:35 | INFO | Train Epoch: 0 [1184032/1281167 (92%)] Data (t): 0.000 Batch (t): 0.056, 566.496/s LR: 0.000491 Logit Scale: 100.000 Loss: 0.81927 (0.87607)\n",
      "INFO:root:Train Epoch: 0 [1200032/1281167 (94%)] Data (t): 0.000 Batch (t): 0.051, 633.452/s LR: 0.000491 Logit Scale: 100.000 Loss: 0.97522 (0.87738)\n",
      "2024-10-28,21:55:04 | INFO | Train Epoch: 0 [1200032/1281167 (94%)] Data (t): 0.000 Batch (t): 0.051, 633.452/s LR: 0.000491 Logit Scale: 100.000 Loss: 0.97522 (0.87738)\n",
      "INFO:root:Train Epoch: 0 [1216032/1281167 (95%)] Data (t): 0.000 Batch (t): 0.052, 616.679/s LR: 0.000490 Logit Scale: 100.000 Loss: 1.1641 (0.88110)\n",
      "2024-10-28,21:55:33 | INFO | Train Epoch: 0 [1216032/1281167 (95%)] Data (t): 0.000 Batch (t): 0.052, 616.679/s LR: 0.000490 Logit Scale: 100.000 Loss: 1.1641 (0.88110)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Train Epoch: 0 [1232032/1281167 (96%)] Data (t): 0.000 Batch (t): 0.052, 610.541/s LR: 0.000490 Logit Scale: 100.000 Loss: 0.58050 (0.87725)\n",
      "2024-10-28,21:56:01 | INFO | Train Epoch: 0 [1232032/1281167 (96%)] Data (t): 0.000 Batch (t): 0.052, 610.541/s LR: 0.000490 Logit Scale: 100.000 Loss: 0.58050 (0.87725)\n",
      "INFO:root:Train Epoch: 0 [1248032/1281167 (97%)] Data (t): 0.000 Batch (t): 0.050, 636.399/s LR: 0.000490 Logit Scale: 100.000 Loss: 0.51101 (0.87261)\n",
      "2024-10-28,21:56:29 | INFO | Train Epoch: 0 [1248032/1281167 (97%)] Data (t): 0.000 Batch (t): 0.050, 636.399/s LR: 0.000490 Logit Scale: 100.000 Loss: 0.51101 (0.87261)\n",
      "INFO:root:Train Epoch: 0 [1264032/1281167 (99%)] Data (t): 0.000 Batch (t): 0.051, 623.228/s LR: 0.000489 Logit Scale: 100.000 Loss: 0.73034 (0.87083)\n",
      "2024-10-28,21:56:58 | INFO | Train Epoch: 0 [1264032/1281167 (99%)] Data (t): 0.000 Batch (t): 0.051, 623.228/s LR: 0.000489 Logit Scale: 100.000 Loss: 0.73034 (0.87083)\n",
      "INFO:root:Train Epoch: 0 [1280032/1281167 (100%)] Data (t): 0.000 Batch (t): 0.050, 636.827/s LR: 0.000489 Logit Scale: 100.000 Loss: 0.47351 (0.86593)\n",
      "2024-10-28,21:57:27 | INFO | Train Epoch: 0 [1280032/1281167 (100%)] Data (t): 0.000 Batch (t): 0.050, 636.827/s LR: 0.000489 Logit Scale: 100.000 Loss: 0.47351 (0.86593)\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py\", line 362, in <module>\n",
      "    main(args)\n",
      "  File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/src/main.py\", line 199, in main\n",
      "    adapt_utils.Rep_AdaptWeight(model.module.model, args)\n",
      "  File \"/home/hbcho991/R-Adapter/R-Adapter-ECCV2024/clip2/loralib/utils.py\", line 129, in Rep_AdaptWeight\n",
      "    rep_attn_weight, rep_attn_bias = reparameterize(_.attn.out_proj.weight.T, adapt_attn_weight.T, _.attn.out_proj.bias, adapt_attn_bias)\n",
      "                                                    ^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'attn'\n",
      "I1028 21:57:31.369000 22359806076736 torch/_dynamo/utils.py:335] TorchDynamo compilation metrics:\n",
      "I1028 21:57:31.369000 22359806076736 torch/_dynamo/utils.py:335] Function    Runtimes (s)\n",
      "I1028 21:57:31.369000 22359806076736 torch/_dynamo/utils.py:335] ----------  --------------\n",
      "E1028 21:57:36.974000 23377559217984 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 1218563) of binary: /opt/anaconda3/2023.09-0/bin/python\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hbcho991/.local/bin/torchrun\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "             ^^^^^^\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 348, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/distributed/run.py\", line 901, in main\n",
      "    run(args)\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/distributed/run.py\", line 892, in run\n",
      "    elastic_launch(\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/distributed/launcher/api.py\", line 133, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/distributed/launcher/api.py\", line 264, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "src.main FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2024-10-28_21:57:36\n",
      "  host      : UTL1\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 1218563)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "!torchrun --master_port 29400 --nproc_per_node 1 -m src.main     --train-dataset=ImageNet     --epochs=10     --lr=5e-4     --wd=0     --workers=4     --batch-size=32     --model=ViT-B/32     --eval-datasets=ImageNet,ImageNetV2     --template=openai_imagenet_template     --save=./checkpoints/     --data-location=./datasets/data/     --ft_data=./datasets/csv/imagenet_classID.csv     --adapter=16,16     --drop-path=0.2     --ema=0.999     --eval-scale=0.5     --grad-clip-norm=1     --ls=0.02     --mg=0.05     --eval_epoch=0     --csv-img-key=filepath     --csv-caption-key=title     --supervised-label-key=class     --exp_name=ImageNet/R-Adapter_full_finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fdb0270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct 28 20:45:33 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 4090        Off | 00000000:17:00.0 Off |                  Off |\r\n",
      "| 43%   54C    P2             183W / 450W |  16651MiB / 24564MiB |     36%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA GeForce RTX 4090        Off | 00000000:3D:00.0 Off |                  Off |\r\n",
      "| 43%   48C    P2             147W / 450W |  22209MiB / 24564MiB |     40%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   2  NVIDIA GeForce RTX 4090        Off | 00000000:50:00.0 Off |                  Off |\r\n",
      "| 69%   57C    P2             202W / 450W |  13653MiB / 24564MiB |     43%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   3  NVIDIA GeForce RTX 4090        Off | 00000000:63:00.0 Off |                  Off |\r\n",
      "| 71%   63C    P2             369W / 450W |  23359MiB / 24564MiB |    100%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   4  NVIDIA GeForce RTX 4090        Off | 00000000:99:00.0 Off |                  Off |\r\n",
      "| 33%   26C    P8              20W / 450W |      5MiB / 24564MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   5  NVIDIA GeForce RTX 4090        Off | 00000000:BD:00.0 Off |                  Off |\r\n",
      "| 38%   49C    P2             187W / 450W |  22081MiB / 24564MiB |     40%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   6  NVIDIA GeForce RTX 4090        Off | 00000000:CF:00.0 Off |                  Off |\r\n",
      "| 43%   43C    P2              69W / 450W |  11953MiB / 24564MiB |     10%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   7  NVIDIA GeForce RTX 4090        Off | 00000000:E1:00.0 Off |                  Off |\r\n",
      "| 38%   48C    P2             187W / 450W |  16627MiB / 24564MiB |     46%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A   2701535      C   ...onda/envs/incontext-diff/bin/python    16642MiB |\r\n",
      "|    1   N/A  N/A   2700938      C   ...onda/envs/incontext-diff/bin/python    22200MiB |\r\n",
      "|    2   N/A  N/A   1007800      C   python                                    13634MiB |\r\n",
      "|    3   N/A  N/A    997565      C   python                                    23346MiB |\r\n",
      "|    5   N/A  N/A   2697206      C   ...onda/envs/incontext-diff/bin/python    21960MiB |\r\n",
      "|    6   N/A  N/A   2220575      C   ...onda/envs/incontext-diff/bin/python    11942MiB |\r\n",
      "|    7   N/A  N/A   2220653      C   ...onda/envs/incontext-diff/bin/python    16618MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f124e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddff527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9684a6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14533cfd",
   "metadata": {},
   "source": [
    "## few-shot 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2022cbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!torchrun --master_port 29400 --nproc_per_node 4 -m src.few_shot     --train-dataset=ImageNet     --epochs=50     --lr=5e-4     --wd=0     --workers=4     --batch-size=32     --model=ViT-B/16     --eval-datasets=ImageNet,ImageNetV2,ImageNetR,ImageNetSketch,ImageNetA     --template=openai_imagenet_template     --save=./checkpoints/     --data-location=./datasets/data/     --ft_data=./datasets/csv/imagenet_classID.csv     --adapter=4,4     --drop-path=0.2     --ema=0.999     --eval-scale=0.5     --grad-clip-norm=1     --ls=0.02     --mg=0.05     --csv-img-key=filepath     --csv-caption-key=title     --supervised-label-key=class     --warmup_length=0     --k=16     --exp_name=ImageNet/R-Adapter_few_shot_16shot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dd0975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94621aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4422725b",
   "metadata": {},
   "source": [
    "## base-to-novel 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7d33a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ln -s /home/dataset/flowers ./datasets/data/flowers102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127efd64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ce8552",
   "metadata": {},
   "outputs": [],
   "source": [
    "!torchrun --master_port 29400 --nproc_per_node 4 -m src.main_few_shot_novel         --train-dataset=flowers102        --epochs=101         --lr=5e-4         --wd=0         --workers=4         --batch-size=32         --model=ViT-B/16         --template=openai_imagenet_template         --save=./checkpoints/         --data-location=./datasets/data/         --adapter=4,4         --drop-path=0.2         --ema=0.9         --eval-scale=0.5         --grad-clip-norm=1         --ls=0         --mg=0.1         --csv-img-key=filepath         --csv-caption-key=title         --supervised-label-key=class         --warmup_length=500         --k=16         --save=False         --exp_name=${dataset}/R-Adapter_few_shot_16shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f92b40b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00b6ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed272ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86129bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a5b211",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radapter",
   "language": "python",
   "name": "radapter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
