{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38b195b4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-tny_a3oe\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-tny_a3oe\n",
      "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: ftfy in /home/hbcho991/.local/lib/python3.11/site-packages (from clip==1.0) (6.2.3)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from clip==1.0) (23.1)\n",
      "Requirement already satisfied: regex in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from clip==1.0) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from clip==1.0) (4.65.0)\n",
      "Requirement already satisfied: torch in /home/hbcho991/.local/lib/python3.11/site-packages (from clip==1.0) (2.4.0)\n",
      "Requirement already satisfied: torchvision in /home/hbcho991/.local/lib/python3.11/site-packages (from clip==1.0) (0.19.0)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /home/hbcho991/.local/lib/python3.11/site-packages (from ftfy->clip==1.0) (0.2.13)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from torch->clip==1.0) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch->clip==1.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from torch->clip==1.0) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from torch->clip==1.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from torch->clip==1.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from torch->clip==1.0) (2023.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch->clip==1.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch->clip==1.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch->clip==1.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch->clip==1.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch->clip==1.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch->clip==1.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch->clip==1.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch->clip==1.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch->clip==1.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch->clip==1.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch->clip==1.0) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch->clip==1.0) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/hbcho991/.local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->clip==1.0) (12.6.20)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from torchvision->clip==1.0) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from torchvision->clip==1.0) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from jinja2->torch->clip==1.0) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from sympy->torch->clip==1.0) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82d0f922",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hbcho991\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d648d4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Dassl.pytorch'...\n",
      "remote: Enumerating objects: 2477, done.\u001b[K\n",
      "remote: Counting objects: 100% (993/993), done.\u001b[K\n",
      "remote: Compressing objects: 100% (288/288), done.\u001b[K\n",
      "remote: Total 2477 (delta 777), reused 861 (delta 705), pack-reused 1484 (from 1)\u001b[K\n",
      "Receiving objects: 100% (2477/2477), 428.00 KiB | 13.37 MiB/s, done.\n",
      "Resolving deltas: 100% (1658/1658), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/KaiyangZhou/Dassl.pytorch.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c084536",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting flake8==3.7.9 (from -r requirements.txt (line 1))\n",
      "  Obtaining dependency information for flake8==3.7.9 from https://files.pythonhosted.org/packages/f8/1f/7ea40d1e4146ea55dbab41cda1376db092a75794914169aabd7e8d7a7def/flake8-3.7.9-py2.py3-none-any.whl.metadata\n",
      "  Downloading flake8-3.7.9-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting yapf==0.29.0 (from -r requirements.txt (line 2))\n",
      "  Obtaining dependency information for yapf==0.29.0 from https://files.pythonhosted.org/packages/7c/21/534d143afd3df9cae9b21674fcc32207cb80cfb3de56b89ef7a37c746cca/yapf-0.29.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading yapf-0.29.0-py2.py3-none-any.whl.metadata (30 kB)\n",
      "Collecting isort==4.3.21 (from -r requirements.txt (line 3))\n",
      "  Obtaining dependency information for isort==4.3.21 from https://files.pythonhosted.org/packages/e5/b0/c121fd1fa3419ea9bfd55c7f9c4fedfec5143208d8c7ad3ce3db6c623c21/isort-4.3.21-py2.py3-none-any.whl.metadata\n",
      "  Downloading isort-4.3.21-py2.py3-none-any.whl.metadata (19 kB)\n",
      "Collecting yacs (from -r requirements.txt (line 4))\n",
      "  Obtaining dependency information for yacs from https://files.pythonhosted.org/packages/38/4f/fe9a4d472aa867878ce3bb7efb16654c5d63672b86dc0e6e953a67018433/yacs-0.1.8-py3-none-any.whl.metadata\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
      "Collecting gdown (from -r requirements.txt (line 5))\n",
      "  Obtaining dependency information for gdown from https://files.pythonhosted.org/packages/54/70/e07c381e6488a77094f04c85c9caf1c8008cdc30778f7019bc52e5285ef0/gdown-5.2.0-py3-none-any.whl.metadata\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting tb-nightly (from -r requirements.txt (line 6))\n",
      "  Obtaining dependency information for tb-nightly from https://files.pythonhosted.org/packages/75/0d/176e2da25a40b28b5a7a7e7380ec6c626409fcafacca57bc2d1720799724/tb_nightly-2.18.0a20240824-py3-none-any.whl.metadata\n",
      "  Downloading tb_nightly-2.18.0a20240824-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: future in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (0.18.3)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (1.11.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (1.3.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (4.65.0)\n",
      "Requirement already satisfied: ftfy in /home/hbcho991/.local/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (6.2.3)\n",
      "Requirement already satisfied: regex in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (2022.7.9)\n",
      "Collecting wilds==1.2.2 (from -r requirements.txt (line 13))\n",
      "  Obtaining dependency information for wilds==1.2.2 from https://files.pythonhosted.org/packages/95/40/7cd1716814fed530ec835de09217593940e391d90772cb84de67435f0ceb/wilds-1.2.2-py3-none-any.whl.metadata\n",
      "  Downloading wilds-1.2.2-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: tabulate in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from -r requirements.txt (line 14)) (0.8.10)\n",
      "Collecting entrypoints<0.4.0,>=0.3.0 (from flake8==3.7.9->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for entrypoints<0.4.0,>=0.3.0 from https://files.pythonhosted.org/packages/ac/c6/44694103f8c221443ee6b0041f69e2740d89a25641e62fb4f2ee568f2f9c/entrypoints-0.3-py2.py3-none-any.whl.metadata\n",
      "  Downloading entrypoints-0.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pyflakes<2.2.0,>=2.1.0 (from flake8==3.7.9->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for pyflakes<2.2.0,>=2.1.0 from https://files.pythonhosted.org/packages/84/f2/ed0ffb887f8138a8fe5a621b8c0bb9598bfb3989e029f6c6a85ee66628ee/pyflakes-2.1.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading pyflakes-2.1.1-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting pycodestyle<2.6.0,>=2.5.0 (from flake8==3.7.9->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for pycodestyle<2.6.0,>=2.5.0 from https://files.pythonhosted.org/packages/0e/0c/04a353e104d2f324f8ee5f4b32012618c1c86dd79e52a433b64fceed511b/pycodestyle-2.5.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading pycodestyle-2.5.0-py2.py3-none-any.whl.metadata (28 kB)\n",
      "Collecting mccabe<0.7.0,>=0.6.0 (from flake8==3.7.9->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for mccabe<0.7.0,>=0.6.0 from https://files.pythonhosted.org/packages/87/89/479dc97e18549e21354893e4ee4ef36db1d237534982482c3681ee6e7b57/mccabe-0.6.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading mccabe-0.6.1-py2.py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: numpy>=1.19.1 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from wilds==1.2.2->-r requirements.txt (line 13)) (1.24.3)\n",
      "Collecting ogb>=1.2.6 (from wilds==1.2.2->-r requirements.txt (line 13))\n",
      "  Obtaining dependency information for ogb>=1.2.6 from https://files.pythonhosted.org/packages/7e/95/e0770cf1ad9667492f56b732f44398ef2756d61df914e10d121a3cad013a/ogb-1.3.6-py3-none-any.whl.metadata\n",
      "  Downloading ogb-1.3.6-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting outdated>=0.2.0 (from wilds==1.2.2->-r requirements.txt (line 13))\n",
      "  Obtaining dependency information for outdated>=0.2.0 from https://files.pythonhosted.org/packages/d3/04/7d2b9a0d1b81e30f39e6f358bac01f4f18b585f35b0ffc5c83fc274f146b/outdated-0.2.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading outdated-0.2.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: pandas>=1.1.0 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from wilds==1.2.2->-r requirements.txt (line 13)) (2.0.3)\n",
      "Requirement already satisfied: pillow>=7.2.0 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from wilds==1.2.2->-r requirements.txt (line 13)) (9.4.0)\n",
      "Requirement already satisfied: pytz>=2020.4 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from wilds==1.2.2->-r requirements.txt (line 13)) (2023.3.post1)\n",
      "Requirement already satisfied: torch>=1.7.0 in /home/hbcho991/.local/lib/python3.11/site-packages (from wilds==1.2.2->-r requirements.txt (line 13)) (2.4.0)\n",
      "Requirement already satisfied: torchvision>=0.8.2 in /home/hbcho991/.local/lib/python3.11/site-packages (from wilds==1.2.2->-r requirements.txt (line 13)) (0.19.0)\n",
      "Requirement already satisfied: PyYAML in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from yacs->-r requirements.txt (line 4)) (6.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from gdown->-r requirements.txt (line 5)) (4.12.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from gdown->-r requirements.txt (line 5)) (3.9.0)\n",
      "Requirement already satisfied: requests[socks] in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from gdown->-r requirements.txt (line 5)) (2.31.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/hbcho991/.local/lib/python3.11/site-packages (from tb-nightly->-r requirements.txt (line 6)) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/hbcho991/.local/lib/python3.11/site-packages (from tb-nightly->-r requirements.txt (line 6)) (1.66.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from tb-nightly->-r requirements.txt (line 6)) (3.4.1)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from tb-nightly->-r requirements.txt (line 6)) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /home/hbcho991/.local/lib/python3.11/site-packages (from tb-nightly->-r requirements.txt (line 6)) (4.25.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from tb-nightly->-r requirements.txt (line 6)) (68.0.0)\n",
      "Requirement already satisfied: six>1.9 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from tb-nightly->-r requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/hbcho991/.local/lib/python3.11/site-packages (from tb-nightly->-r requirements.txt (line 6)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from tb-nightly->-r requirements.txt (line 6)) (2.2.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib>=1.1.1 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from scikit-learn->-r requirements.txt (line 9)) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from scikit-learn->-r requirements.txt (line 9)) (2.2.0)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /home/hbcho991/.local/lib/python3.11/site-packages (from ftfy->-r requirements.txt (line 11)) (0.2.13)\n",
      "Requirement already satisfied: urllib3>=1.24.0 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from ogb>=1.2.6->wilds==1.2.2->-r requirements.txt (line 13)) (1.26.16)\n",
      "Collecting littleutils (from outdated>=0.2.0->wilds==1.2.2->-r requirements.txt (line 13))\n",
      "  Obtaining dependency information for littleutils from https://files.pythonhosted.org/packages/19/ac/a89d28d7421fffc028d68cdfde5e3e056e690cb4b1bbef4a5fea661e16f5/littleutils-0.2.4-py3-none-any.whl.metadata\n",
      "  Downloading littleutils-0.2.4-py3-none-any.whl.metadata (679 bytes)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from pandas>=1.1.0->wilds==1.2.2->-r requirements.txt (line 13)) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from pandas>=1.1.0->wilds==1.2.2->-r requirements.txt (line 13)) (2023.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->-r requirements.txt (line 13)) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->-r requirements.txt (line 13)) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->-r requirements.txt (line 13)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->-r requirements.txt (line 13)) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->-r requirements.txt (line 13)) (2023.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->-r requirements.txt (line 13)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->-r requirements.txt (line 13)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->-r requirements.txt (line 13)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->-r requirements.txt (line 13)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->-r requirements.txt (line 13)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->-r requirements.txt (line 13)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->-r requirements.txt (line 13)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->-r requirements.txt (line 13)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->-r requirements.txt (line 13)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->-r requirements.txt (line 13)) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->-r requirements.txt (line 13)) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->-r requirements.txt (line 13)) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/hbcho991/.local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7.0->wilds==1.2.2->-r requirements.txt (line 13)) (12.6.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from werkzeug>=1.0.1->tb-nightly->-r requirements.txt (line 6)) (2.1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from beautifulsoup4->gdown->-r requirements.txt (line 5)) (2.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from requests[socks]->gdown->-r requirements.txt (line 5)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from requests[socks]->gdown->-r requirements.txt (line 5)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from requests[socks]->gdown->-r requirements.txt (line 5)) (2023.11.17)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from requests[socks]->gdown->-r requirements.txt (line 5)) (1.7.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from sympy->torch>=1.7.0->wilds==1.2.2->-r requirements.txt (line 13)) (1.3.0)\n",
      "Downloading flake8-3.7.9-py2.py3-none-any.whl (69 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.9/69.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yapf-0.29.0-py2.py3-none-any.whl (185 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.3/185.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading isort-4.3.21-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wilds-1.2.2-py3-none-any.whl (92 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.5/92.5 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Downloading tb_nightly-2.18.0a20240824-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading entrypoints-0.3-py2.py3-none-any.whl (11 kB)\n",
      "Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
      "Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
      "Downloading pycodestyle-2.5.0-py2.py3-none-any.whl (51 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyflakes-2.1.1-py2.py3-none-any.whl (59 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading littleutils-0.2.4-py3-none-any.whl (8.1 kB)\n",
      "Installing collected packages: yapf, mccabe, yacs, pyflakes, pycodestyle, littleutils, isort, entrypoints, tb-nightly, outdated, flake8, gdown, ogb, wilds\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autopep8 1.6.0 requires pycodestyle>=2.8.0, but you have pycodestyle 2.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed entrypoints-0.3 flake8-3.7.9 gdown-5.2.0 isort-4.3.21 littleutils-0.2.4 mccabe-0.6.1 ogb-1.3.6 outdated-0.2.2 pycodestyle-2.5.0 pyflakes-2.1.1 tb-nightly-2.18.0a20240824 wilds-1.2.2 yacs-0.1.8 yapf-0.29.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf1a830a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Processing /home/hbcho991/DAMP/Dassl.pytorch\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: flake8==3.7.9 in /home/hbcho991/.local/lib/python3.11/site-packages (from dassl==0.6.3) (3.7.9)\n",
      "Requirement already satisfied: yapf==0.29.0 in /home/hbcho991/.local/lib/python3.11/site-packages (from dassl==0.6.3) (0.29.0)\n",
      "Requirement already satisfied: isort==4.3.21 in /home/hbcho991/.local/lib/python3.11/site-packages (from dassl==0.6.3) (4.3.21)\n",
      "Requirement already satisfied: yacs in /home/hbcho991/.local/lib/python3.11/site-packages (from dassl==0.6.3) (0.1.8)\n",
      "Requirement already satisfied: gdown in /home/hbcho991/.local/lib/python3.11/site-packages (from dassl==0.6.3) (5.2.0)\n",
      "Requirement already satisfied: tb-nightly in /home/hbcho991/.local/lib/python3.11/site-packages (from dassl==0.6.3) (2.18.0a20240824)\n",
      "Requirement already satisfied: future in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from dassl==0.6.3) (0.18.3)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from dassl==0.6.3) (1.11.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from dassl==0.6.3) (1.3.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from dassl==0.6.3) (4.65.0)\n",
      "Requirement already satisfied: ftfy in /home/hbcho991/.local/lib/python3.11/site-packages (from dassl==0.6.3) (6.2.3)\n",
      "Requirement already satisfied: regex in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from dassl==0.6.3) (2022.7.9)\n",
      "Requirement already satisfied: wilds==1.2.2 in /home/hbcho991/.local/lib/python3.11/site-packages (from dassl==0.6.3) (1.2.2)\n",
      "Requirement already satisfied: tabulate in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from dassl==0.6.3) (0.8.10)\n",
      "Requirement already satisfied: entrypoints<0.4.0,>=0.3.0 in /home/hbcho991/.local/lib/python3.11/site-packages (from flake8==3.7.9->dassl==0.6.3) (0.3)\n",
      "Requirement already satisfied: pyflakes<2.2.0,>=2.1.0 in /home/hbcho991/.local/lib/python3.11/site-packages (from flake8==3.7.9->dassl==0.6.3) (2.1.1)\n",
      "Requirement already satisfied: pycodestyle<2.6.0,>=2.5.0 in /home/hbcho991/.local/lib/python3.11/site-packages (from flake8==3.7.9->dassl==0.6.3) (2.5.0)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /home/hbcho991/.local/lib/python3.11/site-packages (from flake8==3.7.9->dassl==0.6.3) (0.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.1 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from wilds==1.2.2->dassl==0.6.3) (1.24.3)\n",
      "Requirement already satisfied: ogb>=1.2.6 in /home/hbcho991/.local/lib/python3.11/site-packages (from wilds==1.2.2->dassl==0.6.3) (1.3.6)\n",
      "Requirement already satisfied: outdated>=0.2.0 in /home/hbcho991/.local/lib/python3.11/site-packages (from wilds==1.2.2->dassl==0.6.3) (0.2.2)\n",
      "Requirement already satisfied: pandas>=1.1.0 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from wilds==1.2.2->dassl==0.6.3) (2.0.3)\n",
      "Requirement already satisfied: pillow>=7.2.0 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from wilds==1.2.2->dassl==0.6.3) (9.4.0)\n",
      "Requirement already satisfied: pytz>=2020.4 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from wilds==1.2.2->dassl==0.6.3) (2023.3.post1)\n",
      "Requirement already satisfied: torch>=1.7.0 in /home/hbcho991/.local/lib/python3.11/site-packages (from wilds==1.2.2->dassl==0.6.3) (2.4.0)\n",
      "Requirement already satisfied: torchvision>=0.8.2 in /home/hbcho991/.local/lib/python3.11/site-packages (from wilds==1.2.2->dassl==0.6.3) (0.19.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from scikit-learn->dassl==0.6.3) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from scikit-learn->dassl==0.6.3) (2.2.0)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /home/hbcho991/.local/lib/python3.11/site-packages (from ftfy->dassl==0.6.3) (0.2.13)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from gdown->dassl==0.6.3) (4.12.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from gdown->dassl==0.6.3) (3.9.0)\n",
      "Requirement already satisfied: requests[socks] in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from gdown->dassl==0.6.3) (2.31.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/hbcho991/.local/lib/python3.11/site-packages (from tb-nightly->dassl==0.6.3) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/hbcho991/.local/lib/python3.11/site-packages (from tb-nightly->dassl==0.6.3) (1.66.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from tb-nightly->dassl==0.6.3) (3.4.1)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from tb-nightly->dassl==0.6.3) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /home/hbcho991/.local/lib/python3.11/site-packages (from tb-nightly->dassl==0.6.3) (4.25.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from tb-nightly->dassl==0.6.3) (68.0.0)\n",
      "Requirement already satisfied: six>1.9 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from tb-nightly->dassl==0.6.3) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/hbcho991/.local/lib/python3.11/site-packages (from tb-nightly->dassl==0.6.3) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from tb-nightly->dassl==0.6.3) (2.2.3)\n",
      "Requirement already satisfied: PyYAML in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from yacs->dassl==0.6.3) (6.0)\n",
      "Requirement already satisfied: urllib3>=1.24.0 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from ogb>=1.2.6->wilds==1.2.2->dassl==0.6.3) (1.26.16)\n",
      "Requirement already satisfied: littleutils in /home/hbcho991/.local/lib/python3.11/site-packages (from outdated>=0.2.0->wilds==1.2.2->dassl==0.6.3) (0.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from pandas>=1.1.0->wilds==1.2.2->dassl==0.6.3) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from pandas>=1.1.0->wilds==1.2.2->dassl==0.6.3) (2023.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->dassl==0.6.3) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->dassl==0.6.3) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->dassl==0.6.3) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->dassl==0.6.3) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->dassl==0.6.3) (2023.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->dassl==0.6.3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->dassl==0.6.3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->dassl==0.6.3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->dassl==0.6.3) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->dassl==0.6.3) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->dassl==0.6.3) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->dassl==0.6.3) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->dassl==0.6.3) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->dassl==0.6.3) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->dassl==0.6.3) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->dassl==0.6.3) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/hbcho991/.local/lib/python3.11/site-packages (from torch>=1.7.0->wilds==1.2.2->dassl==0.6.3) (3.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/hbcho991/.local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7.0->wilds==1.2.2->dassl==0.6.3) (12.6.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from werkzeug>=1.0.1->tb-nightly->dassl==0.6.3) (2.1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from beautifulsoup4->gdown->dassl==0.6.3) (2.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from requests[socks]->gdown->dassl==0.6.3) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from requests[socks]->gdown->dassl==0.6.3) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from requests[socks]->gdown->dassl==0.6.3) (2023.11.17)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from requests[socks]->gdown->dassl==0.6.3) (1.7.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/2023.09-0/lib/python3.11/site-packages (from sympy->torch>=1.7.0->wilds==1.2.2->dassl==0.6.3) (1.3.0)\n",
      "Building wheels for collected packages: dassl\n",
      "  Building wheel for dassl (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dassl: filename=dassl-0.6.3-py3-none-any.whl size=138531 sha256=f4138c90a4d06ee9e8d44b7d2d71c97aa8317aeda7db8e5117f5996901465a58\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ef7f3s5b/wheels/1e/c8/62/b422b029e5b9ed01f923f8e66f8a2f4b5c5faf6ea5f4669e10\n",
      "Successfully built dassl\n",
      "Installing collected packages: dassl\n",
      "Successfully installed dassl-0.6.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e724994",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hbcho991/DAMP\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "553d6ac3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'DAMP'...\n",
      "remote: Enumerating objects: 38, done.\u001b[K\n",
      "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
      "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
      "remote: Total 38 (delta 10), reused 35 (delta 7), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (38/38), 434.34 KiB | 11.14 MiB/s, done.\n",
      "Resolving deltas: 100% (10/10), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/TL-UESTC/DAMP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd84bd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  /opt/anaconda3/2023.09-0/bin/python -m pip uninstall [options] <package> ...\n",
      "  /opt/anaconda3/2023.09-0/bin/python -m pip uninstall [options] -r <requirements file> ...\n",
      "\n",
      "no such option: --Y\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall dassl --Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb4546a",
   "metadata": {},
   "source": [
    "# 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75541d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc4dec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/hbcho991/DAMP/Dassl.pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5b5e1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dassl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5068a3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7d706bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting numpy==1.23.0\n",
      "  Downloading numpy-1.23.0.tar.gz (10.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: numpy\n",
      "  Building wheel for numpy (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for numpy: filename=numpy-1.23.0-cp311-cp311-linux_x86_64.whl size=6195149 sha256=720b863259b37f76e5917ed884ade986d0a876276d73eeb157ccb5a9b31b8f13\n",
      "  Stored in directory: /home/hbcho991/.cache/pip/wheels/6d/36/1a/3ec6b85008bea3151efb003f5d41baa7bf4966cb43c1c2470b\n",
      "Successfully built numpy\n",
      "Installing collected packages: numpy\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\n",
      "tensorflow 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 1.23.0 which is incompatible.\n",
      "ml-dtypes 0.4.0 requires numpy>=1.23.3; python_version >= \"3.11\", but you have numpy 1.23.0 which is incompatible.\n",
      "daal4py 2023.1.1 requires numpy>=1.23.5; python_version >= \"3.11\", but you have numpy 1.23.0 which is incompatible.\n",
      "pandas 2.0.3 requires numpy>=1.23.2; python_version >= \"3.11\", but you have numpy 1.23.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.23.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28243221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hbcho991/DAMP/DAMP/scripts\n"
     ]
    }
   ],
   "source": [
    "cd /home/hbcho991/DAMP/DAMP/scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9016d6ac",
   "metadata": {},
   "source": [
    "## test_time 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81ec9ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-31 10:49:38.266729: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-31 10:49:38.517281: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-31 10:49:38.599925: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-31 10:49:38.622843: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-31 10:49:38.795683: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-31 10:49:39.894705: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/hbcho991/DAMP/DAMP/trainers/damp.py:196: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/home/hbcho991/DAMP/DAMP/trainers/damp.py:218: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/home/hbcho991/DAMP/DAMP/trainers/damp.py:284: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/home/hbcho991/DAMP/DAMP/trainers/damp.py:385: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/home/hbcho991/DAMP/DAMP/trainers/damp.py:425: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "['TRAINER.DAMP.TAU', '0.5', 'TRAINER.DAMP.U', '2.0']\n",
      "DATALOADER:\n",
      "  K_TRANSFORMS: 1\n",
      "  NUM_WORKERS: 4\n",
      "  RETURN_IMG0: False\n",
      "  TEST:\n",
      "    BATCH_SIZE: 128\n",
      "    SAMPLER: SequentialSampler\n",
      "  TRAIN_U:\n",
      "    BATCH_SIZE: 32\n",
      "    N_DOMAIN: 0\n",
      "    N_INS: 16\n",
      "    SAME_AS_X: True\n",
      "    SAMPLER: RandomSampler\n",
      "  TRAIN_X:\n",
      "    BATCH_SIZE: 32\n",
      "    N_DOMAIN: 0\n",
      "    N_INS: 16\n",
      "    SAMPLER: RandomSampler\n",
      "DATASET:\n",
      "  ALL_AS_UNLABELED: False\n",
      "  CIFAR_C_LEVEL: 1\n",
      "  CIFAR_C_TYPE: \n",
      "  NAME: VISDA_C\n",
      "  NUM_LABELED: -1\n",
      "  NUM_SHOTS: -1\n",
      "  ROOT: /home/dataset/\n",
      "  SOURCE_DOMAINS: ['synthetic']\n",
      "  STL10_FOLD: -1\n",
      "  TARGET_DOMAINS: ['real']\n",
      "  VAL_PERCENT: 0.1\n",
      "INPUT:\n",
      "  COLORJITTER_B: 0.4\n",
      "  COLORJITTER_C: 0.4\n",
      "  COLORJITTER_H: 0.1\n",
      "  COLORJITTER_S: 0.4\n",
      "  CROP_PADDING: 4\n",
      "  CUTOUT_LEN: 16\n",
      "  CUTOUT_N: 1\n",
      "  GB_K: 21\n",
      "  GB_P: 0.5\n",
      "  GN_MEAN: 0.0\n",
      "  GN_STD: 0.15\n",
      "  INTERPOLATION: bicubic\n",
      "  NO_TRANSFORM: False\n",
      "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
      "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
      "  RANDAUGMENT_M: 10\n",
      "  RANDAUGMENT_N: 2\n",
      "  RGS_P: 0.2\n",
      "  RRCROP_SCALE: (0.08, 1.0)\n",
      "  SIZE: (224, 224)\n",
      "  TRANSFORMS: ('normalize',)\n",
      "MODEL:\n",
      "  BACKBONE:\n",
      "    NAME: ViT-B/16\n",
      "    PATH: ./assets\n",
      "    PRETRAINED: True\n",
      "  HEAD:\n",
      "    ACTIVATION: relu\n",
      "    BN: True\n",
      "    DROPOUT: 0.0\n",
      "    HIDDEN_LAYERS: ()\n",
      "    NAME: \n",
      "  INIT_WEIGHTS: \n",
      "  INIT_WEIGHTS_CTX: None\n",
      "  INIT_WEIGHTS_PRO: None\n",
      "OPTIM:\n",
      "  ADAM_BETA1: 0.9\n",
      "  ADAM_BETA2: 0.999\n",
      "  BASE_LR_MULT: 0.1\n",
      "  GAMMA: 0.1\n",
      "  LR: 0.003\n",
      "  LR_SCHEDULER: cosine\n",
      "  MAX_EPOCH: 30\n",
      "  MOMENTUM: 0.9\n",
      "  NAME: adam\n",
      "  NEW_LAYERS: ()\n",
      "  RMSPROP_ALPHA: 0.99\n",
      "  SGD_DAMPNING: 0\n",
      "  SGD_NESTEROV: False\n",
      "  STAGED_LR: False\n",
      "  STEPSIZE: (-1,)\n",
      "  WARMUP_CONS_LR: 1e-05\n",
      "  WARMUP_EPOCH: 1\n",
      "  WARMUP_MIN_LR: 1e-05\n",
      "  WARMUP_RECOUNT: True\n",
      "  WARMUP_TYPE: linear\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "OPTIM_C:\n",
      "  ADAM_BETA1: 0.9\n",
      "  ADAM_BETA2: 0.999\n",
      "  BASE_LR_MULT: 0.1\n",
      "  GAMMA: 0.1\n",
      "  LR: 0.003\n",
      "  LR_SCHEDULER: cosine\n",
      "  MAX_EPOCH: 30\n",
      "  MOMENTUM: 0.9\n",
      "  NAME: adam\n",
      "  NEW_LAYERS: ()\n",
      "  RMSPROP_ALPHA: 0.99\n",
      "  SGD_DAMPNING: 0\n",
      "  SGD_NESTEROV: False\n",
      "  STAGED_LR: False\n",
      "  STEPSIZE: (-1,)\n",
      "  WARMUP_CONS_LR: 1e-05\n",
      "  WARMUP_EPOCH: 1\n",
      "  WARMUP_MIN_LR: 1e-05\n",
      "  WARMUP_RECOUNT: True\n",
      "  WARMUP_TYPE: linear\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "OUTPUT_DIR: output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1\n",
      "RESUME: \n",
      "SEED: 1\n",
      "TEST:\n",
      "  COMPUTE_CMAT: False\n",
      "  EVALUATOR: Classification\n",
      "  FINAL_MODEL: last_step\n",
      "  NO_TEST: False\n",
      "  PER_CLASS_RESULT: True\n",
      "  SPLIT: test\n",
      "TRAIN:\n",
      "  CHECKPOINT_FREQ: 0\n",
      "  COUNT_ITER: train_x\n",
      "  PRINT_FREQ: 100\n",
      "TRAINER:\n",
      "  CDAC:\n",
      "    CLASS_LR_MULTI: 10\n",
      "    P_THRESH: 0.95\n",
      "    RAMPUP_COEF: 30\n",
      "    RAMPUP_ITRS: 1000\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    TOPK_MATCH: 5\n",
      "  CROSSGRAD:\n",
      "    ALPHA_D: 0.5\n",
      "    ALPHA_F: 0.5\n",
      "    EPS_D: 1.0\n",
      "    EPS_F: 1.0\n",
      "  DAEL:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 0.5\n",
      "  DAELDG:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 0.5\n",
      "  DAMP:\n",
      "    CSC: False\n",
      "    IM: 1.0\n",
      "    IND: 1.0\n",
      "    N_CLS: 2\n",
      "    N_CTX: 32\n",
      "    PREC: amp\n",
      "    STRONG_TRANSFORMS: ['randaugment', 'normalize']\n",
      "    TAU: 0.5\n",
      "    U: 2.0\n",
      "  DAPL:\n",
      "    CSC: False\n",
      "    N_CTX: 16\n",
      "    N_DMX: 16\n",
      "    PREC: fp16\n",
      "    T: 1.0\n",
      "    TAU: 0.5\n",
      "    U: 1.0\n",
      "  DDAIG:\n",
      "    ALPHA: 0.5\n",
      "    CLAMP: False\n",
      "    CLAMP_MAX: 1.0\n",
      "    CLAMP_MIN: -1.0\n",
      "    G_ARCH: \n",
      "    LMDA: 0.3\n",
      "    WARMUP: 0\n",
      "  DOMAINMIX:\n",
      "    ALPHA: 1.0\n",
      "    BETA: 1.0\n",
      "    TYPE: crossdomain\n",
      "  ENTMIN:\n",
      "    LMDA: 0.001\n",
      "  FIXMATCH:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 1.0\n",
      "  M3SDA:\n",
      "    LMDA: 0.5\n",
      "    N_STEP_F: 4\n",
      "  MCD:\n",
      "    N_STEP_F: 4\n",
      "  MEANTEACHER:\n",
      "    EMA_ALPHA: 0.999\n",
      "    RAMPUP: 5\n",
      "    WEIGHT_U: 1.0\n",
      "  MIXMATCH:\n",
      "    MIXUP_BETA: 0.75\n",
      "    RAMPUP: 20000\n",
      "    TEMP: 2.0\n",
      "    WEIGHT_U: 100.0\n",
      "  MME:\n",
      "    LMDA: 0.1\n",
      "  NAME: DAMP\n",
      "  SE:\n",
      "    CONF_THRE: 0.95\n",
      "    EMA_ALPHA: 0.999\n",
      "    RAMPUP: 300\n",
      "USE_CUDA: True\n",
      "VERBOSE: True\n",
      "VERSION: 1\n",
      "Setting fixed seed: 1\n",
      "***************\n",
      "** Arguments **\n",
      "***************\n",
      "backbone: \n",
      "config_file: configs/trainers/DAMP/damp.yaml\n",
      "dataset_config_file: configs/datasets/visda17.yaml\n",
      "eval_only: False\n",
      "head: \n",
      "load_epoch: None\n",
      "model_dir: \n",
      "no_train: False\n",
      "opts: ['TRAINER.DAMP.TAU', '0.5', 'TRAINER.DAMP.U', '2.0']\n",
      "output_dir: output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1\n",
      "resume: \n",
      "root: /home/dataset/\n",
      "seed: 1\n",
      "source_domains: ['synthetic']\n",
      "target_domains: ['real']\n",
      "trainer: DAMP\n",
      "transforms: None\n",
      "************\n",
      "** Config **\n",
      "************\n",
      "DATALOADER:\n",
      "  K_TRANSFORMS: 1\n",
      "  NUM_WORKERS: 4\n",
      "  RETURN_IMG0: False\n",
      "  TEST:\n",
      "    BATCH_SIZE: 128\n",
      "    SAMPLER: SequentialSampler\n",
      "  TRAIN_U:\n",
      "    BATCH_SIZE: 32\n",
      "    N_DOMAIN: 0\n",
      "    N_INS: 16\n",
      "    SAME_AS_X: True\n",
      "    SAMPLER: RandomSampler\n",
      "  TRAIN_X:\n",
      "    BATCH_SIZE: 32\n",
      "    N_DOMAIN: 0\n",
      "    N_INS: 16\n",
      "    SAMPLER: RandomSampler\n",
      "DATASET:\n",
      "  ALL_AS_UNLABELED: False\n",
      "  CIFAR_C_LEVEL: 1\n",
      "  CIFAR_C_TYPE: \n",
      "  NAME: VISDA_C\n",
      "  NUM_LABELED: -1\n",
      "  NUM_SHOTS: -1\n",
      "  ROOT: /home/dataset/\n",
      "  SOURCE_DOMAINS: ['synthetic']\n",
      "  STL10_FOLD: -1\n",
      "  TARGET_DOMAINS: ['real']\n",
      "  VAL_PERCENT: 0.1\n",
      "INPUT:\n",
      "  COLORJITTER_B: 0.4\n",
      "  COLORJITTER_C: 0.4\n",
      "  COLORJITTER_H: 0.1\n",
      "  COLORJITTER_S: 0.4\n",
      "  CROP_PADDING: 4\n",
      "  CUTOUT_LEN: 16\n",
      "  CUTOUT_N: 1\n",
      "  GB_K: 21\n",
      "  GB_P: 0.5\n",
      "  GN_MEAN: 0.0\n",
      "  GN_STD: 0.15\n",
      "  INTERPOLATION: bicubic\n",
      "  NO_TRANSFORM: False\n",
      "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
      "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
      "  RANDAUGMENT_M: 10\n",
      "  RANDAUGMENT_N: 2\n",
      "  RGS_P: 0.2\n",
      "  RRCROP_SCALE: (0.08, 1.0)\n",
      "  SIZE: (224, 224)\n",
      "  TRANSFORMS: ('normalize',)\n",
      "MODEL:\n",
      "  BACKBONE:\n",
      "    NAME: ViT-B/16\n",
      "    PATH: ./assets\n",
      "    PRETRAINED: True\n",
      "  HEAD:\n",
      "    ACTIVATION: relu\n",
      "    BN: True\n",
      "    DROPOUT: 0.0\n",
      "    HIDDEN_LAYERS: ()\n",
      "    NAME: \n",
      "  INIT_WEIGHTS: \n",
      "  INIT_WEIGHTS_CTX: None\n",
      "  INIT_WEIGHTS_PRO: None\n",
      "OPTIM:\n",
      "  ADAM_BETA1: 0.9\n",
      "  ADAM_BETA2: 0.999\n",
      "  BASE_LR_MULT: 0.1\n",
      "  GAMMA: 0.1\n",
      "  LR: 0.003\n",
      "  LR_SCHEDULER: cosine\n",
      "  MAX_EPOCH: 30\n",
      "  MOMENTUM: 0.9\n",
      "  NAME: adam\n",
      "  NEW_LAYERS: ()\n",
      "  RMSPROP_ALPHA: 0.99\n",
      "  SGD_DAMPNING: 0\n",
      "  SGD_NESTEROV: False\n",
      "  STAGED_LR: False\n",
      "  STEPSIZE: (-1,)\n",
      "  WARMUP_CONS_LR: 1e-05\n",
      "  WARMUP_EPOCH: 1\n",
      "  WARMUP_MIN_LR: 1e-05\n",
      "  WARMUP_RECOUNT: True\n",
      "  WARMUP_TYPE: linear\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "OPTIM_C:\n",
      "  ADAM_BETA1: 0.9\n",
      "  ADAM_BETA2: 0.999\n",
      "  BASE_LR_MULT: 0.1\n",
      "  GAMMA: 0.1\n",
      "  LR: 0.003\n",
      "  LR_SCHEDULER: cosine\n",
      "  MAX_EPOCH: 30\n",
      "  MOMENTUM: 0.9\n",
      "  NAME: adam\n",
      "  NEW_LAYERS: ()\n",
      "  RMSPROP_ALPHA: 0.99\n",
      "  SGD_DAMPNING: 0\n",
      "  SGD_NESTEROV: False\n",
      "  STAGED_LR: False\n",
      "  STEPSIZE: (-1,)\n",
      "  WARMUP_CONS_LR: 1e-05\n",
      "  WARMUP_EPOCH: 1\n",
      "  WARMUP_MIN_LR: 1e-05\n",
      "  WARMUP_RECOUNT: True\n",
      "  WARMUP_TYPE: linear\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "OUTPUT_DIR: output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1\n",
      "RESUME: \n",
      "SEED: 1\n",
      "TEST:\n",
      "  COMPUTE_CMAT: False\n",
      "  EVALUATOR: Classification\n",
      "  FINAL_MODEL: last_step\n",
      "  NO_TEST: False\n",
      "  PER_CLASS_RESULT: True\n",
      "  SPLIT: test\n",
      "TRAIN:\n",
      "  CHECKPOINT_FREQ: 0\n",
      "  COUNT_ITER: train_x\n",
      "  PRINT_FREQ: 100\n",
      "TRAINER:\n",
      "  CDAC:\n",
      "    CLASS_LR_MULTI: 10\n",
      "    P_THRESH: 0.95\n",
      "    RAMPUP_COEF: 30\n",
      "    RAMPUP_ITRS: 1000\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    TOPK_MATCH: 5\n",
      "  CROSSGRAD:\n",
      "    ALPHA_D: 0.5\n",
      "    ALPHA_F: 0.5\n",
      "    EPS_D: 1.0\n",
      "    EPS_F: 1.0\n",
      "  DAEL:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 0.5\n",
      "  DAELDG:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 0.5\n",
      "  DAMP:\n",
      "    CSC: False\n",
      "    IM: 1.0\n",
      "    IND: 1.0\n",
      "    N_CLS: 2\n",
      "    N_CTX: 32\n",
      "    PREC: amp\n",
      "    STRONG_TRANSFORMS: ['randaugment', 'normalize']\n",
      "    TAU: 0.5\n",
      "    U: 2.0\n",
      "  DAPL:\n",
      "    CSC: False\n",
      "    N_CTX: 16\n",
      "    N_DMX: 16\n",
      "    PREC: fp16\n",
      "    T: 1.0\n",
      "    TAU: 0.5\n",
      "    U: 1.0\n",
      "  DDAIG:\n",
      "    ALPHA: 0.5\n",
      "    CLAMP: False\n",
      "    CLAMP_MAX: 1.0\n",
      "    CLAMP_MIN: -1.0\n",
      "    G_ARCH: \n",
      "    LMDA: 0.3\n",
      "    WARMUP: 0\n",
      "  DOMAINMIX:\n",
      "    ALPHA: 1.0\n",
      "    BETA: 1.0\n",
      "    TYPE: crossdomain\n",
      "  ENTMIN:\n",
      "    LMDA: 0.001\n",
      "  FIXMATCH:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 1.0\n",
      "  M3SDA:\n",
      "    LMDA: 0.5\n",
      "    N_STEP_F: 4\n",
      "  MCD:\n",
      "    N_STEP_F: 4\n",
      "  MEANTEACHER:\n",
      "    EMA_ALPHA: 0.999\n",
      "    RAMPUP: 5\n",
      "    WEIGHT_U: 1.0\n",
      "  MIXMATCH:\n",
      "    MIXUP_BETA: 0.75\n",
      "    RAMPUP: 20000\n",
      "    TEMP: 2.0\n",
      "    WEIGHT_U: 100.0\n",
      "  MME:\n",
      "    LMDA: 0.1\n",
      "  NAME: DAMP\n",
      "  SE:\n",
      "    CONF_THRE: 0.95\n",
      "    EMA_ALPHA: 0.999\n",
      "    RAMPUP: 300\n",
      "USE_CUDA: True\n",
      "VERBOSE: True\n",
      "VERSION: 1\n",
      "Collecting env info ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** System info **\n",
      "PyTorch version: 2.4.0+cu121\n",
      "Is debug build: False\n",
      "CUDA used to build PyTorch: 12.1\n",
      "ROCM used to build PyTorch: N/A\n",
      "\n",
      "OS: Ubuntu 22.04.3 LTS (x86_64)\n",
      "GCC version: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Clang version: Could not collect\n",
      "CMake version: version 3.22.1\n",
      "Libc version: glibc-2.35\n",
      "\n",
      "Python version: 3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0] (64-bit runtime)\n",
      "Python platform: Linux-6.2.0-26-generic-x86_64-with-glibc2.35\n",
      "Is CUDA available: True\n",
      "CUDA runtime version: 12.3.103\n",
      "CUDA_MODULE_LOADING set to: LAZY\n",
      "GPU models and configuration: \n",
      "GPU 0: NVIDIA GeForce RTX 4090\n",
      "GPU 1: NVIDIA GeForce RTX 4090\n",
      "GPU 2: NVIDIA GeForce RTX 4090\n",
      "GPU 3: NVIDIA GeForce RTX 4090\n",
      "GPU 4: NVIDIA GeForce RTX 4090\n",
      "GPU 5: NVIDIA GeForce RTX 4090\n",
      "GPU 6: NVIDIA GeForce RTX 4090\n",
      "GPU 7: NVIDIA GeForce RTX 4090\n",
      "\n",
      "Nvidia driver version: 535.129.03\n",
      "cuDNN version: Could not collect\n",
      "HIP runtime version: N/A\n",
      "MIOpen runtime version: N/A\n",
      "Is XNNPACK available: True\n",
      "\n",
      "CPU:\n",
      "Architecture:                    x86_64\n",
      "CPU op-mode(s):                  32-bit, 64-bit\n",
      "Address sizes:                   46 bits physical, 57 bits virtual\n",
      "Byte Order:                      Little Endian\n",
      "CPU(s):                          32\n",
      "On-line CPU(s) list:             0-31\n",
      "Vendor ID:                       GenuineIntel\n",
      "Model name:                      Intel(R) Xeon(R) Gold 6426Y\n",
      "CPU family:                      6\n",
      "Model:                           143\n",
      "Thread(s) per core:              1\n",
      "Core(s) per socket:              16\n",
      "Socket(s):                       2\n",
      "Stepping:                        8\n",
      "CPU max MHz:                     4100.0000\n",
      "CPU min MHz:                     800.0000\n",
      "BogoMIPS:                        5000.00\n",
      "Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 cat_l2 cdp_l3 invpcid_single intel_ppin cdp_l2 ssbd mba ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm rdt_a avx512f avx512dq rdseed adx smap avx512ifma clflushopt clwb intel_pt avx512cd sha_ni avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local split_lock_detect avx_vnni avx512_bf16 wbnoinvd dtherm ida arat pln pts hwp hwp_act_window hwp_epp hwp_pkg_req hfi avx512vbmi umip pku ospke waitpkg avx512_vbmi2 gfni vaes vpclmulqdq avx512_vnni avx512_bitalg tme avx512_vpopcntdq la57 rdpid bus_lock_detect cldemote movdiri movdir64b enqcmd fsrm md_clear serialize tsxldtrk pconfig arch_lbr ibt amx_bf16 avx512_fp16 amx_tile amx_int8 flush_l1d arch_capabilities\n",
      "Virtualization:                  VT-x\n",
      "L1d cache:                       1.5 MiB (32 instances)\n",
      "L1i cache:                       1 MiB (32 instances)\n",
      "L2 cache:                        64 MiB (32 instances)\n",
      "L3 cache:                        75 MiB (2 instances)\n",
      "NUMA node(s):                    2\n",
      "NUMA node0 CPU(s):               0-15\n",
      "NUMA node1 CPU(s):               16-31\n",
      "Vulnerability Itlb multihit:     Not affected\n",
      "Vulnerability L1tf:              Not affected\n",
      "Vulnerability Mds:               Not affected\n",
      "Vulnerability Meltdown:          Not affected\n",
      "Vulnerability Mmio stale data:   Not affected\n",
      "Vulnerability Retbleed:          Not affected\n",
      "Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl\n",
      "Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization\n",
      "Vulnerability Spectre v2:        Mitigation; Enhanced IBRS, IBPB conditional, RSB filling, PBRSB-eIBRS SW sequence\n",
      "Vulnerability Srbds:             Not affected\n",
      "Vulnerability Tsx async abort:   Not affected\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] flake8==3.7.9\n",
      "[pip3] mypy-extensions==1.0.0\n",
      "[pip3] numpy==1.23.0\n",
      "[pip3] numpydoc==1.5.0\n",
      "[pip3] optree==0.12.1\n",
      "[pip3] torch==2.4.0\n",
      "[pip3] torchvision==0.19.0\n",
      "[pip3] triton==3.0.0\n",
      "[conda] _anaconda_depends         2023.09             py311_mkl_1  \n",
      "[conda] blas                      1.0                         mkl  \n",
      "[conda] mkl                       2023.1.0         h213fc3f_46343  \n",
      "[conda] mkl-service               2.4.0           py311h5eee18b_1  \n",
      "[conda] mkl_fft                   1.3.8           py311h5eee18b_0  \n",
      "[conda] mkl_random                1.2.4           py311hdb19cb5_0  \n",
      "[conda] numpy                     1.24.3          py311h08b1b3b_1  \n",
      "[conda] numpy-base                1.24.3          py311hf175353_1  \n",
      "[conda] numpydoc                  1.5.0           py311h06a4308_0  \n",
      "        Pillow (9.4.0)\n",
      "\n",
      "Loading trainer: DAMP\n",
      "Building transform_train\n",
      "+ resize to 224x224\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
      "Building transform_train\n",
      "+ resize to 224x224\n",
      "+ randaugment (n=2, m=10)\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
      "Loading dataset: VISDA_C\n",
      "* Using custom transform for training\n",
      "Building transform_test\n",
      "+ resize the smaller edge to 224\n",
      "+ 224x224 center crop\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
      "---------  -------------\n",
      "Dataset    VISDA_C\n",
      "Source     ['synthetic']\n",
      "Target     ['real']\n",
      "# classes  12\n",
      "# train_x  152,397\n",
      "# train_u  55,388\n",
      "# test     55,388\n",
      "---------  -------------\n",
      "['aeroplane', 'bicycle', 'bus', 'car', 'horse', 'knife', 'motorcycle', 'person', 'plant', 'skateboard', 'train', 'truck']\n",
      "Loading CLIP (backbone: ViT-B/16)\n",
      "./assets/ViT-B-16.pt\n",
      "Building custom CLIP\n",
      "ContextDecoder(\n",
      "  (memory_proj): Sequential(\n",
      "    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (text_proj): Sequential(\n",
      "    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "  )\n",
      "  (decoder): ModuleList(\n",
      "    (0-5): 6 x TransformerDecoderLayer(\n",
      "      (self_attn): Attention(\n",
      "        (q_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (k_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (v_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (cross_attn): Attention(\n",
      "        (q_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (k_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (v_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "        (3): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (out_proj): Sequential(\n",
      "    (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=256, out_features=512, bias=True)\n",
      "  )\n",
      ")\n",
      "Initializing a generic context\n",
      "ctx vectors size: \n",
      "Initial context: \"X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X\"\n",
      "Number of context words (tokens): 32\n",
      "Number of cls words (tokens): 2\n",
      "Prompts: \"X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X aeroplane.\"\n",
      "Naive Prompts: \"a real photo of a aeroplane.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turning off gradients in both the image and the text encoder\n",
      "Loading evaluator: Classification\n",
      "No checkpoint found, train from scratch\n",
      "Initialize tensorboard (log_dir=output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/tensorboard)\n",
      "epoch [1/30][100/500]\ttime 0.190 (0.209)\tdata 0.001 (0.003)\teta 0:52:00\tloss 1.3648 (4.3817) loss_x 0.7404 (0.4450) loss_u 0.0656 (0.1843) acc_x 78.1250 (86.6562) acc_u 84.3750 (85.1250) gamma_v 0.0127 (0.0147) gamma_t 0.0886 (0.0590) loss_x_ind 0.6078 (1.9805)\tlr 6.183221e-04\n",
      "epoch [1/30][200/500]\ttime 0.186 (0.198)\tdata 0.001 (0.002)\teta 0:48:51\tloss -0.4313 (2.3661) loss_x 0.0593 (0.3686) loss_u 0.0354 (0.1356) acc_x 96.8750 (88.2031) acc_u 81.2500 (85.6094) gamma_v 0.0150 (0.0149) gamma_t 0.1005 (0.0778) loss_x_ind 0.2013 (1.2508)\tlr 8.898950e-04\n",
      "epoch [1/30][300/500]\ttime 0.185 (0.196)\tdata 0.001 (0.002)\teta 0:47:57\tloss 0.1659 (1.5380) loss_x 0.3421 (0.3372) loss_u 0.0433 (0.1155) acc_x 81.2500 (89.0729) acc_u 87.5000 (85.2708) gamma_v 0.0181 (0.0156) gamma_t 0.1096 (0.0866) loss_x_ind 0.2524 (0.9357)\tlr 2.991783e-03\n",
      "epoch [1/30][400/500]\ttime 0.231 (0.198)\tdata 0.001 (0.002)\teta 0:48:10\tloss 0.0897 (1.0580) loss_x 0.1767 (0.3076) loss_u 0.0761 (0.1038) acc_x 93.7500 (89.9141) acc_u 81.2500 (85.3125) gamma_v 0.0214 (0.0165) gamma_t 0.1113 (0.0924) loss_x_ind 0.1180 (0.7615)\tlr 6.183221e-04\n",
      "epoch [1/30][500/500]\ttime 0.238 (0.205)\tdata 0.001 (0.001)\teta 0:49:37\tloss -0.9684 (0.7653) loss_x 0.1046 (0.2953) loss_u 0.0380 (0.0985) acc_x 93.7500 (90.2875) acc_u 90.6250 (85.2000) gamma_v 0.0233 (0.0170) gamma_t 0.1074 (0.0960) loss_x_ind 0.1244 (0.6481)\tlr 8.898950e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,193\n",
      "* accuracy: 87.0%\n",
      "* error: 13.0%\n",
      "* macro_f1: 87.9%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,609\tacc: 99.0%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,216\tacc: 92.5%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,346\tacc: 92.7%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,660\tacc: 73.6%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,620\tacc: 98.5%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,996\tacc: 96.2%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,478\tacc: 94.5%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,246\tacc: 81.2%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,183\tacc: 92.0%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,170\tacc: 95.1%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,983\tacc: 94.0%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,686\tacc: 66.4%\n",
      "* average: 89.6%\n",
      "test_batch_time: 0.095\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/prompt_learner/model-best.pth.tar\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/context_decoder/model-best.pth.tar\n",
      "epoch [2/30][100/500]\ttime 0.204 (0.241)\tdata 0.001 (0.004)\teta 0:57:46\tloss -1.2424 (-0.5773) loss_x 0.1592 (0.2151) loss_u 0.0290 (0.0640) acc_x 90.6250 (92.0625) acc_u 87.5000 (84.9375) gamma_v 0.0251 (0.0232) gamma_t 0.1088 (0.1083) loss_x_ind 0.1321 (0.1714)\tlr 2.991783e-03\n",
      "epoch [2/30][200/500]\ttime 0.215 (0.227)\tdata 0.001 (0.002)\teta 0:54:00\tloss -0.3757 (-0.5547) loss_x 0.4667 (0.2255) loss_u 0.0394 (0.0668) acc_x 90.6250 (92.0000) acc_u 87.5000 (84.9688) gamma_v 0.0185 (0.0213) gamma_t 0.1128 (0.1102) loss_x_ind 0.1000 (0.1645)\tlr 6.183221e-04\n",
      "epoch [2/30][300/500]\ttime 0.213 (0.228)\tdata 0.001 (0.002)\teta 0:53:57\tloss -1.2041 (-0.5874) loss_x 0.2913 (0.2176) loss_u 0.0275 (0.0647) acc_x 84.3750 (92.2292) acc_u 81.2500 (85.3021) gamma_v 0.0202 (0.0219) gamma_t 0.1168 (0.1115) loss_x_ind 0.0425 (0.1561)\tlr 8.898950e-04\n",
      "epoch [2/30][400/500]\ttime 0.180 (0.227)\tdata 0.000 (0.002)\teta 0:53:24\tloss -0.1937 (-0.6087) loss_x 0.4954 (0.2169) loss_u 0.0477 (0.0652) acc_x 84.3750 (92.3516) acc_u 90.6250 (85.1562) gamma_v 0.0223 (0.0218) gamma_t 0.1157 (0.1126) loss_x_ind 0.1163 (0.1483)\tlr 2.991783e-03\n",
      "epoch [2/30][500/500]\ttime 0.213 (0.221)\tdata 0.001 (0.001)\teta 0:51:35\tloss -0.2844 (-0.6186) loss_x 0.2225 (0.2140) loss_u 0.1039 (0.0646) acc_x 90.6250 (92.5438) acc_u 90.6250 (85.1000) gamma_v 0.0209 (0.0218) gamma_t 0.1132 (0.1132) loss_x_ind 0.0966 (0.1445)\tlr 6.183221e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,288\n",
      "* accuracy: 87.2%\n",
      "* error: 12.8%\n",
      "* macro_f1: 88.0%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,599\tacc: 98.7%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,200\tacc: 92.1%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,286\tacc: 91.4%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,887\tacc: 75.8%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,628\tacc: 98.7%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,928\tacc: 92.9%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,494\tacc: 94.8%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,343\tacc: 83.6%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,132\tacc: 90.8%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,195\tacc: 96.2%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,997\tacc: 94.4%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,599\tacc: 64.9%\n",
      "* average: 89.5%\n",
      "test_batch_time: 0.097\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/prompt_learner/model-best.pth.tar\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/context_decoder/model-best.pth.tar\n",
      "epoch [3/30][100/500]\ttime 0.220 (0.249)\tdata 0.001 (0.004)\teta 0:57:43\tloss -0.6307 (-0.7338) loss_x 0.2395 (0.2008) loss_u 0.0643 (0.0549) acc_x 93.7500 (93.0312) acc_u 84.3750 (85.7500) gamma_v 0.0279 (0.0263) gamma_t 0.1186 (0.1174) loss_x_ind 0.0615 (0.1173)\tlr 8.898950e-04\n",
      "epoch [3/30][200/500]\ttime 0.240 (0.248)\tdata 0.001 (0.003)\teta 0:57:07\tloss -1.1644 (-0.7264) loss_x 0.2707 (0.1971) loss_u 0.0232 (0.0580) acc_x 90.6250 (93.0156) acc_u 87.5000 (85.7656) gamma_v 0.0281 (0.0266) gamma_t 0.1191 (0.1188) loss_x_ind 0.0929 (0.1098)\tlr 2.991783e-03\n",
      "epoch [3/30][300/500]\ttime 0.240 (0.246)\tdata 0.001 (0.002)\teta 0:56:03\tloss -0.1990 (-0.7176) loss_x 0.1696 (0.1930) loss_u 0.1546 (0.0604) acc_x 93.7500 (93.2708) acc_u 87.5000 (85.7604) gamma_v 0.0260 (0.0267) gamma_t 0.1264 (0.1200) loss_x_ind 0.1108 (0.1126)\tlr 6.183221e-04\n",
      "epoch [3/30][400/500]\ttime 0.235 (0.247)\tdata 0.001 (0.002)\teta 0:56:03\tloss -0.2808 (-0.7254) loss_x 0.1418 (0.1942) loss_u 0.0979 (0.0596) acc_x 93.7500 (93.1094) acc_u 90.6250 (85.6016) gamma_v 0.0236 (0.0274) gamma_t 0.1260 (0.1204) loss_x_ind 0.0438 (0.1126)\tlr 8.898950e-04\n",
      "epoch [3/30][500/500]\ttime 0.208 (0.246)\tdata 0.001 (0.002)\teta 0:55:26\tloss -0.8221 (-0.7341) loss_x 0.1251 (0.1920) loss_u 0.0709 (0.0595) acc_x 90.6250 (93.0938) acc_u 84.3750 (85.3375) gamma_v 0.0294 (0.0270) gamma_t 0.1240 (0.1207) loss_x_ind 0.1377 (0.1111)\tlr 2.991783e-03\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 47,841\n",
      "* accuracy: 86.4%\n",
      "* error: 13.6%\n",
      "* macro_f1: 87.0%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,609\tacc: 99.0%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,226\tacc: 92.8%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,385\tacc: 93.5%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,899\tacc: 75.9%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,621\tacc: 98.5%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,945\tacc: 93.7%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,502\tacc: 94.9%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,280\tacc: 82.0%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,069\tacc: 89.4%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,165\tacc: 94.9%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,974\tacc: 93.8%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,166\tacc: 57.1%\n",
      "* average: 88.8%\n",
      "test_batch_time: 0.094\n",
      "epoch [4/30][100/500]\ttime 0.404 (0.256)\tdata 0.003 (0.004)\teta 0:57:03\tloss -1.0372 (-0.8191) loss_x 0.1464 (0.1742) loss_u 0.0251 (0.0476) acc_x 93.7500 (94.0938) acc_u 84.3750 (84.8750) gamma_v 0.0270 (0.0277) gamma_t 0.1265 (0.1240) loss_x_ind 0.0827 (0.1112)\tlr 6.183221e-04\n",
      "epoch [4/30][200/500]\ttime 0.232 (0.238)\tdata 0.001 (0.002)\teta 0:52:46\tloss -1.0978 (-0.8083) loss_x 0.0212 (0.1770) loss_u 0.0658 (0.0502) acc_x 100.0000 (93.9531) acc_u 84.3750 (85.2812) gamma_v 0.0300 (0.0280) gamma_t 0.1244 (0.1265) loss_x_ind 0.1747 (0.1057)\tlr 8.898950e-04\n",
      "epoch [4/30][300/500]\ttime 0.201 (0.241)\tdata 0.001 (0.002)\teta 0:52:57\tloss -0.5225 (-0.8164) loss_x 0.3538 (0.1814) loss_u 0.0195 (0.0487) acc_x 81.2500 (93.6042) acc_u 90.6250 (85.2812) gamma_v 0.0355 (0.0289) gamma_t 0.1304 (0.1276) loss_x_ind 0.1267 (0.1041)\tlr 2.991783e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [4/30][400/500]\ttime 0.245 (0.238)\tdata 0.001 (0.002)\teta 0:51:54\tloss -1.3967 (-0.8247) loss_x 0.0161 (0.1814) loss_u 0.0165 (0.0505) acc_x 100.0000 (93.6719) acc_u 87.5000 (85.4453) gamma_v 0.0348 (0.0306) gamma_t 0.1318 (0.1287) loss_x_ind 0.0625 (0.1020)\tlr 6.183221e-04\n",
      "epoch [4/30][500/500]\ttime 0.216 (0.238)\tdata 0.002 (0.002)\teta 0:51:32\tloss -0.7668 (-0.8299) loss_x 0.1775 (0.1807) loss_u 0.0446 (0.0523) acc_x 93.7500 (93.7438) acc_u 87.5000 (85.4188) gamma_v 0.0292 (0.0314) gamma_t 0.1360 (0.1295) loss_x_ind 0.0863 (0.0996)\tlr 8.898950e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,135\n",
      "* accuracy: 86.9%\n",
      "* error: 13.1%\n",
      "* macro_f1: 87.7%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,598\tacc: 98.7%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,175\tacc: 91.4%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,405\tacc: 93.9%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,953\tacc: 76.5%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,621\tacc: 98.5%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,997\tacc: 96.2%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,507\tacc: 95.0%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,233\tacc: 80.8%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,184\tacc: 92.0%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,150\tacc: 94.3%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,003\tacc: 94.5%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,309\tacc: 59.6%\n",
      "* average: 89.3%\n",
      "test_batch_time: 0.097\n",
      "epoch [5/30][100/500]\ttime 0.216 (0.253)\tdata 0.001 (0.004)\teta 0:54:19\tloss -0.4481 (-0.8433) loss_x 0.2307 (0.1757) loss_u 0.0579 (0.0472) acc_x 93.7500 (93.7500) acc_u 84.3750 (85.3438) gamma_v 0.0372 (0.0306) gamma_t 0.1352 (0.1361) loss_x_ind 0.0607 (0.0824)\tlr 2.991783e-03\n",
      "epoch [5/30][200/500]\ttime 0.203 (0.242)\tdata 0.001 (0.003)\teta 0:51:43\tloss -1.5020 (-0.8779) loss_x 0.1046 (0.1737) loss_u 0.0302 (0.0475) acc_x 96.8750 (93.8281) acc_u 90.6250 (85.4531) gamma_v 0.0335 (0.0312) gamma_t 0.1402 (0.1369) loss_x_ind 0.0808 (0.0869)\tlr 6.183221e-04\n",
      "epoch [5/30][300/500]\ttime 0.232 (0.238)\tdata 0.001 (0.002)\teta 0:50:24\tloss -0.8220 (-0.8855) loss_x 0.3195 (0.1757) loss_u 0.0231 (0.0474) acc_x 90.6250 (93.6562) acc_u 87.5000 (85.5938) gamma_v 0.0358 (0.0322) gamma_t 0.1394 (0.1392) loss_x_ind 0.0690 (0.0837)\tlr 8.898950e-04\n",
      "epoch [5/30][400/500]\ttime 0.233 (0.242)\tdata 0.001 (0.002)\teta 0:50:48\tloss -0.6834 (-0.8798) loss_x 0.2014 (0.1779) loss_u 0.0466 (0.0472) acc_x 93.7500 (93.5547) acc_u 84.3750 (85.6094) gamma_v 0.0379 (0.0331) gamma_t 0.1428 (0.1401) loss_x_ind 0.0504 (0.0823)\tlr 2.991783e-03\n",
      "epoch [5/30][500/500]\ttime 0.206 (0.244)\tdata 0.001 (0.002)\teta 0:50:46\tloss -0.7766 (-0.8890) loss_x 0.1251 (0.1766) loss_u 0.0382 (0.0466) acc_x 96.8750 (93.6312) acc_u 78.1250 (85.7875) gamma_v 0.0363 (0.0344) gamma_t 0.1453 (0.1412) loss_x_ind 0.0400 (0.0830)\tlr 6.183221e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,107\n",
      "* accuracy: 86.9%\n",
      "* error: 13.1%\n",
      "* macro_f1: 87.8%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,605\tacc: 98.9%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,183\tacc: 91.6%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,340\tacc: 92.5%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,643\tacc: 73.5%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,623\tacc: 98.6%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,979\tacc: 95.4%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,493\tacc: 94.8%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,361\tacc: 84.0%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,177\tacc: 91.8%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,177\tacc: 95.4%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,966\tacc: 93.6%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,560\tacc: 64.2%\n",
      "* average: 89.5%\n",
      "test_batch_time: 0.094\n",
      "epoch [6/30][100/500]\ttime 0.203 (0.215)\tdata 0.001 (0.003)\teta 0:44:27\tloss -0.6396 (-0.8496) loss_x 0.1179 (0.1604) loss_u 0.0222 (0.0462) acc_x 93.7500 (94.3750) acc_u 87.5000 (85.5000) gamma_v 0.0402 (0.0373) gamma_t 0.1468 (0.1491) loss_x_ind 0.0647 (0.0724)\tlr 8.898950e-04\n",
      "epoch [6/30][200/500]\ttime 0.212 (0.221)\tdata 0.001 (0.002)\teta 0:45:19\tloss -1.1160 (-0.8805) loss_x 0.1719 (0.1650) loss_u 0.0271 (0.0445) acc_x 93.7500 (94.2969) acc_u 93.7500 (85.8438) gamma_v 0.0426 (0.0383) gamma_t 0.1517 (0.1499) loss_x_ind 0.0317 (0.0742)\tlr 2.991783e-03\n",
      "epoch [6/30][300/500]\ttime 0.238 (0.230)\tdata 0.001 (0.002)\teta 0:46:40\tloss -0.7668 (-0.8732) loss_x 0.1580 (0.1659) loss_u 0.0195 (0.0439) acc_x 96.8750 (94.1667) acc_u 93.7500 (85.8646) gamma_v 0.0389 (0.0388) gamma_t 0.1549 (0.1509) loss_x_ind 0.0321 (0.0747)\tlr 6.183221e-04\n",
      "epoch [6/30][400/500]\ttime 0.232 (0.231)\tdata 0.001 (0.002)\teta 0:46:34\tloss -0.6006 (-0.9081) loss_x 0.3724 (0.1668) loss_u 0.0647 (0.0430) acc_x 93.7500 (94.1562) acc_u 75.0000 (85.9062) gamma_v 0.0382 (0.0388) gamma_t 0.1534 (0.1519) loss_x_ind 0.0890 (0.0741)\tlr 8.898950e-04\n",
      "epoch [6/30][500/500]\ttime 0.237 (0.235)\tdata 0.001 (0.002)\teta 0:46:59\tloss -1.4818 (-0.9212) loss_x 0.0751 (0.1675) loss_u 0.0262 (0.0429) acc_x 96.8750 (94.0563) acc_u 84.3750 (86.0000) gamma_v 0.0391 (0.0391) gamma_t 0.1602 (0.1527) loss_x_ind 0.0278 (0.0727)\tlr 2.991783e-03\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,396\n",
      "* accuracy: 87.4%\n",
      "* error: 12.6%\n",
      "* macro_f1: 88.5%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,600\tacc: 98.7%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,097\tacc: 89.1%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,336\tacc: 92.5%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,664\tacc: 73.7%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,593\tacc: 97.9%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,969\tacc: 94.9%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,439\tacc: 93.8%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,302\tacc: 82.5%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,105\tacc: 90.2%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,181\tacc: 95.6%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,945\tacc: 93.1%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 4,165\tacc: 75.1%\n",
      "* average: 89.8%\n",
      "test_batch_time: 0.096\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/prompt_learner/model-best.pth.tar\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/context_decoder/model-best.pth.tar\n",
      "epoch [7/30][100/500]\ttime 0.215 (0.239)\tdata 0.000 (0.004)\teta 0:47:24\tloss -1.3190 (-0.9560) loss_x 0.1183 (0.1836) loss_u 0.0105 (0.0423) acc_x 96.8750 (93.5625) acc_u 87.5000 (86.0625) gamma_v 0.0402 (0.0403) gamma_t 0.1638 (0.1613) loss_x_ind 0.0801 (0.0708)\tlr 6.183221e-04\n",
      "epoch [7/30][200/500]\ttime 0.214 (0.230)\tdata 0.001 (0.003)\teta 0:45:09\tloss -0.0956 (-0.9667) loss_x 0.1219 (0.1725) loss_u 0.0623 (0.0415) acc_x 96.8750 (93.7969) acc_u 65.6250 (86.4062) gamma_v 0.0383 (0.0406) gamma_t 0.1646 (0.1628) loss_x_ind 0.0164 (0.0680)\tlr 8.898950e-04\n",
      "epoch [7/30][300/500]\ttime 0.214 (0.229)\tdata 0.001 (0.002)\teta 0:44:37\tloss -1.5226 (-0.9424) loss_x 0.0407 (0.1744) loss_u 0.0118 (0.0409) acc_x 100.0000 (93.8021) acc_u 78.1250 (85.9375) gamma_v 0.0496 (0.0405) gamma_t 0.1713 (0.1651) loss_x_ind 0.0792 (0.0685)\tlr 2.991783e-03\n",
      "epoch [7/30][400/500]\ttime 0.213 (0.228)\tdata 0.000 (0.002)\teta 0:44:10\tloss -1.0232 (-0.9377) loss_x 0.2884 (0.1726) loss_u 0.0272 (0.0427) acc_x 90.6250 (93.8359) acc_u 87.5000 (85.8438) gamma_v 0.0505 (0.0423) gamma_t 0.1734 (0.1668) loss_x_ind 0.0767 (0.0694)\tlr 6.183221e-04\n",
      "epoch [7/30][500/500]\ttime 0.239 (0.229)\tdata 0.001 (0.002)\teta 0:43:48\tloss -1.4382 (-0.9558) loss_x 0.1831 (0.1691) loss_u 0.0420 (0.0429) acc_x 87.5000 (93.9750) acc_u 90.6250 (85.7938) gamma_v 0.0420 (0.0426) gamma_t 0.1738 (0.1676) loss_x_ind 0.0458 (0.0676)\tlr 8.898950e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,075\n",
      "* accuracy: 86.8%\n",
      "* error: 13.2%\n",
      "* macro_f1: 87.5%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,594\tacc: 98.6%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,269\tacc: 94.1%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,335\tacc: 92.4%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,599\tacc: 73.1%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,598\tacc: 98.0%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,991\tacc: 96.0%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,435\tacc: 93.8%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,126\tacc: 78.2%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,125\tacc: 90.7%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,204\tacc: 96.6%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,992\tacc: 94.2%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,807\tacc: 68.6%\n",
      "* average: 89.5%\n",
      "test_batch_time: 0.095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [8/30][100/500]\ttime 0.215 (0.235)\tdata 0.002 (0.004)\teta 0:44:44\tloss -0.1232 (-1.0005) loss_x 0.2731 (0.1689) loss_u 0.0597 (0.0403) acc_x 93.7500 (94.0625) acc_u 81.2500 (86.1250) gamma_v 0.0466 (0.0481) gamma_t 0.1720 (0.1706) loss_x_ind 0.0594 (0.0667)\tlr 2.991783e-03\n",
      "epoch [8/30][200/500]\ttime 0.247 (0.241)\tdata 0.001 (0.003)\teta 0:45:26\tloss -1.0351 (-1.0046) loss_x 0.2396 (0.1624) loss_u 0.0209 (0.0377) acc_x 93.7500 (94.2031) acc_u 96.8750 (86.5625) gamma_v 0.0440 (0.0462) gamma_t 0.1784 (0.1727) loss_x_ind 0.1346 (0.0655)\tlr 6.183221e-04\n",
      "epoch [8/30][300/500]\ttime 0.241 (0.245)\tdata 0.001 (0.002)\teta 0:45:48\tloss -1.3597 (-1.0032) loss_x 0.0153 (0.1575) loss_u 0.0064 (0.0367) acc_x 100.0000 (94.2917) acc_u 84.3750 (86.2188) gamma_v 0.0513 (0.0463) gamma_t 0.1742 (0.1741) loss_x_ind 0.0886 (0.0636)\tlr 8.898950e-04\n",
      "epoch [8/30][400/500]\ttime 0.240 (0.244)\tdata 0.001 (0.002)\teta 0:45:06\tloss -0.5418 (-1.0037) loss_x 0.2262 (0.1569) loss_u 0.0583 (0.0372) acc_x 93.7500 (94.3516) acc_u 90.6250 (86.0469) gamma_v 0.0514 (0.0471) gamma_t 0.1697 (0.1740) loss_x_ind 0.0665 (0.0606)\tlr 2.991783e-03\n",
      "epoch [8/30][500/500]\ttime 0.235 (0.243)\tdata 0.001 (0.002)\teta 0:44:28\tloss -1.2111 (-1.0128) loss_x 0.1068 (0.1557) loss_u 0.0500 (0.0377) acc_x 96.8750 (94.4500) acc_u 81.2500 (86.0750) gamma_v 0.0540 (0.0487) gamma_t 0.1753 (0.1741) loss_x_ind 0.0456 (0.0591)\tlr 6.183221e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 47,979\n",
      "* accuracy: 86.6%\n",
      "* error: 13.4%\n",
      "* macro_f1: 87.5%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,597\tacc: 98.7%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,171\tacc: 91.3%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,385\tacc: 93.5%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,589\tacc: 73.0%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,621\tacc: 98.5%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,938\tacc: 93.4%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,507\tacc: 95.0%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,334\tacc: 83.3%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,197\tacc: 92.3%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,193\tacc: 96.1%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,014\tacc: 94.8%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,433\tacc: 61.9%\n",
      "* average: 89.3%\n",
      "test_batch_time: 0.095\n",
      "epoch [9/30][100/500]\ttime 0.209 (0.221)\tdata 0.001 (0.004)\teta 0:40:13\tloss -0.4841 (-1.0278) loss_x 0.0478 (0.1498) loss_u 0.0268 (0.0357) acc_x 100.0000 (94.7500) acc_u 90.6250 (85.6875) gamma_v 0.0490 (0.0441) gamma_t 0.1826 (0.1816) loss_x_ind 0.0498 (0.0618)\tlr 8.898950e-04\n",
      "epoch [9/30][200/500]\ttime 0.241 (0.224)\tdata 0.001 (0.002)\teta 0:40:17\tloss -0.2855 (-1.0367) loss_x 0.3598 (0.1538) loss_u 0.0129 (0.0368) acc_x 87.5000 (94.5938) acc_u 81.2500 (85.4688) gamma_v 0.0485 (0.0465) gamma_t 0.1909 (0.1834) loss_x_ind 0.0676 (0.0578)\tlr 2.991783e-03\n",
      "epoch [9/30][300/500]\ttime 0.228 (0.232)\tdata 0.001 (0.002)\teta 0:41:17\tloss -0.9195 (-1.0170) loss_x 0.0091 (0.1555) loss_u 0.0308 (0.0382) acc_x 100.0000 (94.5625) acc_u 90.6250 (85.3750) gamma_v 0.0500 (0.0477) gamma_t 0.1853 (0.1847) loss_x_ind 0.0302 (0.0579)\tlr 6.183221e-04\n",
      "epoch [9/30][400/500]\ttime 0.235 (0.234)\tdata 0.001 (0.002)\teta 0:41:17\tloss -1.3484 (-1.0076) loss_x 0.0254 (0.1581) loss_u 0.0330 (0.0377) acc_x 100.0000 (94.3594) acc_u 90.6250 (85.3828) gamma_v 0.0459 (0.0479) gamma_t 0.1927 (0.1854) loss_x_ind 0.0892 (0.0578)\tlr 8.898950e-04\n",
      "epoch [9/30][500/500]\ttime 0.237 (0.233)\tdata 0.002 (0.002)\teta 0:40:45\tloss -0.4551 (-1.0060) loss_x 0.0783 (0.1584) loss_u 0.0584 (0.0373) acc_x 96.8750 (94.3312) acc_u 84.3750 (85.5062) gamma_v 0.0488 (0.0480) gamma_t 0.1930 (0.1869) loss_x_ind 0.0709 (0.0572)\tlr 2.991783e-03\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 47,675\n",
      "* accuracy: 86.1%\n",
      "* error: 13.9%\n",
      "* macro_f1: 87.2%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,601\tacc: 98.8%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,188\tacc: 91.7%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,404\tacc: 93.9%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,444\tacc: 71.6%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,624\tacc: 98.6%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,962\tacc: 94.6%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,511\tacc: 95.1%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,432\tacc: 85.8%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 3,953\tacc: 86.9%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,163\tacc: 94.8%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,012\tacc: 94.7%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,381\tacc: 60.9%\n",
      "* average: 88.9%\n",
      "test_batch_time: 0.096\n",
      "epoch [10/30][100/500]\ttime 0.220 (0.255)\tdata 0.001 (0.004)\teta 0:44:07\tloss -0.8154 (-0.9418) loss_x 0.2155 (0.1628) loss_u 0.0641 (0.0412) acc_x 93.7500 (94.1875) acc_u 96.8750 (85.8125) gamma_v 0.0572 (0.0549) gamma_t 0.1893 (0.1900) loss_x_ind 0.0437 (0.0561)\tlr 6.183221e-04\n",
      "epoch [10/30][200/500]\ttime 0.224 (0.244)\tdata 0.001 (0.003)\teta 0:41:57\tloss -0.6605 (-0.9631) loss_x 0.0511 (0.1608) loss_u 0.0237 (0.0396) acc_x 100.0000 (94.1250) acc_u 87.5000 (85.8281) gamma_v 0.0558 (0.0554) gamma_t 0.1972 (0.1922) loss_x_ind 0.0973 (0.0570)\tlr 8.898950e-04\n",
      "epoch [10/30][300/500]\ttime 0.230 (0.235)\tdata 0.001 (0.002)\teta 0:39:54\tloss -0.5879 (-0.9955) loss_x 0.2546 (0.1620) loss_u 0.1185 (0.0368) acc_x 93.7500 (94.0000) acc_u 90.6250 (86.1875) gamma_v 0.0502 (0.0547) gamma_t 0.2051 (0.1946) loss_x_ind 0.0242 (0.0574)\tlr 2.991783e-03\n",
      "epoch [10/30][400/500]\ttime 0.233 (0.237)\tdata 0.002 (0.002)\teta 0:39:57\tloss -1.0242 (-1.0053) loss_x 0.2147 (0.1578) loss_u 0.0392 (0.0356) acc_x 93.7500 (94.2109) acc_u 84.3750 (86.0312) gamma_v 0.0523 (0.0538) gamma_t 0.1965 (0.1956) loss_x_ind 0.0996 (0.0557)\tlr 6.183221e-04\n",
      "epoch [10/30][500/500]\ttime 0.234 (0.239)\tdata 0.001 (0.002)\teta 0:39:49\tloss -1.3347 (-1.0188) loss_x 0.1279 (0.1542) loss_u 0.0217 (0.0356) acc_x 93.7500 (94.3625) acc_u 87.5000 (86.0312) gamma_v 0.0588 (0.0538) gamma_t 0.1957 (0.1957) loss_x_ind 0.0239 (0.0547)\tlr 8.898950e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,026\n",
      "* accuracy: 86.7%\n",
      "* error: 13.3%\n",
      "* macro_f1: 87.5%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,606\tacc: 98.9%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,190\tacc: 91.8%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,372\tacc: 93.2%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,515\tacc: 72.3%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,621\tacc: 98.5%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,978\tacc: 95.3%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,538\tacc: 95.5%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,209\tacc: 80.2%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,235\tacc: 93.1%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,194\tacc: 96.2%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,020\tacc: 94.9%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,548\tacc: 64.0%\n",
      "* average: 89.5%\n",
      "test_batch_time: 0.097\n",
      "epoch [11/30][100/500]\ttime 0.188 (0.223)\tdata 0.001 (0.004)\teta 0:36:43\tloss -1.4828 (-1.0574) loss_x 0.0345 (0.1558) loss_u 0.0129 (0.0296) acc_x 100.0000 (94.2500) acc_u 90.6250 (87.0312) gamma_v 0.0523 (0.0580) gamma_t 0.2047 (0.1988) loss_x_ind 0.0586 (0.0479)\tlr 2.991783e-03\n",
      "epoch [11/30][200/500]\ttime 0.218 (0.214)\tdata 0.001 (0.002)\teta 0:34:58\tloss -1.2506 (-1.0357) loss_x 0.1226 (0.1503) loss_u 0.0228 (0.0329) acc_x 96.8750 (94.4844) acc_u 87.5000 (85.9844) gamma_v 0.0546 (0.0554) gamma_t 0.2073 (0.2021) loss_x_ind 0.0454 (0.0520)\tlr 6.183221e-04\n",
      "epoch [11/30][300/500]\ttime 0.223 (0.218)\tdata 0.001 (0.002)\teta 0:35:11\tloss -1.2766 (-1.0507) loss_x 0.0381 (0.1487) loss_u 0.0380 (0.0313) acc_x 100.0000 (94.4688) acc_u 81.2500 (85.7917) gamma_v 0.0577 (0.0547) gamma_t 0.2053 (0.2043) loss_x_ind 0.0290 (0.0515)\tlr 8.898950e-04\n",
      "epoch [11/30][400/500]\ttime 0.225 (0.220)\tdata 0.001 (0.002)\teta 0:35:13\tloss -1.5651 (-1.0499) loss_x 0.1088 (0.1456) loss_u 0.0536 (0.0327) acc_x 96.8750 (94.5312) acc_u 90.6250 (85.7266) gamma_v 0.0478 (0.0547) gamma_t 0.2155 (0.2060) loss_x_ind 0.0396 (0.0495)\tlr 2.991783e-03\n",
      "epoch [11/30][500/500]\ttime 0.225 (0.223)\tdata 0.001 (0.002)\teta 0:35:22\tloss -1.0056 (-1.0448) loss_x 0.3174 (0.1482) loss_u 0.0279 (0.0327) acc_x 93.7500 (94.5750) acc_u 84.3750 (85.8000) gamma_v 0.0484 (0.0539) gamma_t 0.2133 (0.2072) loss_x_ind 0.0498 (0.0494)\tlr 6.183221e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,138\n",
      "* accuracy: 86.9%\n",
      "* error: 13.1%\n",
      "* macro_f1: 87.9%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,602\tacc: 98.8%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,170\tacc: 91.2%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,369\tacc: 93.2%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,509\tacc: 72.2%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,622\tacc: 98.5%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,995\tacc: 96.1%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,478\tacc: 94.5%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,331\tacc: 83.3%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,184\tacc: 92.0%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,142\tacc: 93.9%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,986\tacc: 94.1%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,750\tacc: 67.6%\n",
      "* average: 89.6%\n",
      "test_batch_time: 0.097\n",
      "epoch [12/30][100/500]\ttime 0.217 (0.242)\tdata 0.001 (0.003)\teta 0:37:53\tloss -0.6940 (-1.0087) loss_x 0.3170 (0.1551) loss_u 0.0151 (0.0345) acc_x 87.5000 (94.5000) acc_u 87.5000 (86.1875) gamma_v 0.0557 (0.0541) gamma_t 0.2184 (0.2177) loss_x_ind 0.0647 (0.0546)\tlr 8.898950e-04\n",
      "epoch [12/30][200/500]\ttime 0.538 (0.239)\tdata 0.004 (0.002)\teta 0:37:06\tloss 0.0831 (-1.0280) loss_x 0.3218 (0.1514) loss_u 0.1599 (0.0341) acc_x 90.6250 (94.5156) acc_u 78.1250 (86.3281) gamma_v 0.0612 (0.0548) gamma_t 0.2165 (0.2190) loss_x_ind 0.0701 (0.0511)\tlr 2.991783e-03\n",
      "epoch [12/30][300/500]\ttime 0.233 (0.238)\tdata 0.001 (0.002)\teta 0:36:29\tloss -0.9068 (-1.0399) loss_x 0.1399 (0.1456) loss_u 0.0508 (0.0342) acc_x 96.8750 (94.6875) acc_u 87.5000 (86.2917) gamma_v 0.0553 (0.0559) gamma_t 0.2230 (0.2197) loss_x_ind 0.0237 (0.0502)\tlr 6.183221e-04\n",
      "epoch [12/30][400/500]\ttime 0.232 (0.241)\tdata 0.001 (0.002)\teta 0:36:34\tloss -1.2607 (-1.0555) loss_x 0.1661 (0.1459) loss_u 0.0079 (0.0334) acc_x 93.7500 (94.6250) acc_u 84.3750 (86.2344) gamma_v 0.0596 (0.0578) gamma_t 0.2216 (0.2204) loss_x_ind 0.0226 (0.0491)\tlr 8.898950e-04\n",
      "epoch [12/30][500/500]\ttime 0.528 (0.242)\tdata 0.005 (0.002)\teta 0:36:18\tloss -0.6711 (-1.0466) loss_x 0.2922 (0.1469) loss_u 0.0292 (0.0335) acc_x 84.3750 (94.6312) acc_u 75.0000 (86.1937) gamma_v 0.0675 (0.0585) gamma_t 0.2226 (0.2209) loss_x_ind 0.0267 (0.0488)\tlr 2.991783e-03\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,508\n",
      "* accuracy: 87.6%\n",
      "* error: 12.4%\n",
      "* macro_f1: 88.5%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,606\tacc: 98.9%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,202\tacc: 92.1%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,364\tacc: 93.0%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 8,089\tacc: 77.8%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,626\tacc: 98.6%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,995\tacc: 96.1%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,486\tacc: 94.7%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,334\tacc: 83.3%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,157\tacc: 91.4%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,170\tacc: 95.1%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,980\tacc: 94.0%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,499\tacc: 63.1%\n",
      "* average: 89.8%\n",
      "test_batch_time: 0.092\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/prompt_learner/model-best.pth.tar\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/context_decoder/model-best.pth.tar\n",
      "epoch [13/30][100/500]\ttime 0.239 (0.243)\tdata 0.001 (0.004)\teta 0:36:06\tloss -0.6911 (-1.0721) loss_x 0.1470 (0.1485) loss_u 0.0272 (0.0286) acc_x 93.7500 (94.5938) acc_u 87.5000 (87.4688) gamma_v 0.0538 (0.0624) gamma_t 0.2253 (0.2211) loss_x_ind 0.0656 (0.0475)\tlr 6.183221e-04\n",
      "epoch [13/30][200/500]\ttime 0.230 (0.248)\tdata 0.001 (0.002)\teta 0:36:26\tloss -0.7482 (-1.0684) loss_x 0.1990 (0.1509) loss_u 0.0295 (0.0293) acc_x 93.7500 (94.4531) acc_u 84.3750 (86.9062) gamma_v 0.0591 (0.0603) gamma_t 0.2252 (0.2235) loss_x_ind 0.0304 (0.0475)\tlr 8.898950e-04\n",
      "epoch [13/30][300/500]\ttime 0.215 (0.245)\tdata 0.001 (0.002)\teta 0:35:34\tloss -0.5273 (-1.0400) loss_x 0.0614 (0.1553) loss_u 0.0376 (0.0312) acc_x 96.8750 (94.3333) acc_u 90.6250 (86.5312) gamma_v 0.0592 (0.0595) gamma_t 0.2245 (0.2248) loss_x_ind 0.0682 (0.0490)\tlr 2.991783e-03\n",
      "epoch [13/30][400/500]\ttime 0.218 (0.238)\tdata 0.001 (0.002)\teta 0:34:06\tloss -1.3888 (-1.0532) loss_x 0.2901 (0.1492) loss_u 0.0173 (0.0305) acc_x 90.6250 (94.5625) acc_u 93.7500 (86.7891) gamma_v 0.0552 (0.0596) gamma_t 0.2311 (0.2249) loss_x_ind 0.0552 (0.0498)\tlr 6.183221e-04\n",
      "epoch [13/30][500/500]\ttime 0.236 (0.238)\tdata 0.001 (0.002)\teta 0:33:41\tloss -1.0312 (-1.0652) loss_x 0.1060 (0.1456) loss_u 0.0502 (0.0307) acc_x 96.8750 (94.6688) acc_u 84.3750 (86.5875) gamma_v 0.0677 (0.0599) gamma_t 0.2305 (0.2260) loss_x_ind 0.0334 (0.0482)\tlr 8.898950e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 47,998\n",
      "* accuracy: 86.7%\n",
      "* error: 13.3%\n",
      "* macro_f1: 87.3%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,608\tacc: 99.0%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,221\tacc: 92.7%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,373\tacc: 93.2%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 8,143\tacc: 78.3%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,616\tacc: 98.4%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,993\tacc: 96.0%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,483\tacc: 94.6%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,258\tacc: 81.5%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,178\tacc: 91.8%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,169\tacc: 95.1%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,969\tacc: 93.7%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 2,987\tacc: 53.8%\n",
      "* average: 89.0%\n",
      "test_batch_time: 0.095\n",
      "epoch [14/30][100/500]\ttime 0.243 (0.253)\tdata 0.001 (0.004)\teta 0:35:22\tloss -1.0255 (-1.1220) loss_x 0.0296 (0.1346) loss_u 0.0453 (0.0283) acc_x 100.0000 (95.3125) acc_u 87.5000 (86.4375) gamma_v 0.0657 (0.0645) gamma_t 0.2281 (0.2305) loss_x_ind 0.0156 (0.0414)\tlr 2.991783e-03\n",
      "epoch [14/30][200/500]\ttime 0.241 (0.253)\tdata 0.001 (0.003)\teta 0:34:58\tloss -1.1336 (-1.0855) loss_x 0.1055 (0.1425) loss_u 0.0187 (0.0308) acc_x 96.8750 (94.8594) acc_u 84.3750 (86.1250) gamma_v 0.0641 (0.0626) gamma_t 0.2321 (0.2317) loss_x_ind 0.0677 (0.0444)\tlr 6.183221e-04\n",
      "epoch [14/30][300/500]\ttime 0.240 (0.249)\tdata 0.001 (0.002)\teta 0:34:01\tloss -1.0658 (-1.0919) loss_x 0.0312 (0.1444) loss_u 0.0376 (0.0314) acc_x 100.0000 (94.8125) acc_u 90.6250 (86.2083) gamma_v 0.0690 (0.0627) gamma_t 0.2320 (0.2324) loss_x_ind 0.0284 (0.0445)\tlr 8.898950e-04\n",
      "epoch [14/30][400/500]\ttime 0.225 (0.247)\tdata 0.001 (0.002)\teta 0:33:19\tloss -1.3080 (-1.0798) loss_x 0.1664 (0.1462) loss_u 0.0155 (0.0314) acc_x 93.7500 (94.6484) acc_u 78.1250 (86.2812) gamma_v 0.0690 (0.0643) gamma_t 0.2321 (0.2319) loss_x_ind 0.1050 (0.0456)\tlr 2.991783e-03\n",
      "epoch [14/30][500/500]\ttime 0.234 (0.247)\tdata 0.001 (0.002)\teta 0:32:56\tloss -1.1721 (-1.0682) loss_x 0.2009 (0.1438) loss_u 0.0204 (0.0323) acc_x 90.6250 (94.7062) acc_u 87.5000 (86.1875) gamma_v 0.0647 (0.0650) gamma_t 0.2353 (0.2324) loss_x_ind 0.0417 (0.0475)\tlr 6.183221e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 47,961\n",
      "* accuracy: 86.6%\n",
      "* error: 13.4%\n",
      "* macro_f1: 87.5%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,612\tacc: 99.1%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,208\tacc: 92.3%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,374\tacc: 93.3%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,659\tacc: 73.6%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,614\tacc: 98.4%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 2,007\tacc: 96.7%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,445\tacc: 93.9%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,289\tacc: 82.2%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,140\tacc: 91.0%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,187\tacc: 95.9%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,034\tacc: 95.2%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,392\tacc: 61.1%\n",
      "* average: 89.4%\n",
      "test_batch_time: 0.095\n",
      "epoch [15/30][100/500]\ttime 0.242 (0.243)\tdata 0.001 (0.004)\teta 0:32:03\tloss -1.2043 (-1.0298) loss_x 0.0812 (0.1530) loss_u 0.0535 (0.0328) acc_x 96.8750 (94.1562) acc_u 78.1250 (85.1875) gamma_v 0.0650 (0.0629) gamma_t 0.2360 (0.2312) loss_x_ind 0.0218 (0.0454)\tlr 8.898950e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [15/30][200/500]\ttime 0.231 (0.238)\tdata 0.001 (0.002)\teta 0:30:54\tloss -1.5846 (-1.0747) loss_x 0.0082 (0.1422) loss_u 0.0226 (0.0329) acc_x 100.0000 (94.6250) acc_u 93.7500 (85.6406) gamma_v 0.0667 (0.0613) gamma_t 0.2422 (0.2341) loss_x_ind 0.0564 (0.0473)\tlr 2.991783e-03\n",
      "epoch [15/30][300/500]\ttime 0.237 (0.243)\tdata 0.001 (0.002)\teta 0:31:07\tloss -1.5187 (-1.0872) loss_x 0.0672 (0.1416) loss_u 0.0149 (0.0327) acc_x 96.8750 (94.6042) acc_u 84.3750 (85.6667) gamma_v 0.0685 (0.0629) gamma_t 0.2433 (0.2369) loss_x_ind 0.0256 (0.0467)\tlr 6.183221e-04\n",
      "epoch [15/30][400/500]\ttime 0.232 (0.240)\tdata 0.001 (0.002)\teta 0:30:26\tloss -1.3245 (-1.1066) loss_x 0.2614 (0.1382) loss_u 0.0354 (0.0325) acc_x 90.6250 (94.8047) acc_u 84.3750 (85.8516) gamma_v 0.0666 (0.0640) gamma_t 0.2395 (0.2377) loss_x_ind 0.0445 (0.0456)\tlr 8.898950e-04\n",
      "epoch [15/30][500/500]\ttime 0.234 (0.240)\tdata 0.001 (0.002)\teta 0:30:02\tloss -1.0547 (-1.1018) loss_x 0.2107 (0.1384) loss_u 0.0404 (0.0321) acc_x 90.6250 (94.7438) acc_u 78.1250 (86.0563) gamma_v 0.0660 (0.0637) gamma_t 0.2491 (0.2388) loss_x_ind 0.0438 (0.0455)\tlr 2.991783e-03\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,240\n",
      "* accuracy: 87.1%\n",
      "* error: 12.9%\n",
      "* macro_f1: 87.9%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,603\tacc: 98.8%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,225\tacc: 92.8%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,344\tacc: 92.6%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,745\tacc: 74.5%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,622\tacc: 98.5%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 2,022\tacc: 97.4%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,447\tacc: 94.0%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,224\tacc: 80.6%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,132\tacc: 90.8%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,171\tacc: 95.2%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,049\tacc: 95.6%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,656\tacc: 65.9%\n",
      "* average: 89.7%\n",
      "test_batch_time: 0.096\n",
      "epoch [16/30][100/500]\ttime 0.224 (0.235)\tdata 0.001 (0.003)\teta 0:29:02\tloss -0.5565 (-1.0667) loss_x 0.3255 (0.1360) loss_u 0.0174 (0.0379) acc_x 87.5000 (95.0938) acc_u 84.3750 (85.1562) gamma_v 0.0571 (0.0647) gamma_t 0.2457 (0.2445) loss_x_ind 0.0215 (0.0396)\tlr 6.183221e-04\n",
      "epoch [16/30][200/500]\ttime 0.242 (0.238)\tdata 0.001 (0.002)\teta 0:28:57\tloss -0.1881 (-1.0513) loss_x 0.3280 (0.1405) loss_u 0.0554 (0.0350) acc_x 81.2500 (94.7031) acc_u 81.2500 (85.4531) gamma_v 0.0648 (0.0647) gamma_t 0.2452 (0.2450) loss_x_ind 0.0247 (0.0408)\tlr 8.898950e-04\n",
      "epoch [16/30][300/500]\ttime 0.243 (0.237)\tdata 0.001 (0.002)\teta 0:28:24\tloss -0.3862 (-1.0616) loss_x 0.2297 (0.1359) loss_u 0.0480 (0.0342) acc_x 93.7500 (94.9062) acc_u 78.1250 (85.7188) gamma_v 0.0639 (0.0635) gamma_t 0.2438 (0.2460) loss_x_ind 0.0322 (0.0416)\tlr 2.991783e-03\n",
      "epoch [16/30][400/500]\ttime 0.238 (0.240)\tdata 0.001 (0.002)\teta 0:28:22\tloss -1.0147 (-1.0604) loss_x 0.0717 (0.1383) loss_u 0.0285 (0.0337) acc_x 96.8750 (94.7500) acc_u 87.5000 (85.8203) gamma_v 0.0581 (0.0635) gamma_t 0.2503 (0.2461) loss_x_ind 0.0350 (0.0429)\tlr 6.183221e-04\n",
      "epoch [16/30][500/500]\ttime 0.237 (0.242)\tdata 0.001 (0.002)\teta 0:28:13\tloss -1.1641 (-1.0559) loss_x 0.0826 (0.1369) loss_u 0.0168 (0.0333) acc_x 96.8750 (94.8375) acc_u 81.2500 (85.8563) gamma_v 0.0682 (0.0637) gamma_t 0.2471 (0.2468) loss_x_ind 0.0481 (0.0441)\tlr 8.898950e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,363\n",
      "* accuracy: 87.3%\n",
      "* error: 12.7%\n",
      "* macro_f1: 88.1%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,610\tacc: 99.0%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,281\tacc: 94.4%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,246\tacc: 90.5%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,849\tacc: 75.5%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,629\tacc: 98.7%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 2,016\tacc: 97.2%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,377\tacc: 92.8%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,287\tacc: 82.2%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,170\tacc: 91.7%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,166\tacc: 95.0%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,009\tacc: 94.6%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,723\tacc: 67.1%\n",
      "* average: 89.9%\n",
      "test_batch_time: 0.094\n",
      "epoch [17/30][100/500]\ttime 0.239 (0.248)\tdata 0.001 (0.003)\teta 0:28:33\tloss -0.7853 (-1.0996) loss_x 0.2303 (0.1367) loss_u 0.0154 (0.0306) acc_x 90.6250 (95.0938) acc_u 84.3750 (87.2188) gamma_v 0.0618 (0.0669) gamma_t 0.2524 (0.2492) loss_x_ind 0.0440 (0.0426)\tlr 2.991783e-03\n",
      "epoch [17/30][200/500]\ttime 0.231 (0.242)\tdata 0.001 (0.002)\teta 0:27:24\tloss -1.1538 (-1.0919) loss_x 0.1609 (0.1358) loss_u 0.0355 (0.0309) acc_x 96.8750 (95.3438) acc_u 87.5000 (86.6875) gamma_v 0.0683 (0.0659) gamma_t 0.2525 (0.2503) loss_x_ind 0.0314 (0.0441)\tlr 6.183221e-04\n",
      "epoch [17/30][300/500]\ttime 0.234 (0.243)\tdata 0.001 (0.002)\teta 0:27:06\tloss -1.1586 (-1.0861) loss_x 0.3314 (0.1390) loss_u 0.0309 (0.0309) acc_x 87.5000 (95.0104) acc_u 90.6250 (86.6146) gamma_v 0.0645 (0.0661) gamma_t 0.2578 (0.2516) loss_x_ind 0.0951 (0.0456)\tlr 8.898950e-04\n",
      "epoch [17/30][400/500]\ttime 0.232 (0.243)\tdata 0.001 (0.002)\teta 0:26:45\tloss -1.3886 (-1.1105) loss_x 0.1715 (0.1358) loss_u 0.0097 (0.0310) acc_x 93.7500 (95.0625) acc_u 93.7500 (86.6406) gamma_v 0.0692 (0.0675) gamma_t 0.2546 (0.2526) loss_x_ind 0.0196 (0.0452)\tlr 2.991783e-03\n",
      "epoch [17/30][500/500]\ttime 0.235 (0.241)\tdata 0.001 (0.002)\teta 0:26:06\tloss -0.4750 (-1.1162) loss_x 0.4208 (0.1371) loss_u 0.0446 (0.0307) acc_x 84.3750 (94.9875) acc_u 84.3750 (86.8688) gamma_v 0.0774 (0.0675) gamma_t 0.2614 (0.2537) loss_x_ind 0.0217 (0.0449)\tlr 6.183221e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,172\n",
      "* accuracy: 87.0%\n",
      "* error: 13.0%\n",
      "* macro_f1: 87.8%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,609\tacc: 99.0%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,206\tacc: 92.3%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,397\tacc: 93.8%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,916\tacc: 76.1%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,618\tacc: 98.4%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,975\tacc: 95.2%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,460\tacc: 94.2%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,328\tacc: 83.2%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,303\tacc: 94.6%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,165\tacc: 94.9%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,976\tacc: 93.9%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,219\tacc: 58.0%\n",
      "* average: 89.5%\n",
      "test_batch_time: 0.096\n",
      "epoch [18/30][100/500]\ttime 0.241 (0.229)\tdata 0.001 (0.003)\teta 0:24:26\tloss -1.3044 (-1.0835) loss_x 0.2272 (0.1418) loss_u 0.0087 (0.0312) acc_x 93.7500 (94.8125) acc_u 84.3750 (87.7500) gamma_v 0.0733 (0.0664) gamma_t 0.2620 (0.2602) loss_x_ind 0.0202 (0.0473)\tlr 8.898950e-04\n",
      "epoch [18/30][200/500]\ttime 0.233 (0.236)\tdata 0.001 (0.002)\teta 0:24:49\tloss -0.9529 (-1.1215) loss_x 0.1733 (0.1344) loss_u 0.0778 (0.0310) acc_x 90.6250 (95.0625) acc_u 87.5000 (87.3438) gamma_v 0.0798 (0.0695) gamma_t 0.2572 (0.2586) loss_x_ind 0.0420 (0.0458)\tlr 2.991783e-03\n",
      "epoch [18/30][300/500]\ttime 0.240 (0.241)\tdata 0.001 (0.002)\teta 0:24:51\tloss -0.5790 (-1.1092) loss_x 0.0520 (0.1334) loss_u 0.0341 (0.0316) acc_x 100.0000 (95.0833) acc_u 90.6250 (87.2708) gamma_v 0.0607 (0.0697) gamma_t 0.2502 (0.2566) loss_x_ind 0.0411 (0.0468)\tlr 6.183221e-04\n",
      "epoch [18/30][400/500]\ttime 0.219 (0.235)\tdata 0.001 (0.002)\teta 0:23:55\tloss -1.8879 (-1.1077) loss_x 0.0565 (0.1307) loss_u 0.0031 (0.0321) acc_x 100.0000 (95.1797) acc_u 90.6250 (86.9609) gamma_v 0.0720 (0.0680) gamma_t 0.2582 (0.2574) loss_x_ind 0.0319 (0.0461)\tlr 8.898950e-04\n",
      "epoch [18/30][500/500]\ttime 0.196 (0.231)\tdata 0.001 (0.001)\teta 0:23:03\tloss -1.0760 (-1.0974) loss_x 0.1924 (0.1318) loss_u 0.0192 (0.0325) acc_x 93.7500 (95.0750) acc_u 100.0000 (86.8312) gamma_v 0.0682 (0.0681) gamma_t 0.2619 (0.2583) loss_x_ind 0.0237 (0.0443)\tlr 2.991783e-03\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,156\n",
      "* accuracy: 86.9%\n",
      "* error: 13.1%\n",
      "* macro_f1: 88.1%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,603\tacc: 98.8%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,217\tacc: 92.6%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,351\tacc: 92.8%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,373\tacc: 70.9%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,624\tacc: 98.6%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 2,016\tacc: 97.2%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,498\tacc: 94.9%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,411\tacc: 85.3%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,146\tacc: 91.1%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,123\tacc: 93.1%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,001\tacc: 94.5%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,793\tacc: 68.4%\n",
      "* average: 89.8%\n",
      "test_batch_time: 0.093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [19/30][100/500]\ttime 0.243 (0.253)\tdata 0.001 (0.004)\teta 0:24:53\tloss -1.1806 (-1.1639) loss_x 0.0596 (0.1183) loss_u 0.0460 (0.0312) acc_x 96.8750 (95.3750) acc_u 81.2500 (86.8438) gamma_v 0.0680 (0.0667) gamma_t 0.2584 (0.2598) loss_x_ind 0.0309 (0.0414)\tlr 6.183221e-04\n",
      "epoch [19/30][200/500]\ttime 0.238 (0.246)\tdata 0.001 (0.003)\teta 0:23:48\tloss -1.3336 (-1.1086) loss_x 0.0784 (0.1265) loss_u 0.0111 (0.0316) acc_x 100.0000 (95.2031) acc_u 96.8750 (86.4062) gamma_v 0.0596 (0.0697) gamma_t 0.2700 (0.2631) loss_x_ind 0.0430 (0.0438)\tlr 8.898950e-04\n",
      "epoch [19/30][300/500]\ttime 0.216 (0.243)\tdata 0.001 (0.002)\teta 0:23:04\tloss -1.4838 (-1.1257) loss_x 0.1289 (0.1265) loss_u 0.0233 (0.0312) acc_x 93.7500 (95.3333) acc_u 81.2500 (86.1979) gamma_v 0.0673 (0.0689) gamma_t 0.2691 (0.2648) loss_x_ind 0.0528 (0.0422)\tlr 2.991783e-03\n",
      "epoch [19/30][400/500]\ttime 0.218 (0.240)\tdata 0.001 (0.002)\teta 0:22:25\tloss -1.1729 (-1.1303) loss_x 0.1275 (0.1248) loss_u 0.0227 (0.0318) acc_x 96.8750 (95.4766) acc_u 93.7500 (86.3438) gamma_v 0.0732 (0.0701) gamma_t 0.2699 (0.2654) loss_x_ind 0.0450 (0.0416)\tlr 6.183221e-04\n",
      "epoch [19/30][500/500]\ttime 0.236 (0.236)\tdata 0.001 (0.002)\teta 0:21:38\tloss -1.2934 (-1.1122) loss_x 0.1354 (0.1281) loss_u 0.0169 (0.0330) acc_x 93.7500 (95.3750) acc_u 90.6250 (86.2938) gamma_v 0.0611 (0.0703) gamma_t 0.2753 (0.2677) loss_x_ind 0.0258 (0.0416)\tlr 8.898950e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,473\n",
      "* accuracy: 87.5%\n",
      "* error: 12.5%\n",
      "* macro_f1: 88.3%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,609\tacc: 99.0%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,227\tacc: 92.9%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,359\tacc: 92.9%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 8,270\tacc: 79.5%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,614\tacc: 98.4%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,961\tacc: 94.5%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,424\tacc: 93.6%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,336\tacc: 83.4%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,216\tacc: 92.7%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,188\tacc: 95.9%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,945\tacc: 93.1%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,324\tacc: 59.9%\n",
      "* average: 89.6%\n",
      "test_batch_time: 0.098\n",
      "epoch [20/30][100/500]\ttime 0.207 (0.217)\tdata 0.001 (0.004)\teta 0:19:33\tloss -0.6567 (-1.0500) loss_x 0.2015 (0.1440) loss_u 0.0636 (0.0315) acc_x 93.7500 (95.2500) acc_u 87.5000 (86.7812) gamma_v 0.0796 (0.0708) gamma_t 0.2792 (0.2760) loss_x_ind 0.0262 (0.0399)\tlr 2.991783e-03\n",
      "epoch [20/30][200/500]\ttime 0.224 (0.220)\tdata 0.001 (0.002)\teta 0:19:25\tloss -1.6018 (-1.0713) loss_x 0.0310 (0.1447) loss_u 0.0185 (0.0320) acc_x 100.0000 (95.0000) acc_u 84.3750 (86.7812) gamma_v 0.0696 (0.0719) gamma_t 0.2724 (0.2752) loss_x_ind 0.0482 (0.0403)\tlr 6.183221e-04\n",
      "epoch [20/30][300/500]\ttime 0.240 (0.223)\tdata 0.001 (0.002)\teta 0:19:20\tloss -1.5356 (-1.0881) loss_x 0.1283 (0.1401) loss_u 0.0313 (0.0322) acc_x 96.8750 (95.1458) acc_u 93.7500 (86.4062) gamma_v 0.0670 (0.0736) gamma_t 0.2786 (0.2735) loss_x_ind 0.0364 (0.0398)\tlr 8.898950e-04\n",
      "epoch [20/30][400/500]\ttime 0.219 (0.225)\tdata 0.001 (0.002)\teta 0:19:08\tloss -1.1351 (-1.1114) loss_x 0.0906 (0.1335) loss_u 0.0580 (0.0317) acc_x 93.7500 (95.2969) acc_u 90.6250 (86.4922) gamma_v 0.0752 (0.0735) gamma_t 0.2775 (0.2740) loss_x_ind 0.0206 (0.0398)\tlr 2.991783e-03\n",
      "epoch [20/30][500/500]\ttime 0.211 (0.227)\tdata 0.001 (0.002)\teta 0:18:52\tloss -1.4201 (-1.1037) loss_x 0.1434 (0.1360) loss_u 0.0391 (0.0321) acc_x 96.8750 (95.1937) acc_u 84.3750 (86.4500) gamma_v 0.0767 (0.0738) gamma_t 0.2764 (0.2743) loss_x_ind 0.0194 (0.0406)\tlr 6.183221e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,315\n",
      "* accuracy: 87.2%\n",
      "* error: 12.8%\n",
      "* macro_f1: 88.2%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,602\tacc: 98.8%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,255\tacc: 93.7%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,326\tacc: 92.2%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,541\tacc: 72.5%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,610\tacc: 98.3%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 2,028\tacc: 97.7%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,483\tacc: 94.6%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,345\tacc: 83.6%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,149\tacc: 91.2%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,133\tacc: 93.5%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,999\tacc: 94.4%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,844\tacc: 69.3%\n",
      "* average: 90.0%\n",
      "test_batch_time: 0.093\n",
      "epoch [21/30][100/500]\ttime 0.227 (0.255)\tdata 0.001 (0.004)\teta 0:20:51\tloss -0.7120 (-1.1615) loss_x 0.1179 (0.1272) loss_u 0.0458 (0.0290) acc_x 90.6250 (95.5938) acc_u 81.2500 (87.5938) gamma_v 0.0720 (0.0763) gamma_t 0.2836 (0.2799) loss_x_ind 0.0200 (0.0370)\tlr 8.898950e-04\n",
      "epoch [21/30][200/500]\ttime 0.233 (0.243)\tdata 0.001 (0.002)\teta 0:19:25\tloss -1.2734 (-1.1227) loss_x 0.0303 (0.1281) loss_u 0.0664 (0.0295) acc_x 100.0000 (95.5938) acc_u 81.2500 (86.7031) gamma_v 0.0770 (0.0772) gamma_t 0.2856 (0.2832) loss_x_ind 0.0322 (0.0388)\tlr 2.991783e-03\n",
      "epoch [21/30][300/500]\ttime 0.238 (0.247)\tdata 0.002 (0.002)\teta 0:19:19\tloss -1.4439 (-1.1129) loss_x 0.0085 (0.1233) loss_u 0.0242 (0.0310) acc_x 100.0000 (95.7188) acc_u 96.8750 (86.6354) gamma_v 0.0692 (0.0749) gamma_t 0.2817 (0.2841) loss_x_ind 0.0261 (0.0397)\tlr 6.183221e-04\n",
      "epoch [21/30][400/500]\ttime 0.239 (0.249)\tdata 0.001 (0.002)\teta 0:19:03\tloss -1.2639 (-1.1279) loss_x 0.1643 (0.1248) loss_u 0.0186 (0.0312) acc_x 93.7500 (95.5234) acc_u 87.5000 (86.8516) gamma_v 0.0845 (0.0753) gamma_t 0.2833 (0.2839) loss_x_ind 0.0367 (0.0389)\tlr 8.898950e-04\n",
      "epoch [21/30][500/500]\ttime 0.238 (0.247)\tdata 0.001 (0.002)\teta 0:18:29\tloss -1.0335 (-1.1145) loss_x 0.2805 (0.1255) loss_u 0.0357 (0.0312) acc_x 90.6250 (95.4938) acc_u 93.7500 (86.5563) gamma_v 0.0779 (0.0771) gamma_t 0.2923 (0.2847) loss_x_ind 0.0296 (0.0390)\tlr 2.991783e-03\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,157\n",
      "* accuracy: 86.9%\n",
      "* error: 13.1%\n",
      "* macro_f1: 88.1%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,601\tacc: 98.8%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,147\tacc: 90.6%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,217\tacc: 89.9%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,288\tacc: 70.1%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,608\tacc: 98.2%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 2,017\tacc: 97.2%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,530\tacc: 95.4%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,380\tacc: 84.5%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,140\tacc: 91.0%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,157\tacc: 94.6%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,037\tacc: 95.3%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 4,035\tacc: 72.7%\n",
      "* average: 89.9%\n",
      "test_batch_time: 0.094\n",
      "epoch [22/30][100/500]\ttime 0.204 (0.225)\tdata 0.001 (0.003)\teta 0:16:32\tloss -1.4720 (-1.0629) loss_x 0.0210 (0.1323) loss_u 0.0415 (0.0320) acc_x 100.0000 (95.0625) acc_u 81.2500 (86.4375) gamma_v 0.0669 (0.0701) gamma_t 0.2834 (0.2883) loss_x_ind 0.0311 (0.0411)\tlr 6.183221e-04\n",
      "epoch [22/30][200/500]\ttime 0.205 (0.220)\tdata 0.001 (0.002)\teta 0:15:44\tloss -1.1551 (-1.1066) loss_x 0.0758 (0.1290) loss_u 0.0656 (0.0310) acc_x 100.0000 (95.2031) acc_u 87.5000 (86.3750) gamma_v 0.0783 (0.0722) gamma_t 0.2871 (0.2867) loss_x_ind 0.0212 (0.0407)\tlr 8.898950e-04\n",
      "epoch [22/30][300/500]\ttime 0.208 (0.215)\tdata 0.001 (0.002)\teta 0:15:02\tloss -1.1687 (-1.1109) loss_x 0.2756 (0.1254) loss_u 0.0261 (0.0317) acc_x 87.5000 (95.4271) acc_u 84.3750 (85.9792) gamma_v 0.0823 (0.0757) gamma_t 0.2882 (0.2860) loss_x_ind 0.0726 (0.0415)\tlr 2.991783e-03\n",
      "epoch [22/30][400/500]\ttime 0.234 (0.220)\tdata 0.001 (0.002)\teta 0:15:00\tloss -1.5564 (-1.1279) loss_x 0.0479 (0.1210) loss_u 0.0360 (0.0319) acc_x 100.0000 (95.6328) acc_u 87.5000 (86.2266) gamma_v 0.0784 (0.0760) gamma_t 0.2849 (0.2868) loss_x_ind 0.0233 (0.0408)\tlr 6.183221e-04\n",
      "epoch [22/30][500/500]\ttime 0.233 (0.225)\tdata 0.001 (0.002)\teta 0:14:58\tloss -0.9766 (-1.1246) loss_x 0.1406 (0.1211) loss_u 0.0117 (0.0322) acc_x 96.8750 (95.5938) acc_u 84.3750 (86.2938) gamma_v 0.0752 (0.0758) gamma_t 0.2884 (0.2864) loss_x_ind 0.0889 (0.0410)\tlr 8.898950e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,399\n",
      "* accuracy: 87.4%\n",
      "* error: 12.6%\n",
      "* macro_f1: 88.3%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,609\tacc: 99.0%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,243\tacc: 93.3%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,239\tacc: 90.4%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,695\tacc: 74.0%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,632\tacc: 98.7%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 2,013\tacc: 97.0%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,516\tacc: 95.2%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,342\tacc: 83.5%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,246\tacc: 93.3%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,151\tacc: 94.3%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,010\tacc: 94.7%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,703\tacc: 66.7%\n",
      "* average: 90.0%\n",
      "test_batch_time: 0.096\n",
      "epoch [23/30][100/500]\ttime 0.233 (0.248)\tdata 0.001 (0.003)\teta 0:16:06\tloss -1.1150 (-1.1539) loss_x 0.0435 (0.1143) loss_u 0.0714 (0.0285) acc_x 96.8750 (95.6875) acc_u 84.3750 (87.6875) gamma_v 0.0736 (0.0726) gamma_t 0.2835 (0.2868) loss_x_ind 0.1011 (0.0419)\tlr 2.991783e-03\n",
      "epoch [23/30][200/500]\ttime 0.232 (0.240)\tdata 0.001 (0.002)\teta 0:15:12\tloss -1.3159 (-1.1414) loss_x 0.1466 (0.1188) loss_u 0.0458 (0.0299) acc_x 90.6250 (95.6719) acc_u 90.6250 (87.5781) gamma_v 0.0799 (0.0722) gamma_t 0.2821 (0.2861) loss_x_ind 0.0400 (0.0425)\tlr 6.183221e-04\n",
      "epoch [23/30][300/500]\ttime 0.232 (0.243)\tdata 0.001 (0.002)\teta 0:15:00\tloss -1.1798 (-1.1485) loss_x 0.1138 (0.1233) loss_u 0.0253 (0.0308) acc_x 93.7500 (95.4583) acc_u 93.7500 (87.1354) gamma_v 0.0863 (0.0765) gamma_t 0.2829 (0.2867) loss_x_ind 0.0349 (0.0419)\tlr 8.898950e-04\n",
      "epoch [23/30][400/500]\ttime 0.231 (0.245)\tdata 0.001 (0.002)\teta 0:14:40\tloss -1.5968 (-1.1494) loss_x 0.1319 (0.1281) loss_u 0.0076 (0.0314) acc_x 93.7500 (95.2734) acc_u 90.6250 (86.9922) gamma_v 0.0780 (0.0779) gamma_t 0.2958 (0.2875) loss_x_ind 0.0449 (0.0413)\tlr 2.991783e-03\n",
      "epoch [23/30][500/500]\ttime 0.233 (0.242)\tdata 0.001 (0.002)\teta 0:14:07\tloss -1.2626 (-1.1569) loss_x 0.1136 (0.1262) loss_u 0.0480 (0.0314) acc_x 96.8750 (95.3750) acc_u 87.5000 (86.9813) gamma_v 0.0864 (0.0784) gamma_t 0.2890 (0.2878) loss_x_ind 0.0196 (0.0406)\tlr 6.183221e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,379\n",
      "* accuracy: 87.3%\n",
      "* error: 12.7%\n",
      "* macro_f1: 88.7%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,592\tacc: 98.5%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,191\tacc: 91.8%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,194\tacc: 89.4%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,224\tacc: 69.5%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,636\tacc: 98.8%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 2,020\tacc: 97.3%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,493\tacc: 94.8%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,324\tacc: 83.1%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,249\tacc: 93.4%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,117\tacc: 92.8%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,001\tacc: 94.5%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 4,338\tacc: 78.2%\n",
      "* average: 90.2%\n",
      "test_batch_time: 0.094\n",
      "epoch [24/30][100/500]\ttime 0.215 (0.234)\tdata 0.001 (0.004)\teta 0:13:13\tloss -1.6981 (-1.1101) loss_x 0.0954 (0.1360) loss_u 0.0357 (0.0322) acc_x 96.8750 (95.0625) acc_u 96.8750 (86.9688) gamma_v 0.0887 (0.0813) gamma_t 0.2894 (0.2903) loss_x_ind 0.0344 (0.0403)\tlr 8.898950e-04\n",
      "epoch [24/30][200/500]\ttime 0.239 (0.238)\tdata 0.001 (0.002)\teta 0:13:05\tloss -1.4681 (-1.1219) loss_x 0.0645 (0.1371) loss_u 0.0413 (0.0305) acc_x 96.8750 (95.0000) acc_u 96.8750 (87.0000) gamma_v 0.0900 (0.0851) gamma_t 0.2900 (0.2899) loss_x_ind 0.0388 (0.0408)\tlr 2.991783e-03\n",
      "epoch [24/30][300/500]\ttime 0.232 (0.236)\tdata 0.001 (0.002)\teta 0:12:35\tloss -0.9423 (-1.1165) loss_x 0.1388 (0.1334) loss_u 0.0701 (0.0315) acc_x 93.7500 (95.1250) acc_u 78.1250 (86.8542) gamma_v 0.0767 (0.0840) gamma_t 0.2911 (0.2914) loss_x_ind 0.0260 (0.0399)\tlr 6.183221e-04\n",
      "epoch [24/30][400/500]\ttime 0.230 (0.238)\tdata 0.001 (0.002)\teta 0:12:17\tloss -1.6674 (-1.1047) loss_x 0.0464 (0.1371) loss_u 0.0007 (0.0317) acc_x 100.0000 (95.0703) acc_u 90.6250 (86.8828) gamma_v 0.0839 (0.0825) gamma_t 0.2966 (0.2919) loss_x_ind 0.0462 (0.0399)\tlr 8.898950e-04\n",
      "epoch [24/30][500/500]\ttime 0.230 (0.239)\tdata 0.001 (0.002)\teta 0:11:56\tloss -0.9077 (-1.0987) loss_x 0.0955 (0.1347) loss_u 0.0305 (0.0324) acc_x 93.7500 (95.1562) acc_u 75.0000 (86.6813) gamma_v 0.0888 (0.0823) gamma_t 0.3037 (0.2937) loss_x_ind 0.0680 (0.0397)\tlr 2.991783e-03\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,421\n",
      "* accuracy: 87.4%\n",
      "* error: 12.6%\n",
      "* macro_f1: 88.0%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,606\tacc: 98.9%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,264\tacc: 93.9%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,193\tacc: 89.4%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 8,017\tacc: 77.1%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,623\tacc: 98.6%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,989\tacc: 95.9%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,472\tacc: 94.4%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,192\tacc: 79.8%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,263\tacc: 93.7%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,198\tacc: 96.4%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,030\tacc: 95.1%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,574\tacc: 64.4%\n",
      "* average: 89.8%\n",
      "test_batch_time: 0.096\n",
      "epoch [25/30][100/500]\ttime 0.222 (0.232)\tdata 0.001 (0.003)\teta 0:11:13\tloss -1.2349 (-1.1200) loss_x 0.3069 (0.1284) loss_u 0.0174 (0.0316) acc_x 87.5000 (95.5312) acc_u 90.6250 (86.7500) gamma_v 0.0884 (0.0901) gamma_t 0.3024 (0.3027) loss_x_ind 0.0228 (0.0389)\tlr 6.183221e-04\n",
      "epoch [25/30][200/500]\ttime 0.198 (0.219)\tdata 0.001 (0.002)\teta 0:10:13\tloss -0.6936 (-1.0950) loss_x 0.2107 (0.1335) loss_u 0.0724 (0.0336) acc_x 93.7500 (95.2812) acc_u 87.5000 (86.6250) gamma_v 0.0863 (0.0889) gamma_t 0.3021 (0.3018) loss_x_ind 0.0433 (0.0400)\tlr 8.898950e-04\n",
      "epoch [25/30][300/500]\ttime 0.241 (0.225)\tdata 0.001 (0.002)\teta 0:10:06\tloss -1.3320 (-1.1091) loss_x 0.0930 (0.1314) loss_u 0.0088 (0.0333) acc_x 93.7500 (95.2917) acc_u 93.7500 (86.8854) gamma_v 0.0822 (0.0862) gamma_t 0.3083 (0.3023) loss_x_ind 0.0363 (0.0380)\tlr 2.991783e-03\n",
      "epoch [25/30][400/500]\ttime 0.227 (0.231)\tdata 0.001 (0.002)\teta 0:10:00\tloss -0.7896 (-1.1167) loss_x 0.1468 (0.1307) loss_u 0.0314 (0.0330) acc_x 96.8750 (95.2109) acc_u 78.1250 (87.0312) gamma_v 0.0853 (0.0853) gamma_t 0.3046 (0.3031) loss_x_ind 0.0339 (0.0387)\tlr 6.183221e-04\n",
      "epoch [25/30][500/500]\ttime 0.217 (0.229)\tdata 0.001 (0.001)\teta 0:09:31\tloss -1.2271 (-1.1178) loss_x 0.0756 (0.1322) loss_u 0.0389 (0.0328) acc_x 96.8750 (95.1625) acc_u 75.0000 (86.8563) gamma_v 0.0869 (0.0861) gamma_t 0.3063 (0.3030) loss_x_ind 0.0256 (0.0387)\tlr 8.898950e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,162\n",
      "* accuracy: 87.0%\n",
      "* error: 13.0%\n",
      "* macro_f1: 87.8%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,587\tacc: 98.4%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,216\tacc: 92.5%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,176\tacc: 89.0%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 8,162\tacc: 78.5%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,610\tacc: 98.3%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,989\tacc: 95.9%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,477\tacc: 94.5%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,341\tacc: 83.5%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,087\tacc: 89.8%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,179\tacc: 95.5%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,985\tacc: 94.1%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,353\tacc: 60.4%\n",
      "* average: 89.2%\n",
      "test_batch_time: 0.096\n",
      "epoch [26/30][100/500]\ttime 0.224 (0.218)\tdata 0.001 (0.003)\teta 0:08:42\tloss -0.6811 (-1.1073) loss_x 0.0368 (0.1113) loss_u 0.0349 (0.0309) acc_x 100.0000 (95.7188) acc_u 87.5000 (86.5312) gamma_v 0.0871 (0.0882) gamma_t 0.3012 (0.3039) loss_x_ind 0.0138 (0.0383)\tlr 2.991783e-03\n",
      "epoch [26/30][200/500]\ttime 0.222 (0.227)\tdata 0.001 (0.002)\teta 0:08:41\tloss -1.3616 (-1.1241) loss_x 0.1716 (0.1201) loss_u 0.0477 (0.0310) acc_x 96.8750 (95.5781) acc_u 84.3750 (86.6719) gamma_v 0.0802 (0.0864) gamma_t 0.3038 (0.3037) loss_x_ind 0.0195 (0.0372)\tlr 6.183221e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [26/30][300/500]\ttime 0.223 (0.227)\tdata 0.001 (0.002)\teta 0:08:18\tloss -1.8809 (-1.1331) loss_x 0.0554 (0.1212) loss_u 0.0139 (0.0307) acc_x 100.0000 (95.6250) acc_u 93.7500 (86.9271) gamma_v 0.0786 (0.0848) gamma_t 0.3089 (0.3039) loss_x_ind 0.0653 (0.0369)\tlr 8.898950e-04\n",
      "epoch [26/30][400/500]\ttime 0.228 (0.229)\tdata 0.001 (0.002)\teta 0:08:01\tloss -1.3956 (-1.1376) loss_x 0.1022 (0.1172) loss_u 0.0240 (0.0312) acc_x 96.8750 (95.7188) acc_u 81.2500 (86.9219) gamma_v 0.0797 (0.0850) gamma_t 0.3062 (0.3042) loss_x_ind 0.0668 (0.0375)\tlr 2.991783e-03\n",
      "epoch [26/30][500/500]\ttime 0.240 (0.232)\tdata 0.001 (0.002)\teta 0:07:44\tloss -1.6102 (-1.1335) loss_x 0.0462 (0.1218) loss_u 0.0109 (0.0318) acc_x 100.0000 (95.5438) acc_u 90.6250 (86.8937) gamma_v 0.0811 (0.0839) gamma_t 0.3055 (0.3040) loss_x_ind 0.0193 (0.0380)\tlr 6.183221e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,187\n",
      "* accuracy: 87.0%\n",
      "* error: 13.0%\n",
      "* macro_f1: 88.2%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,595\tacc: 98.6%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,284\tacc: 94.5%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,306\tacc: 91.8%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,152\tacc: 68.8%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,627\tacc: 98.6%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 2,012\tacc: 97.0%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,459\tacc: 94.2%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,287\tacc: 82.2%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,243\tacc: 93.3%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,165\tacc: 94.9%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,984\tacc: 94.1%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 4,073\tacc: 73.4%\n",
      "* average: 90.1%\n",
      "test_batch_time: 0.094\n",
      "epoch [27/30][100/500]\ttime 0.237 (0.247)\tdata 0.001 (0.004)\teta 0:07:49\tloss -1.2340 (-1.1307) loss_x 0.1771 (0.1289) loss_u 0.0019 (0.0337) acc_x 87.5000 (95.3438) acc_u 93.7500 (86.8750) gamma_v 0.0818 (0.0838) gamma_t 0.3105 (0.3066) loss_x_ind 0.0601 (0.0415)\tlr 8.898950e-04\n",
      "epoch [27/30][200/500]\ttime 0.233 (0.241)\tdata 0.001 (0.002)\teta 0:07:14\tloss -1.2877 (-1.1420) loss_x 0.1092 (0.1232) loss_u 0.0325 (0.0321) acc_x 90.6250 (95.5781) acc_u 75.0000 (87.2969) gamma_v 0.0825 (0.0829) gamma_t 0.3043 (0.3062) loss_x_ind 0.0853 (0.0386)\tlr 2.991783e-03\n",
      "epoch [27/30][300/500]\ttime 0.235 (0.244)\tdata 0.001 (0.002)\teta 0:06:55\tloss -0.8155 (-1.1305) loss_x 0.1123 (0.1262) loss_u 0.0392 (0.0317) acc_x 96.8750 (95.5104) acc_u 87.5000 (86.8125) gamma_v 0.0854 (0.0824) gamma_t 0.3058 (0.3056) loss_x_ind 0.0478 (0.0389)\tlr 6.183221e-04\n",
      "epoch [27/30][400/500]\ttime 0.223 (0.243)\tdata 0.001 (0.002)\teta 0:06:28\tloss -1.3942 (-1.1332) loss_x 0.1053 (0.1263) loss_u 0.0497 (0.0315) acc_x 93.7500 (95.4141) acc_u 84.3750 (86.8828) gamma_v 0.0737 (0.0810) gamma_t 0.3040 (0.3063) loss_x_ind 0.0160 (0.0382)\tlr 8.898950e-04\n",
      "epoch [27/30][500/500]\ttime 0.223 (0.239)\tdata 0.001 (0.002)\teta 0:05:58\tloss -0.0221 (-1.1195) loss_x 0.5242 (0.1266) loss_u 0.0355 (0.0319) acc_x 84.3750 (95.4750) acc_u 87.5000 (86.8375) gamma_v 0.0888 (0.0813) gamma_t 0.3108 (0.3067) loss_x_ind 0.0606 (0.0378)\tlr 2.991783e-03\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 47,653\n",
      "* accuracy: 86.0%\n",
      "* error: 14.0%\n",
      "* macro_f1: 86.9%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,525\tacc: 96.7%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,157\tacc: 90.8%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,112\tacc: 87.7%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,067\tacc: 67.9%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,597\tacc: 98.0%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 2,058\tacc: 99.2%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,385\tacc: 92.9%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,320\tacc: 83.0%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,047\tacc: 89.0%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,072\tacc: 90.8%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,977\tacc: 93.9%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 4,336\tacc: 78.2%\n",
      "* average: 89.0%\n",
      "test_batch_time: 0.097\n",
      "epoch [28/30][100/500]\ttime 0.210 (0.229)\tdata 0.001 (0.003)\teta 0:05:20\tloss -1.1643 (-1.0502) loss_x 0.0555 (0.1198) loss_u 0.0315 (0.0351) acc_x 100.0000 (95.1562) acc_u 84.3750 (86.9375) gamma_v 0.0817 (0.0824) gamma_t 0.3174 (0.3144) loss_x_ind 0.0288 (0.0421)\tlr 6.183221e-04\n",
      "epoch [28/30][200/500]\ttime 0.231 (0.234)\tdata 0.001 (0.002)\teta 0:05:04\tloss -1.4269 (-1.0761) loss_x 0.1112 (0.1244) loss_u 0.0045 (0.0350) acc_x 93.7500 (95.1562) acc_u 93.7500 (86.8281) gamma_v 0.0808 (0.0836) gamma_t 0.3090 (0.3109) loss_x_ind 0.0312 (0.0394)\tlr 8.898950e-04\n",
      "epoch [28/30][300/500]\ttime 0.231 (0.234)\tdata 0.001 (0.002)\teta 0:04:40\tloss -1.2164 (-1.0907) loss_x 0.2911 (0.1250) loss_u 0.0368 (0.0344) acc_x 90.6250 (95.2604) acc_u 87.5000 (86.8542) gamma_v 0.0828 (0.0826) gamma_t 0.3087 (0.3095) loss_x_ind 0.0170 (0.0393)\tlr 2.991783e-03\n",
      "epoch [28/30][400/500]\ttime 0.232 (0.237)\tdata 0.001 (0.002)\teta 0:04:21\tloss -1.4997 (-1.1054) loss_x 0.0737 (0.1229) loss_u 0.0214 (0.0336) acc_x 96.8750 (95.2812) acc_u 87.5000 (86.8750) gamma_v 0.0791 (0.0812) gamma_t 0.3043 (0.3098) loss_x_ind 0.0223 (0.0391)\tlr 6.183221e-04\n",
      "epoch [28/30][500/500]\ttime 0.230 (0.238)\tdata 0.000 (0.002)\teta 0:03:58\tloss -1.4014 (-1.0979) loss_x 0.1356 (0.1238) loss_u 0.0254 (0.0340) acc_x 93.7500 (95.2500) acc_u 78.1250 (86.5687) gamma_v 0.0720 (0.0825) gamma_t 0.3115 (0.3093) loss_x_ind 0.0275 (0.0402)\tlr 8.898950e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,190\n",
      "* accuracy: 87.0%\n",
      "* error: 13.0%\n",
      "* macro_f1: 88.2%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,607\tacc: 98.9%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,299\tacc: 94.9%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,290\tacc: 91.5%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,256\tacc: 69.8%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,622\tacc: 98.5%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 2,020\tacc: 97.3%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,376\tacc: 92.8%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,317\tacc: 82.9%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,170\tacc: 91.7%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,151\tacc: 94.3%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,983\tacc: 94.0%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 4,099\tacc: 73.9%\n",
      "* average: 90.0%\n",
      "test_batch_time: 0.097\n",
      "epoch [29/30][100/500]\ttime 0.204 (0.229)\tdata 0.001 (0.003)\teta 0:03:26\tloss -1.5464 (-1.1651) loss_x 0.0272 (0.1165) loss_u 0.0305 (0.0373) acc_x 100.0000 (95.5312) acc_u 90.6250 (85.8750) gamma_v 0.0894 (0.0817) gamma_t 0.3065 (0.3121) loss_x_ind 0.0491 (0.0365)\tlr 2.991783e-03\n",
      "epoch [29/30][200/500]\ttime 0.211 (0.218)\tdata 0.001 (0.002)\teta 0:02:54\tloss -0.8604 (-1.1136) loss_x 0.1045 (0.1292) loss_u 0.0469 (0.0345) acc_x 93.7500 (94.9062) acc_u 78.1250 (85.5938) gamma_v 0.0860 (0.0797) gamma_t 0.3039 (0.3081) loss_x_ind 0.0178 (0.0376)\tlr 6.183221e-04\n",
      "epoch [29/30][300/500]\ttime 0.233 (0.228)\tdata 0.001 (0.002)\teta 0:02:39\tloss -1.8055 (-1.1035) loss_x 0.0358 (0.1269) loss_u 0.0366 (0.0346) acc_x 100.0000 (95.1771) acc_u 87.5000 (85.9896) gamma_v 0.0887 (0.0814) gamma_t 0.3146 (0.3089) loss_x_ind 0.0496 (0.0375)\tlr 8.898950e-04\n",
      "epoch [29/30][400/500]\ttime 0.233 (0.234)\tdata 0.001 (0.002)\teta 0:02:20\tloss -1.0529 (-1.1010) loss_x 0.0688 (0.1267) loss_u 0.0454 (0.0344) acc_x 96.8750 (95.2109) acc_u 90.6250 (86.1953) gamma_v 0.0948 (0.0841) gamma_t 0.3069 (0.3098) loss_x_ind 0.0293 (0.0368)\tlr 2.991783e-03\n",
      "epoch [29/30][500/500]\ttime 0.230 (0.234)\tdata 0.001 (0.001)\teta 0:01:56\tloss -0.5192 (-1.1139) loss_x 0.1185 (0.1273) loss_u 0.0490 (0.0337) acc_x 93.7500 (95.1937) acc_u 84.3750 (86.4125) gamma_v 0.0933 (0.0843) gamma_t 0.3067 (0.3103) loss_x_ind 0.0213 (0.0361)\tlr 6.183221e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,441\n",
      "* accuracy: 87.5%\n",
      "* error: 12.5%\n",
      "* macro_f1: 88.5%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,606\tacc: 98.9%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,207\tacc: 92.3%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,235\tacc: 90.3%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,648\tacc: 73.5%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,617\tacc: 98.4%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,993\tacc: 96.0%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,476\tacc: 94.5%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,357\tacc: 83.9%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,280\tacc: 94.1%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,184\tacc: 95.7%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,046\tacc: 95.5%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,792\tacc: 68.3%\n",
      "* average: 90.1%\n",
      "test_batch_time: 0.096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [30/30][100/500]\ttime 0.242 (0.229)\tdata 0.001 (0.004)\teta 0:01:31\tloss -1.6530 (-1.1456) loss_x 0.0568 (0.1174) loss_u 0.0275 (0.0299) acc_x 100.0000 (95.5000) acc_u 90.6250 (87.1562) gamma_v 0.0840 (0.0847) gamma_t 0.3211 (0.3191) loss_x_ind 0.0185 (0.0327)\tlr 8.898950e-04\n",
      "epoch [30/30][200/500]\ttime 0.197 (0.236)\tdata 0.001 (0.002)\teta 0:01:10\tloss -0.9045 (-1.1532) loss_x 0.0378 (0.1163) loss_u 0.0640 (0.0332) acc_x 100.0000 (95.7344) acc_u 90.6250 (86.7812) gamma_v 0.0767 (0.0839) gamma_t 0.3213 (0.3204) loss_x_ind 0.0137 (0.0343)\tlr 2.991783e-03\n",
      "epoch [30/30][300/500]\ttime 0.198 (0.223)\tdata 0.001 (0.002)\teta 0:00:44\tloss -1.4767 (-1.1452) loss_x 0.0310 (0.1161) loss_u 0.0460 (0.0326) acc_x 100.0000 (95.8750) acc_u 84.3750 (86.8958) gamma_v 0.0919 (0.0842) gamma_t 0.3143 (0.3197) loss_x_ind 0.0447 (0.0356)\tlr 6.183221e-04\n",
      "epoch [30/30][400/500]\ttime 0.194 (0.219)\tdata 0.000 (0.002)\teta 0:00:21\tloss -0.8917 (-1.1302) loss_x 0.1131 (0.1234) loss_u 0.0610 (0.0326) acc_x 93.7500 (95.5859) acc_u 75.0000 (86.8359) gamma_v 0.0832 (0.0845) gamma_t 0.3225 (0.3202) loss_x_ind 0.0468 (0.0365)\tlr 8.898950e-04\n",
      "epoch [30/30][500/500]\ttime 0.224 (0.224)\tdata 0.001 (0.002)\teta 0:00:00\tloss -1.6342 (-1.1242) loss_x 0.0435 (0.1238) loss_u 0.0320 (0.0330) acc_x 100.0000 (95.5687) acc_u 96.8750 (86.7750) gamma_v 0.0870 (0.0841) gamma_t 0.3184 (0.3209) loss_x_ind 0.0330 (0.0360)\tlr 2.991783e-03\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 47,917\n",
      "* accuracy: 86.5%\n",
      "* error: 13.5%\n",
      "* macro_f1: 87.2%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,590\tacc: 98.5%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,250\tacc: 93.5%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,221\tacc: 90.0%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 8,300\tacc: 79.8%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,618\tacc: 98.4%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 2,029\tacc: 97.8%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,415\tacc: 93.4%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,383\tacc: 84.6%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,256\tacc: 93.6%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,159\tacc: 94.7%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,990\tacc: 94.2%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 2,706\tacc: 48.8%\n",
      "* average: 88.9%\n",
      "test_batch_time: 0.094\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/prompt_learner/model.pth.tar-30\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/context_decoder/model.pth.tar-30\n",
      "Finish training\n",
      "Deploy the last-epoch model\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 47,917\n",
      "* accuracy: 86.5%\n",
      "* error: 13.5%\n",
      "* macro_f1: 87.2%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,590\tacc: 98.5%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,250\tacc: 93.5%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,221\tacc: 90.0%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 8,300\tacc: 79.8%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,618\tacc: 98.4%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 2,029\tacc: 97.8%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,415\tacc: 93.4%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,383\tacc: 84.6%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,256\tacc: 93.6%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,159\tacc: 94.7%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,990\tacc: 94.2%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 2,706\tacc: 48.8%\n",
      "* average: 88.9%\n",
      "test_batch_time: 0.096\n",
      "Elapsed: 1:21:04\n"
     ]
    }
   ],
   "source": [
    "!sh VisDA17.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fb6dff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4e14c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e64bf87c",
   "metadata": {},
   "source": [
    "## damp1 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f90a81df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-31 12:41:26.336095: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-31 12:41:26.346811: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-31 12:41:26.358759: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-31 12:41:26.362297: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-31 12:41:26.373137: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-31 12:41:27.024318: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/hbcho991/DAMP/DAMP/trainers/damp.py:214: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/home/hbcho991/DAMP/DAMP/trainers/damp.py:236: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/home/hbcho991/DAMP/DAMP/trainers/damp.py:302: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/home/hbcho991/DAMP/DAMP/trainers/damp.py:403: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/home/hbcho991/DAMP/DAMP/trainers/damp.py:443: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "['TRAINER.DAMP.TAU', '0.5', 'TRAINER.DAMP.U', '2.0']\n",
      "DATALOADER:\n",
      "  K_TRANSFORMS: 1\n",
      "  NUM_WORKERS: 4\n",
      "  RETURN_IMG0: False\n",
      "  TEST:\n",
      "    BATCH_SIZE: 128\n",
      "    SAMPLER: SequentialSampler\n",
      "  TRAIN_U:\n",
      "    BATCH_SIZE: 32\n",
      "    N_DOMAIN: 0\n",
      "    N_INS: 16\n",
      "    SAME_AS_X: True\n",
      "    SAMPLER: RandomSampler\n",
      "  TRAIN_X:\n",
      "    BATCH_SIZE: 32\n",
      "    N_DOMAIN: 0\n",
      "    N_INS: 16\n",
      "    SAMPLER: RandomSampler\n",
      "DATASET:\n",
      "  ALL_AS_UNLABELED: False\n",
      "  CIFAR_C_LEVEL: 1\n",
      "  CIFAR_C_TYPE: \n",
      "  NAME: VISDA_C\n",
      "  NUM_LABELED: -1\n",
      "  NUM_SHOTS: -1\n",
      "  ROOT: /home/dataset/\n",
      "  SOURCE_DOMAINS: ['synthetic']\n",
      "  STL10_FOLD: -1\n",
      "  TARGET_DOMAINS: ['real']\n",
      "  VAL_PERCENT: 0.1\n",
      "INPUT:\n",
      "  COLORJITTER_B: 0.4\n",
      "  COLORJITTER_C: 0.4\n",
      "  COLORJITTER_H: 0.1\n",
      "  COLORJITTER_S: 0.4\n",
      "  CROP_PADDING: 4\n",
      "  CUTOUT_LEN: 16\n",
      "  CUTOUT_N: 1\n",
      "  GB_K: 21\n",
      "  GB_P: 0.5\n",
      "  GN_MEAN: 0.0\n",
      "  GN_STD: 0.15\n",
      "  INTERPOLATION: bicubic\n",
      "  NO_TRANSFORM: False\n",
      "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
      "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
      "  RANDAUGMENT_M: 10\n",
      "  RANDAUGMENT_N: 2\n",
      "  RGS_P: 0.2\n",
      "  RRCROP_SCALE: (0.08, 1.0)\n",
      "  SIZE: (224, 224)\n",
      "  TRANSFORMS: ('normalize',)\n",
      "MODEL:\n",
      "  BACKBONE:\n",
      "    NAME: ViT-B/16\n",
      "    PATH: ./assets\n",
      "    PRETRAINED: True\n",
      "  HEAD:\n",
      "    ACTIVATION: relu\n",
      "    BN: True\n",
      "    DROPOUT: 0.0\n",
      "    HIDDEN_LAYERS: ()\n",
      "    NAME: \n",
      "  INIT_WEIGHTS: \n",
      "  INIT_WEIGHTS_CTX: None\n",
      "  INIT_WEIGHTS_PRO: None\n",
      "OPTIM:\n",
      "  ADAM_BETA1: 0.9\n",
      "  ADAM_BETA2: 0.999\n",
      "  BASE_LR_MULT: 0.1\n",
      "  GAMMA: 0.1\n",
      "  LR: 0.003\n",
      "  LR_SCHEDULER: cosine\n",
      "  MAX_EPOCH: 30\n",
      "  MOMENTUM: 0.9\n",
      "  NAME: adam\n",
      "  NEW_LAYERS: ()\n",
      "  RMSPROP_ALPHA: 0.99\n",
      "  SGD_DAMPNING: 0\n",
      "  SGD_NESTEROV: False\n",
      "  STAGED_LR: False\n",
      "  STEPSIZE: (-1,)\n",
      "  WARMUP_CONS_LR: 1e-05\n",
      "  WARMUP_EPOCH: 1\n",
      "  WARMUP_MIN_LR: 1e-05\n",
      "  WARMUP_RECOUNT: True\n",
      "  WARMUP_TYPE: linear\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "OPTIM_C:\n",
      "  ADAM_BETA1: 0.9\n",
      "  ADAM_BETA2: 0.999\n",
      "  BASE_LR_MULT: 0.1\n",
      "  GAMMA: 0.1\n",
      "  LR: 0.003\n",
      "  LR_SCHEDULER: cosine\n",
      "  MAX_EPOCH: 30\n",
      "  MOMENTUM: 0.9\n",
      "  NAME: adam\n",
      "  NEW_LAYERS: ()\n",
      "  RMSPROP_ALPHA: 0.99\n",
      "  SGD_DAMPNING: 0\n",
      "  SGD_NESTEROV: False\n",
      "  STAGED_LR: False\n",
      "  STEPSIZE: (-1,)\n",
      "  WARMUP_CONS_LR: 1e-05\n",
      "  WARMUP_EPOCH: 1\n",
      "  WARMUP_MIN_LR: 1e-05\n",
      "  WARMUP_RECOUNT: True\n",
      "  WARMUP_TYPE: linear\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "OUTPUT_DIR: output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1\n",
      "RESUME: \n",
      "SEED: 1\n",
      "TEST:\n",
      "  COMPUTE_CMAT: False\n",
      "  EVALUATOR: Classification\n",
      "  FINAL_MODEL: last_step\n",
      "  NO_TEST: False\n",
      "  PER_CLASS_RESULT: True\n",
      "  SPLIT: test\n",
      "TRAIN:\n",
      "  CHECKPOINT_FREQ: 0\n",
      "  COUNT_ITER: train_x\n",
      "  PRINT_FREQ: 100\n",
      "TRAINER:\n",
      "  CDAC:\n",
      "    CLASS_LR_MULTI: 10\n",
      "    P_THRESH: 0.95\n",
      "    RAMPUP_COEF: 30\n",
      "    RAMPUP_ITRS: 1000\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    TOPK_MATCH: 5\n",
      "  CROSSGRAD:\n",
      "    ALPHA_D: 0.5\n",
      "    ALPHA_F: 0.5\n",
      "    EPS_D: 1.0\n",
      "    EPS_F: 1.0\n",
      "  DAEL:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 0.5\n",
      "  DAELDG:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 0.5\n",
      "  DAMP:\n",
      "    CSC: False\n",
      "    IM: 1.0\n",
      "    IND: 1.0\n",
      "    N_CLS: 2\n",
      "    N_CTX: 32\n",
      "    PREC: amp\n",
      "    STRONG_TRANSFORMS: ['randaugment', 'normalize']\n",
      "    TAU: 0.5\n",
      "    U: 2.0\n",
      "  DAPL:\n",
      "    CSC: False\n",
      "    N_CTX: 16\n",
      "    N_DMX: 16\n",
      "    PREC: fp16\n",
      "    T: 1.0\n",
      "    TAU: 0.5\n",
      "    U: 1.0\n",
      "  DDAIG:\n",
      "    ALPHA: 0.5\n",
      "    CLAMP: False\n",
      "    CLAMP_MAX: 1.0\n",
      "    CLAMP_MIN: -1.0\n",
      "    G_ARCH: \n",
      "    LMDA: 0.3\n",
      "    WARMUP: 0\n",
      "  DOMAINMIX:\n",
      "    ALPHA: 1.0\n",
      "    BETA: 1.0\n",
      "    TYPE: crossdomain\n",
      "  ENTMIN:\n",
      "    LMDA: 0.001\n",
      "  FIXMATCH:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 1.0\n",
      "  M3SDA:\n",
      "    LMDA: 0.5\n",
      "    N_STEP_F: 4\n",
      "  MCD:\n",
      "    N_STEP_F: 4\n",
      "  MEANTEACHER:\n",
      "    EMA_ALPHA: 0.999\n",
      "    RAMPUP: 5\n",
      "    WEIGHT_U: 1.0\n",
      "  MIXMATCH:\n",
      "    MIXUP_BETA: 0.75\n",
      "    RAMPUP: 20000\n",
      "    TEMP: 2.0\n",
      "    WEIGHT_U: 100.0\n",
      "  MME:\n",
      "    LMDA: 0.1\n",
      "  NAME: DAMP\n",
      "  SE:\n",
      "    CONF_THRE: 0.95\n",
      "    EMA_ALPHA: 0.999\n",
      "    RAMPUP: 300\n",
      "USE_CUDA: True\n",
      "VERBOSE: True\n",
      "VERSION: 1\n",
      "Setting fixed seed: 1\n",
      "***************\n",
      "** Arguments **\n",
      "***************\n",
      "backbone: \n",
      "config_file: configs/trainers/DAMP/damp.yaml\n",
      "dataset_config_file: configs/datasets/visda17.yaml\n",
      "eval_only: False\n",
      "head: \n",
      "load_epoch: None\n",
      "model_dir: \n",
      "no_train: False\n",
      "opts: ['TRAINER.DAMP.TAU', '0.5', 'TRAINER.DAMP.U', '2.0']\n",
      "output_dir: output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1\n",
      "resume: \n",
      "root: /home/dataset/\n",
      "seed: 1\n",
      "source_domains: ['synthetic']\n",
      "target_domains: ['real']\n",
      "trainer: DAMP\n",
      "transforms: None\n",
      "************\n",
      "** Config **\n",
      "************\n",
      "DATALOADER:\n",
      "  K_TRANSFORMS: 1\n",
      "  NUM_WORKERS: 4\n",
      "  RETURN_IMG0: False\n",
      "  TEST:\n",
      "    BATCH_SIZE: 128\n",
      "    SAMPLER: SequentialSampler\n",
      "  TRAIN_U:\n",
      "    BATCH_SIZE: 32\n",
      "    N_DOMAIN: 0\n",
      "    N_INS: 16\n",
      "    SAME_AS_X: True\n",
      "    SAMPLER: RandomSampler\n",
      "  TRAIN_X:\n",
      "    BATCH_SIZE: 32\n",
      "    N_DOMAIN: 0\n",
      "    N_INS: 16\n",
      "    SAMPLER: RandomSampler\n",
      "DATASET:\n",
      "  ALL_AS_UNLABELED: False\n",
      "  CIFAR_C_LEVEL: 1\n",
      "  CIFAR_C_TYPE: \n",
      "  NAME: VISDA_C\n",
      "  NUM_LABELED: -1\n",
      "  NUM_SHOTS: -1\n",
      "  ROOT: /home/dataset/\n",
      "  SOURCE_DOMAINS: ['synthetic']\n",
      "  STL10_FOLD: -1\n",
      "  TARGET_DOMAINS: ['real']\n",
      "  VAL_PERCENT: 0.1\n",
      "INPUT:\n",
      "  COLORJITTER_B: 0.4\n",
      "  COLORJITTER_C: 0.4\n",
      "  COLORJITTER_H: 0.1\n",
      "  COLORJITTER_S: 0.4\n",
      "  CROP_PADDING: 4\n",
      "  CUTOUT_LEN: 16\n",
      "  CUTOUT_N: 1\n",
      "  GB_K: 21\n",
      "  GB_P: 0.5\n",
      "  GN_MEAN: 0.0\n",
      "  GN_STD: 0.15\n",
      "  INTERPOLATION: bicubic\n",
      "  NO_TRANSFORM: False\n",
      "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
      "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
      "  RANDAUGMENT_M: 10\n",
      "  RANDAUGMENT_N: 2\n",
      "  RGS_P: 0.2\n",
      "  RRCROP_SCALE: (0.08, 1.0)\n",
      "  SIZE: (224, 224)\n",
      "  TRANSFORMS: ('normalize',)\n",
      "MODEL:\n",
      "  BACKBONE:\n",
      "    NAME: ViT-B/16\n",
      "    PATH: ./assets\n",
      "    PRETRAINED: True\n",
      "  HEAD:\n",
      "    ACTIVATION: relu\n",
      "    BN: True\n",
      "    DROPOUT: 0.0\n",
      "    HIDDEN_LAYERS: ()\n",
      "    NAME: \n",
      "  INIT_WEIGHTS: \n",
      "  INIT_WEIGHTS_CTX: None\n",
      "  INIT_WEIGHTS_PRO: None\n",
      "OPTIM:\n",
      "  ADAM_BETA1: 0.9\n",
      "  ADAM_BETA2: 0.999\n",
      "  BASE_LR_MULT: 0.1\n",
      "  GAMMA: 0.1\n",
      "  LR: 0.003\n",
      "  LR_SCHEDULER: cosine\n",
      "  MAX_EPOCH: 30\n",
      "  MOMENTUM: 0.9\n",
      "  NAME: adam\n",
      "  NEW_LAYERS: ()\n",
      "  RMSPROP_ALPHA: 0.99\n",
      "  SGD_DAMPNING: 0\n",
      "  SGD_NESTEROV: False\n",
      "  STAGED_LR: False\n",
      "  STEPSIZE: (-1,)\n",
      "  WARMUP_CONS_LR: 1e-05\n",
      "  WARMUP_EPOCH: 1\n",
      "  WARMUP_MIN_LR: 1e-05\n",
      "  WARMUP_RECOUNT: True\n",
      "  WARMUP_TYPE: linear\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "OPTIM_C:\n",
      "  ADAM_BETA1: 0.9\n",
      "  ADAM_BETA2: 0.999\n",
      "  BASE_LR_MULT: 0.1\n",
      "  GAMMA: 0.1\n",
      "  LR: 0.003\n",
      "  LR_SCHEDULER: cosine\n",
      "  MAX_EPOCH: 30\n",
      "  MOMENTUM: 0.9\n",
      "  NAME: adam\n",
      "  NEW_LAYERS: ()\n",
      "  RMSPROP_ALPHA: 0.99\n",
      "  SGD_DAMPNING: 0\n",
      "  SGD_NESTEROV: False\n",
      "  STAGED_LR: False\n",
      "  STEPSIZE: (-1,)\n",
      "  WARMUP_CONS_LR: 1e-05\n",
      "  WARMUP_EPOCH: 1\n",
      "  WARMUP_MIN_LR: 1e-05\n",
      "  WARMUP_RECOUNT: True\n",
      "  WARMUP_TYPE: linear\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "OUTPUT_DIR: output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1\n",
      "RESUME: \n",
      "SEED: 1\n",
      "TEST:\n",
      "  COMPUTE_CMAT: False\n",
      "  EVALUATOR: Classification\n",
      "  FINAL_MODEL: last_step\n",
      "  NO_TEST: False\n",
      "  PER_CLASS_RESULT: True\n",
      "  SPLIT: test\n",
      "TRAIN:\n",
      "  CHECKPOINT_FREQ: 0\n",
      "  COUNT_ITER: train_x\n",
      "  PRINT_FREQ: 100\n",
      "TRAINER:\n",
      "  CDAC:\n",
      "    CLASS_LR_MULTI: 10\n",
      "    P_THRESH: 0.95\n",
      "    RAMPUP_COEF: 30\n",
      "    RAMPUP_ITRS: 1000\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    TOPK_MATCH: 5\n",
      "  CROSSGRAD:\n",
      "    ALPHA_D: 0.5\n",
      "    ALPHA_F: 0.5\n",
      "    EPS_D: 1.0\n",
      "    EPS_F: 1.0\n",
      "  DAEL:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 0.5\n",
      "  DAELDG:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 0.5\n",
      "  DAMP:\n",
      "    CSC: False\n",
      "    IM: 1.0\n",
      "    IND: 1.0\n",
      "    N_CLS: 2\n",
      "    N_CTX: 32\n",
      "    PREC: amp\n",
      "    STRONG_TRANSFORMS: ['randaugment', 'normalize']\n",
      "    TAU: 0.5\n",
      "    U: 2.0\n",
      "  DAPL:\n",
      "    CSC: False\n",
      "    N_CTX: 16\n",
      "    N_DMX: 16\n",
      "    PREC: fp16\n",
      "    T: 1.0\n",
      "    TAU: 0.5\n",
      "    U: 1.0\n",
      "  DDAIG:\n",
      "    ALPHA: 0.5\n",
      "    CLAMP: False\n",
      "    CLAMP_MAX: 1.0\n",
      "    CLAMP_MIN: -1.0\n",
      "    G_ARCH: \n",
      "    LMDA: 0.3\n",
      "    WARMUP: 0\n",
      "  DOMAINMIX:\n",
      "    ALPHA: 1.0\n",
      "    BETA: 1.0\n",
      "    TYPE: crossdomain\n",
      "  ENTMIN:\n",
      "    LMDA: 0.001\n",
      "  FIXMATCH:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 1.0\n",
      "  M3SDA:\n",
      "    LMDA: 0.5\n",
      "    N_STEP_F: 4\n",
      "  MCD:\n",
      "    N_STEP_F: 4\n",
      "  MEANTEACHER:\n",
      "    EMA_ALPHA: 0.999\n",
      "    RAMPUP: 5\n",
      "    WEIGHT_U: 1.0\n",
      "  MIXMATCH:\n",
      "    MIXUP_BETA: 0.75\n",
      "    RAMPUP: 20000\n",
      "    TEMP: 2.0\n",
      "    WEIGHT_U: 100.0\n",
      "  MME:\n",
      "    LMDA: 0.1\n",
      "  NAME: DAMP\n",
      "  SE:\n",
      "    CONF_THRE: 0.95\n",
      "    EMA_ALPHA: 0.999\n",
      "    RAMPUP: 300\n",
      "USE_CUDA: True\n",
      "VERBOSE: True\n",
      "VERSION: 1\n",
      "Collecting env info ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** System info **\n",
      "PyTorch version: 2.4.0+cu121\n",
      "Is debug build: False\n",
      "CUDA used to build PyTorch: 12.1\n",
      "ROCM used to build PyTorch: N/A\n",
      "\n",
      "OS: Ubuntu 22.04.3 LTS (x86_64)\n",
      "GCC version: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Clang version: Could not collect\n",
      "CMake version: version 3.22.1\n",
      "Libc version: glibc-2.35\n",
      "\n",
      "Python version: 3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0] (64-bit runtime)\n",
      "Python platform: Linux-6.2.0-26-generic-x86_64-with-glibc2.35\n",
      "Is CUDA available: True\n",
      "CUDA runtime version: 12.3.103\n",
      "CUDA_MODULE_LOADING set to: LAZY\n",
      "GPU models and configuration: \n",
      "GPU 0: NVIDIA GeForce RTX 4090\n",
      "GPU 1: NVIDIA GeForce RTX 4090\n",
      "GPU 2: NVIDIA GeForce RTX 4090\n",
      "GPU 3: NVIDIA GeForce RTX 4090\n",
      "GPU 4: NVIDIA GeForce RTX 4090\n",
      "GPU 5: NVIDIA GeForce RTX 4090\n",
      "GPU 6: NVIDIA GeForce RTX 4090\n",
      "GPU 7: NVIDIA GeForce RTX 4090\n",
      "\n",
      "Nvidia driver version: 535.129.03\n",
      "cuDNN version: Could not collect\n",
      "HIP runtime version: N/A\n",
      "MIOpen runtime version: N/A\n",
      "Is XNNPACK available: True\n",
      "\n",
      "CPU:\n",
      "Architecture:                    x86_64\n",
      "CPU op-mode(s):                  32-bit, 64-bit\n",
      "Address sizes:                   46 bits physical, 57 bits virtual\n",
      "Byte Order:                      Little Endian\n",
      "CPU(s):                          32\n",
      "On-line CPU(s) list:             0-31\n",
      "Vendor ID:                       GenuineIntel\n",
      "Model name:                      Intel(R) Xeon(R) Gold 6426Y\n",
      "CPU family:                      6\n",
      "Model:                           143\n",
      "Thread(s) per core:              1\n",
      "Core(s) per socket:              16\n",
      "Socket(s):                       2\n",
      "Stepping:                        8\n",
      "CPU max MHz:                     4100.0000\n",
      "CPU min MHz:                     800.0000\n",
      "BogoMIPS:                        5000.00\n",
      "Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 cat_l2 cdp_l3 invpcid_single intel_ppin cdp_l2 ssbd mba ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm rdt_a avx512f avx512dq rdseed adx smap avx512ifma clflushopt clwb intel_pt avx512cd sha_ni avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local split_lock_detect avx_vnni avx512_bf16 wbnoinvd dtherm ida arat pln pts hwp hwp_act_window hwp_epp hwp_pkg_req hfi avx512vbmi umip pku ospke waitpkg avx512_vbmi2 gfni vaes vpclmulqdq avx512_vnni avx512_bitalg tme avx512_vpopcntdq la57 rdpid bus_lock_detect cldemote movdiri movdir64b enqcmd fsrm md_clear serialize tsxldtrk pconfig arch_lbr ibt amx_bf16 avx512_fp16 amx_tile amx_int8 flush_l1d arch_capabilities\n",
      "Virtualization:                  VT-x\n",
      "L1d cache:                       1.5 MiB (32 instances)\n",
      "L1i cache:                       1 MiB (32 instances)\n",
      "L2 cache:                        64 MiB (32 instances)\n",
      "L3 cache:                        75 MiB (2 instances)\n",
      "NUMA node(s):                    2\n",
      "NUMA node0 CPU(s):               0-15\n",
      "NUMA node1 CPU(s):               16-31\n",
      "Vulnerability Itlb multihit:     Not affected\n",
      "Vulnerability L1tf:              Not affected\n",
      "Vulnerability Mds:               Not affected\n",
      "Vulnerability Meltdown:          Not affected\n",
      "Vulnerability Mmio stale data:   Not affected\n",
      "Vulnerability Retbleed:          Not affected\n",
      "Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl\n",
      "Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization\n",
      "Vulnerability Spectre v2:        Mitigation; Enhanced IBRS, IBPB conditional, RSB filling, PBRSB-eIBRS SW sequence\n",
      "Vulnerability Srbds:             Not affected\n",
      "Vulnerability Tsx async abort:   Not affected\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] flake8==3.7.9\n",
      "[pip3] mypy-extensions==1.0.0\n",
      "[pip3] numpy==1.23.0\n",
      "[pip3] numpydoc==1.5.0\n",
      "[pip3] optree==0.12.1\n",
      "[pip3] torch==2.4.0\n",
      "[pip3] torchvision==0.19.0\n",
      "[pip3] triton==3.0.0\n",
      "[conda] _anaconda_depends         2023.09             py311_mkl_1  \n",
      "[conda] blas                      1.0                         mkl  \n",
      "[conda] mkl                       2023.1.0         h213fc3f_46343  \n",
      "[conda] mkl-service               2.4.0           py311h5eee18b_1  \n",
      "[conda] mkl_fft                   1.3.8           py311h5eee18b_0  \n",
      "[conda] mkl_random                1.2.4           py311hdb19cb5_0  \n",
      "[conda] numpy                     1.24.3          py311h08b1b3b_1  \n",
      "[conda] numpy-base                1.24.3          py311hf175353_1  \n",
      "[conda] numpydoc                  1.5.0           py311h06a4308_0  \n",
      "        Pillow (9.4.0)\n",
      "\n",
      "Loading trainer: DAMP\n",
      "Building transform_train\n",
      "+ resize to 224x224\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
      "Building transform_train\n",
      "+ resize to 224x224\n",
      "+ randaugment (n=2, m=10)\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
      "Loading dataset: VISDA_C\n",
      "* Using custom transform for training\n",
      "Building transform_test\n",
      "+ resize the smaller edge to 224\n",
      "+ 224x224 center crop\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
      "---------  -------------\n",
      "Dataset    VISDA_C\n",
      "Source     ['synthetic']\n",
      "Target     ['real']\n",
      "# classes  12\n",
      "# train_x  152,397\n",
      "# train_u  55,388\n",
      "# test     55,388\n",
      "---------  -------------\n",
      "['aeroplane', 'bicycle', 'bus', 'car', 'horse', 'knife', 'motorcycle', 'person', 'plant', 'skateboard', 'train', 'truck']\n",
      "Loading CLIP (backbone: ViT-B/16)\n",
      "./assets/ViT-B-16.pt\n",
      "Building custom CLIP\n",
      "ContextDecoder(\n",
      "  (memory_proj): Sequential(\n",
      "    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (text_proj): Sequential(\n",
      "    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "  )\n",
      "  (decoder): ModuleList(\n",
      "    (0-5): 6 x TransformerDecoderLayer(\n",
      "      (self_attn): Attention(\n",
      "        (q_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (k_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (v_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (cross_attn): Attention(\n",
      "        (q_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (k_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (v_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "        (3): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (out_proj): Sequential(\n",
      "    (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=256, out_features=512, bias=True)\n",
      "  )\n",
      ")\n",
      "Initializing a generic context\n",
      "ctx vectors size: \n",
      "Initial context: \"X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X\"\n",
      "Number of context words (tokens): 32\n",
      "Number of cls words (tokens): 2\n",
      "Prompts: \"X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X aeroplane.\"\n",
      "Naive Prompts: \"a real photo of a aeroplane.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turning off gradients in both the image and the text encoder\n",
      "Loading evaluator: Classification\n",
      "No checkpoint found, train from scratch\n",
      "Initialize tensorboard (log_dir=output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/tensorboard)\n",
      "epoch [1/30][100/500]\ttime 0.201 (0.211)\tdata 0.001 (0.003)\teta 0:52:28\tloss 0.9679 (4.5665) loss_x 0.7271 (0.4432) loss_u 0.0600 (0.1818) acc_x 84.3750 (86.8438) acc_u 84.3750 (85.1250) gamma_v 0.0150 (0.0175) gamma_t 0.0862 (0.0552) loss_ind 0.9596 (4.0808) loss_im -2.1081 (-1.8698) loss_new 0.0000 (0.1963)\tlr 6.183221e-04\n",
      "epoch [1/30][200/500]\ttime 0.199 (0.217)\tdata 0.000 (0.002)\teta 0:53:35\tloss -0.6667 (2.4123) loss_x 0.0666 (0.3708) loss_u 0.0273 (0.1339) acc_x 96.8750 (88.2812) acc_u 81.2500 (85.6094) gamma_v 0.0205 (0.0170) gamma_t 0.0975 (0.0746) loss_ind 0.3995 (2.4869) loss_im -2.0221 (-1.9613) loss_new 0.0000 (0.0981)\tlr 8.898950e-04\n",
      "epoch [1/30][300/500]\ttime 0.244 (0.223)\tdata 0.002 (0.002)\teta 0:54:45\tloss 0.4953 (1.5705) loss_x 0.3646 (0.3388) loss_u 0.0483 (0.1147) acc_x 78.1250 (89.1667) acc_u 87.5000 (85.2708) gamma_v 0.0173 (0.0177) gamma_t 0.1082 (0.0836) loss_ind 0.5138 (1.8383) loss_im -1.9914 (-1.9968) loss_new 0.0000 (0.0654)\tlr 2.991783e-03\n",
      "epoch [1/30][400/500]\ttime 0.244 (0.227)\tdata 0.001 (0.001)\teta 0:55:12\tloss -0.1308 (1.0844) loss_x 0.1583 (0.3097) loss_u 0.0601 (0.1024) acc_x 90.6250 (90.0156) acc_u 81.2500 (85.3125) gamma_v 0.0183 (0.0181) gamma_t 0.1083 (0.0894) loss_ind 0.2392 (1.4882) loss_im -2.0448 (-2.0163) loss_new 0.0000 (0.0491)\tlr 6.183221e-04\n",
      "epoch [1/30][500/500]\ttime 0.217 (0.231)\tdata 0.001 (0.001)\teta 0:55:42\tloss -0.8519 (0.7919) loss_x 0.1207 (0.2970) loss_u 0.0254 (0.0975) acc_x 93.7500 (90.3250) acc_u 90.6250 (85.2000) gamma_v 0.0221 (0.0183) gamma_t 0.1052 (0.0930) loss_ind 0.3036 (1.2645) loss_im -2.1796 (-2.0278) loss_new 0.0000 (0.0393)\tlr 8.898950e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,193\n",
      "* accuracy: 87.0%\n",
      "* error: 13.0%\n",
      "* macro_f1: 87.8%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,607\tacc: 98.9%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,224\tacc: 92.8%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,364\tacc: 93.0%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,732\tacc: 74.3%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,614\tacc: 98.4%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,984\tacc: 95.6%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,472\tacc: 94.4%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,251\tacc: 81.3%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,180\tacc: 91.9%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,155\tacc: 94.5%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,985\tacc: 94.1%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,625\tacc: 65.3%\n",
      "* average: 89.5%\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/prompt_learner/model-best.pth.tar\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/context_decoder/model-best.pth.tar\n",
      "epoch [2/30][100/500]\ttime 0.246 (0.263)\tdata 0.001 (0.003)\teta 1:03:03\tloss -1.1310 (-0.5273) loss_x 0.1935 (0.2198) loss_u 0.0320 (0.0652) acc_x 90.6250 (91.8125) acc_u 87.5000 (84.9375) gamma_v 0.0246 (0.0227) gamma_t 0.1075 (0.1075) loss_ind 0.1961 (0.3246) loss_im -2.2000 (-2.0873) loss_new 0.0000 (0.0000)\tlr 2.991783e-03\n",
      "epoch [2/30][200/500]\ttime 0.254 (0.255)\tdata 0.001 (0.002)\teta 1:00:47\tloss -0.4701 (-0.5180) loss_x 0.4388 (0.2265) loss_u 0.0468 (0.0671) acc_x 87.5000 (92.0156) acc_u 87.5000 (84.9375) gamma_v 0.0169 (0.0208) gamma_t 0.1098 (0.1084) loss_ind 0.2785 (0.3126) loss_im -2.0325 (-2.0957) loss_new 0.0000 (0.0000)\tlr 6.183221e-04\n",
      "epoch [2/30][300/500]\ttime 0.234 (0.258)\tdata 0.000 (0.001)\teta 1:01:02\tloss -1.1702 (-0.5512) loss_x 0.3079 (0.2191) loss_u 0.0237 (0.0655) acc_x 84.3750 (92.2396) acc_u 81.2500 (85.2812) gamma_v 0.0207 (0.0220) gamma_t 0.1144 (0.1093) loss_ind 0.2036 (0.2945) loss_im -2.1779 (-2.1031) loss_new 0.0000 (0.0000)\tlr 8.898950e-04\n",
      "epoch [2/30][400/500]\ttime 0.233 (0.258)\tdata 0.000 (0.001)\teta 1:00:44\tloss -0.2497 (-0.5782) loss_x 0.5084 (0.2178) loss_u 0.0215 (0.0662) acc_x 87.5000 (92.2109) acc_u 90.6250 (85.1484) gamma_v 0.0240 (0.0218) gamma_t 0.1122 (0.1105) loss_ind 0.2787 (0.2778) loss_im -2.1942 (-2.1003) loss_new 0.0000 (0.0000)\tlr 2.991783e-03\n",
      "epoch [2/30][500/500]\ttime 0.310 (0.251)\tdata 0.000 (0.001)\teta 0:58:38\tloss -0.2811 (-0.5905) loss_x 0.2577 (0.2145) loss_u 0.1003 (0.0663) acc_x 90.6250 (92.4625) acc_u 93.7500 (85.1063) gamma_v 0.0221 (0.0223) gamma_t 0.1119 (0.1110) loss_ind 0.1820 (0.2691) loss_im -2.0446 (-2.0974) loss_new 0.0000 (0.0000)\tlr 6.183221e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,237\n",
      "* accuracy: 87.1%\n",
      "* error: 12.9%\n",
      "* macro_f1: 87.9%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,601\tacc: 98.8%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,203\tacc: 92.2%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,287\tacc: 91.4%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,820\tacc: 75.2%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,626\tacc: 98.6%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,914\tacc: 92.2%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,484\tacc: 94.6%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,380\tacc: 84.5%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,107\tacc: 90.3%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,200\tacc: 96.4%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,985\tacc: 94.1%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,630\tacc: 65.4%\n",
      "* average: 89.5%\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/prompt_learner/model-best.pth.tar\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/context_decoder/model-best.pth.tar\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hbcho991/DAMP/DAMP/train.py\", line 229, in <module>\n",
      "    main(args)\n",
      "  File \"/home/hbcho991/DAMP/DAMP/train.py\", line 155, in main\n",
      "    trainer.train()\n",
      "  File \"/home/hbcho991/DAMP/DAMP/trainers/damp.py\", line 635, in train\n",
      "    self.run_epoch()\n",
      "  File \"/home/hbcho991/DAMP/DAMP/trainers/damp.py\", line 678, in run_epoch\n",
      "    loss_summary = self.forward_backward(batch_x, batch_u)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hbcho991/DAMP/DAMP/trainers/damp.py\", line 721, in forward_backward\n",
      "    output_x, output_x_ind, visual_x, text_x = self.model(image_x, ind =True, pse=False)\n",
      "                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/amp/autocast_mode.py\", line 43, in decorate_autocast\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hbcho991/DAMP/DAMP/trainers/damp.py\", line 457, in forward\n",
      "    text_embeddings, text_contexts = self.text_encoder(raw_prompt, tokenized_prompts)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/amp/autocast_mode.py\", line 43, in decorate_autocast\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hbcho991/DAMP/DAMP/trainers/damp.py\", line 221, in forward\n",
      "    text_embedding_at_eos = x[torch.arange(x.shape[0]), tokenized_prompts.argmax(dim=-1)] @ self.text_projection\n",
      "                                                                                            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1716, in __getattr__\n",
      "    def __getattr__(self, name: str) -> Any:\n",
      "\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!sh VisDA17.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a07ba7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fe0c39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "874fc0a3",
   "metadata": {},
   "source": [
    "## damp2 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "487d242d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-31 12:48:01.089524: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-31 12:48:01.100041: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-31 12:48:01.112101: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-31 12:48:01.115829: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-31 12:48:01.125190: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-31 12:48:01.753580: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/hbcho991/DAMP/DAMP/trainers/damp.py:197: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/home/hbcho991/DAMP/DAMP/trainers/damp.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/home/hbcho991/DAMP/DAMP/trainers/damp.py:285: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/home/hbcho991/DAMP/DAMP/trainers/damp.py:386: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/home/hbcho991/DAMP/DAMP/trainers/damp.py:426: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "['TRAINER.DAMP.TAU', '0.5', 'TRAINER.DAMP.U', '2.0']\n",
      "DATALOADER:\n",
      "  K_TRANSFORMS: 1\n",
      "  NUM_WORKERS: 4\n",
      "  RETURN_IMG0: False\n",
      "  TEST:\n",
      "    BATCH_SIZE: 128\n",
      "    SAMPLER: SequentialSampler\n",
      "  TRAIN_U:\n",
      "    BATCH_SIZE: 32\n",
      "    N_DOMAIN: 0\n",
      "    N_INS: 16\n",
      "    SAME_AS_X: True\n",
      "    SAMPLER: RandomSampler\n",
      "  TRAIN_X:\n",
      "    BATCH_SIZE: 32\n",
      "    N_DOMAIN: 0\n",
      "    N_INS: 16\n",
      "    SAMPLER: RandomSampler\n",
      "DATASET:\n",
      "  ALL_AS_UNLABELED: False\n",
      "  CIFAR_C_LEVEL: 1\n",
      "  CIFAR_C_TYPE: \n",
      "  NAME: VISDA_C\n",
      "  NUM_LABELED: -1\n",
      "  NUM_SHOTS: -1\n",
      "  ROOT: /home/dataset/\n",
      "  SOURCE_DOMAINS: ['synthetic']\n",
      "  STL10_FOLD: -1\n",
      "  TARGET_DOMAINS: ['real']\n",
      "  VAL_PERCENT: 0.1\n",
      "INPUT:\n",
      "  COLORJITTER_B: 0.4\n",
      "  COLORJITTER_C: 0.4\n",
      "  COLORJITTER_H: 0.1\n",
      "  COLORJITTER_S: 0.4\n",
      "  CROP_PADDING: 4\n",
      "  CUTOUT_LEN: 16\n",
      "  CUTOUT_N: 1\n",
      "  GB_K: 21\n",
      "  GB_P: 0.5\n",
      "  GN_MEAN: 0.0\n",
      "  GN_STD: 0.15\n",
      "  INTERPOLATION: bicubic\n",
      "  NO_TRANSFORM: False\n",
      "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
      "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
      "  RANDAUGMENT_M: 10\n",
      "  RANDAUGMENT_N: 2\n",
      "  RGS_P: 0.2\n",
      "  RRCROP_SCALE: (0.08, 1.0)\n",
      "  SIZE: (224, 224)\n",
      "  TRANSFORMS: ('normalize',)\n",
      "MODEL:\n",
      "  BACKBONE:\n",
      "    NAME: ViT-B/16\n",
      "    PATH: ./assets\n",
      "    PRETRAINED: True\n",
      "  HEAD:\n",
      "    ACTIVATION: relu\n",
      "    BN: True\n",
      "    DROPOUT: 0.0\n",
      "    HIDDEN_LAYERS: ()\n",
      "    NAME: \n",
      "  INIT_WEIGHTS: \n",
      "  INIT_WEIGHTS_CTX: None\n",
      "  INIT_WEIGHTS_PRO: None\n",
      "OPTIM:\n",
      "  ADAM_BETA1: 0.9\n",
      "  ADAM_BETA2: 0.999\n",
      "  BASE_LR_MULT: 0.1\n",
      "  GAMMA: 0.1\n",
      "  LR: 0.003\n",
      "  LR_SCHEDULER: cosine\n",
      "  MAX_EPOCH: 30\n",
      "  MOMENTUM: 0.9\n",
      "  NAME: adam\n",
      "  NEW_LAYERS: ()\n",
      "  RMSPROP_ALPHA: 0.99\n",
      "  SGD_DAMPNING: 0\n",
      "  SGD_NESTEROV: False\n",
      "  STAGED_LR: False\n",
      "  STEPSIZE: (-1,)\n",
      "  WARMUP_CONS_LR: 1e-05\n",
      "  WARMUP_EPOCH: 1\n",
      "  WARMUP_MIN_LR: 1e-05\n",
      "  WARMUP_RECOUNT: True\n",
      "  WARMUP_TYPE: linear\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "OPTIM_C:\n",
      "  ADAM_BETA1: 0.9\n",
      "  ADAM_BETA2: 0.999\n",
      "  BASE_LR_MULT: 0.1\n",
      "  GAMMA: 0.1\n",
      "  LR: 0.003\n",
      "  LR_SCHEDULER: cosine\n",
      "  MAX_EPOCH: 30\n",
      "  MOMENTUM: 0.9\n",
      "  NAME: adam\n",
      "  NEW_LAYERS: ()\n",
      "  RMSPROP_ALPHA: 0.99\n",
      "  SGD_DAMPNING: 0\n",
      "  SGD_NESTEROV: False\n",
      "  STAGED_LR: False\n",
      "  STEPSIZE: (-1,)\n",
      "  WARMUP_CONS_LR: 1e-05\n",
      "  WARMUP_EPOCH: 1\n",
      "  WARMUP_MIN_LR: 1e-05\n",
      "  WARMUP_RECOUNT: True\n",
      "  WARMUP_TYPE: linear\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "OUTPUT_DIR: output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1\n",
      "RESUME: \n",
      "SEED: 1\n",
      "TEST:\n",
      "  COMPUTE_CMAT: False\n",
      "  EVALUATOR: Classification\n",
      "  FINAL_MODEL: last_step\n",
      "  NO_TEST: False\n",
      "  PER_CLASS_RESULT: True\n",
      "  SPLIT: test\n",
      "TRAIN:\n",
      "  CHECKPOINT_FREQ: 0\n",
      "  COUNT_ITER: train_x\n",
      "  PRINT_FREQ: 100\n",
      "TRAINER:\n",
      "  CDAC:\n",
      "    CLASS_LR_MULTI: 10\n",
      "    P_THRESH: 0.95\n",
      "    RAMPUP_COEF: 30\n",
      "    RAMPUP_ITRS: 1000\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    TOPK_MATCH: 5\n",
      "  CROSSGRAD:\n",
      "    ALPHA_D: 0.5\n",
      "    ALPHA_F: 0.5\n",
      "    EPS_D: 1.0\n",
      "    EPS_F: 1.0\n",
      "  DAEL:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 0.5\n",
      "  DAELDG:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 0.5\n",
      "  DAMP:\n",
      "    CSC: False\n",
      "    IM: 1.0\n",
      "    IND: 1.0\n",
      "    N_CLS: 2\n",
      "    N_CTX: 32\n",
      "    PREC: amp\n",
      "    STRONG_TRANSFORMS: ['randaugment', 'normalize']\n",
      "    TAU: 0.5\n",
      "    U: 2.0\n",
      "  DAPL:\n",
      "    CSC: False\n",
      "    N_CTX: 16\n",
      "    N_DMX: 16\n",
      "    PREC: fp16\n",
      "    T: 1.0\n",
      "    TAU: 0.5\n",
      "    U: 1.0\n",
      "  DDAIG:\n",
      "    ALPHA: 0.5\n",
      "    CLAMP: False\n",
      "    CLAMP_MAX: 1.0\n",
      "    CLAMP_MIN: -1.0\n",
      "    G_ARCH: \n",
      "    LMDA: 0.3\n",
      "    WARMUP: 0\n",
      "  DOMAINMIX:\n",
      "    ALPHA: 1.0\n",
      "    BETA: 1.0\n",
      "    TYPE: crossdomain\n",
      "  ENTMIN:\n",
      "    LMDA: 0.001\n",
      "  FIXMATCH:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 1.0\n",
      "  M3SDA:\n",
      "    LMDA: 0.5\n",
      "    N_STEP_F: 4\n",
      "  MCD:\n",
      "    N_STEP_F: 4\n",
      "  MEANTEACHER:\n",
      "    EMA_ALPHA: 0.999\n",
      "    RAMPUP: 5\n",
      "    WEIGHT_U: 1.0\n",
      "  MIXMATCH:\n",
      "    MIXUP_BETA: 0.75\n",
      "    RAMPUP: 20000\n",
      "    TEMP: 2.0\n",
      "    WEIGHT_U: 100.0\n",
      "  MME:\n",
      "    LMDA: 0.1\n",
      "  NAME: DAMP\n",
      "  SE:\n",
      "    CONF_THRE: 0.95\n",
      "    EMA_ALPHA: 0.999\n",
      "    RAMPUP: 300\n",
      "USE_CUDA: True\n",
      "VERBOSE: True\n",
      "VERSION: 1\n",
      "Setting fixed seed: 1\n",
      "***************\n",
      "** Arguments **\n",
      "***************\n",
      "backbone: \n",
      "config_file: configs/trainers/DAMP/damp.yaml\n",
      "dataset_config_file: configs/datasets/visda17.yaml\n",
      "eval_only: False\n",
      "head: \n",
      "load_epoch: None\n",
      "model_dir: \n",
      "no_train: False\n",
      "opts: ['TRAINER.DAMP.TAU', '0.5', 'TRAINER.DAMP.U', '2.0']\n",
      "output_dir: output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1\n",
      "resume: \n",
      "root: /home/dataset/\n",
      "seed: 1\n",
      "source_domains: ['synthetic']\n",
      "target_domains: ['real']\n",
      "trainer: DAMP\n",
      "transforms: None\n",
      "************\n",
      "** Config **\n",
      "************\n",
      "DATALOADER:\n",
      "  K_TRANSFORMS: 1\n",
      "  NUM_WORKERS: 4\n",
      "  RETURN_IMG0: False\n",
      "  TEST:\n",
      "    BATCH_SIZE: 128\n",
      "    SAMPLER: SequentialSampler\n",
      "  TRAIN_U:\n",
      "    BATCH_SIZE: 32\n",
      "    N_DOMAIN: 0\n",
      "    N_INS: 16\n",
      "    SAME_AS_X: True\n",
      "    SAMPLER: RandomSampler\n",
      "  TRAIN_X:\n",
      "    BATCH_SIZE: 32\n",
      "    N_DOMAIN: 0\n",
      "    N_INS: 16\n",
      "    SAMPLER: RandomSampler\n",
      "DATASET:\n",
      "  ALL_AS_UNLABELED: False\n",
      "  CIFAR_C_LEVEL: 1\n",
      "  CIFAR_C_TYPE: \n",
      "  NAME: VISDA_C\n",
      "  NUM_LABELED: -1\n",
      "  NUM_SHOTS: -1\n",
      "  ROOT: /home/dataset/\n",
      "  SOURCE_DOMAINS: ['synthetic']\n",
      "  STL10_FOLD: -1\n",
      "  TARGET_DOMAINS: ['real']\n",
      "  VAL_PERCENT: 0.1\n",
      "INPUT:\n",
      "  COLORJITTER_B: 0.4\n",
      "  COLORJITTER_C: 0.4\n",
      "  COLORJITTER_H: 0.1\n",
      "  COLORJITTER_S: 0.4\n",
      "  CROP_PADDING: 4\n",
      "  CUTOUT_LEN: 16\n",
      "  CUTOUT_N: 1\n",
      "  GB_K: 21\n",
      "  GB_P: 0.5\n",
      "  GN_MEAN: 0.0\n",
      "  GN_STD: 0.15\n",
      "  INTERPOLATION: bicubic\n",
      "  NO_TRANSFORM: False\n",
      "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
      "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
      "  RANDAUGMENT_M: 10\n",
      "  RANDAUGMENT_N: 2\n",
      "  RGS_P: 0.2\n",
      "  RRCROP_SCALE: (0.08, 1.0)\n",
      "  SIZE: (224, 224)\n",
      "  TRANSFORMS: ('normalize',)\n",
      "MODEL:\n",
      "  BACKBONE:\n",
      "    NAME: ViT-B/16\n",
      "    PATH: ./assets\n",
      "    PRETRAINED: True\n",
      "  HEAD:\n",
      "    ACTIVATION: relu\n",
      "    BN: True\n",
      "    DROPOUT: 0.0\n",
      "    HIDDEN_LAYERS: ()\n",
      "    NAME: \n",
      "  INIT_WEIGHTS: \n",
      "  INIT_WEIGHTS_CTX: None\n",
      "  INIT_WEIGHTS_PRO: None\n",
      "OPTIM:\n",
      "  ADAM_BETA1: 0.9\n",
      "  ADAM_BETA2: 0.999\n",
      "  BASE_LR_MULT: 0.1\n",
      "  GAMMA: 0.1\n",
      "  LR: 0.003\n",
      "  LR_SCHEDULER: cosine\n",
      "  MAX_EPOCH: 30\n",
      "  MOMENTUM: 0.9\n",
      "  NAME: adam\n",
      "  NEW_LAYERS: ()\n",
      "  RMSPROP_ALPHA: 0.99\n",
      "  SGD_DAMPNING: 0\n",
      "  SGD_NESTEROV: False\n",
      "  STAGED_LR: False\n",
      "  STEPSIZE: (-1,)\n",
      "  WARMUP_CONS_LR: 1e-05\n",
      "  WARMUP_EPOCH: 1\n",
      "  WARMUP_MIN_LR: 1e-05\n",
      "  WARMUP_RECOUNT: True\n",
      "  WARMUP_TYPE: linear\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "OPTIM_C:\n",
      "  ADAM_BETA1: 0.9\n",
      "  ADAM_BETA2: 0.999\n",
      "  BASE_LR_MULT: 0.1\n",
      "  GAMMA: 0.1\n",
      "  LR: 0.003\n",
      "  LR_SCHEDULER: cosine\n",
      "  MAX_EPOCH: 30\n",
      "  MOMENTUM: 0.9\n",
      "  NAME: adam\n",
      "  NEW_LAYERS: ()\n",
      "  RMSPROP_ALPHA: 0.99\n",
      "  SGD_DAMPNING: 0\n",
      "  SGD_NESTEROV: False\n",
      "  STAGED_LR: False\n",
      "  STEPSIZE: (-1,)\n",
      "  WARMUP_CONS_LR: 1e-05\n",
      "  WARMUP_EPOCH: 1\n",
      "  WARMUP_MIN_LR: 1e-05\n",
      "  WARMUP_RECOUNT: True\n",
      "  WARMUP_TYPE: linear\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "OUTPUT_DIR: output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1\n",
      "RESUME: \n",
      "SEED: 1\n",
      "TEST:\n",
      "  COMPUTE_CMAT: False\n",
      "  EVALUATOR: Classification\n",
      "  FINAL_MODEL: last_step\n",
      "  NO_TEST: False\n",
      "  PER_CLASS_RESULT: True\n",
      "  SPLIT: test\n",
      "TRAIN:\n",
      "  CHECKPOINT_FREQ: 0\n",
      "  COUNT_ITER: train_x\n",
      "  PRINT_FREQ: 100\n",
      "TRAINER:\n",
      "  CDAC:\n",
      "    CLASS_LR_MULTI: 10\n",
      "    P_THRESH: 0.95\n",
      "    RAMPUP_COEF: 30\n",
      "    RAMPUP_ITRS: 1000\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    TOPK_MATCH: 5\n",
      "  CROSSGRAD:\n",
      "    ALPHA_D: 0.5\n",
      "    ALPHA_F: 0.5\n",
      "    EPS_D: 1.0\n",
      "    EPS_F: 1.0\n",
      "  DAEL:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 0.5\n",
      "  DAELDG:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 0.5\n",
      "  DAMP:\n",
      "    CSC: False\n",
      "    IM: 1.0\n",
      "    IND: 1.0\n",
      "    N_CLS: 2\n",
      "    N_CTX: 32\n",
      "    PREC: amp\n",
      "    STRONG_TRANSFORMS: ['randaugment', 'normalize']\n",
      "    TAU: 0.5\n",
      "    U: 2.0\n",
      "  DAPL:\n",
      "    CSC: False\n",
      "    N_CTX: 16\n",
      "    N_DMX: 16\n",
      "    PREC: fp16\n",
      "    T: 1.0\n",
      "    TAU: 0.5\n",
      "    U: 1.0\n",
      "  DDAIG:\n",
      "    ALPHA: 0.5\n",
      "    CLAMP: False\n",
      "    CLAMP_MAX: 1.0\n",
      "    CLAMP_MIN: -1.0\n",
      "    G_ARCH: \n",
      "    LMDA: 0.3\n",
      "    WARMUP: 0\n",
      "  DOMAINMIX:\n",
      "    ALPHA: 1.0\n",
      "    BETA: 1.0\n",
      "    TYPE: crossdomain\n",
      "  ENTMIN:\n",
      "    LMDA: 0.001\n",
      "  FIXMATCH:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 1.0\n",
      "  M3SDA:\n",
      "    LMDA: 0.5\n",
      "    N_STEP_F: 4\n",
      "  MCD:\n",
      "    N_STEP_F: 4\n",
      "  MEANTEACHER:\n",
      "    EMA_ALPHA: 0.999\n",
      "    RAMPUP: 5\n",
      "    WEIGHT_U: 1.0\n",
      "  MIXMATCH:\n",
      "    MIXUP_BETA: 0.75\n",
      "    RAMPUP: 20000\n",
      "    TEMP: 2.0\n",
      "    WEIGHT_U: 100.0\n",
      "  MME:\n",
      "    LMDA: 0.1\n",
      "  NAME: DAMP\n",
      "  SE:\n",
      "    CONF_THRE: 0.95\n",
      "    EMA_ALPHA: 0.999\n",
      "    RAMPUP: 300\n",
      "USE_CUDA: True\n",
      "VERBOSE: True\n",
      "VERSION: 1\n",
      "Collecting env info ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** System info **\n",
      "PyTorch version: 2.4.0+cu121\n",
      "Is debug build: False\n",
      "CUDA used to build PyTorch: 12.1\n",
      "ROCM used to build PyTorch: N/A\n",
      "\n",
      "OS: Ubuntu 22.04.3 LTS (x86_64)\n",
      "GCC version: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Clang version: Could not collect\n",
      "CMake version: version 3.22.1\n",
      "Libc version: glibc-2.35\n",
      "\n",
      "Python version: 3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0] (64-bit runtime)\n",
      "Python platform: Linux-6.2.0-26-generic-x86_64-with-glibc2.35\n",
      "Is CUDA available: True\n",
      "CUDA runtime version: 12.3.103\n",
      "CUDA_MODULE_LOADING set to: LAZY\n",
      "GPU models and configuration: \n",
      "GPU 0: NVIDIA GeForce RTX 4090\n",
      "GPU 1: NVIDIA GeForce RTX 4090\n",
      "GPU 2: NVIDIA GeForce RTX 4090\n",
      "GPU 3: NVIDIA GeForce RTX 4090\n",
      "GPU 4: NVIDIA GeForce RTX 4090\n",
      "GPU 5: NVIDIA GeForce RTX 4090\n",
      "GPU 6: NVIDIA GeForce RTX 4090\n",
      "GPU 7: NVIDIA GeForce RTX 4090\n",
      "\n",
      "Nvidia driver version: 535.129.03\n",
      "cuDNN version: Could not collect\n",
      "HIP runtime version: N/A\n",
      "MIOpen runtime version: N/A\n",
      "Is XNNPACK available: True\n",
      "\n",
      "CPU:\n",
      "Architecture:                    x86_64\n",
      "CPU op-mode(s):                  32-bit, 64-bit\n",
      "Address sizes:                   46 bits physical, 57 bits virtual\n",
      "Byte Order:                      Little Endian\n",
      "CPU(s):                          32\n",
      "On-line CPU(s) list:             0-31\n",
      "Vendor ID:                       GenuineIntel\n",
      "Model name:                      Intel(R) Xeon(R) Gold 6426Y\n",
      "CPU family:                      6\n",
      "Model:                           143\n",
      "Thread(s) per core:              1\n",
      "Core(s) per socket:              16\n",
      "Socket(s):                       2\n",
      "Stepping:                        8\n",
      "CPU max MHz:                     4100.0000\n",
      "CPU min MHz:                     800.0000\n",
      "BogoMIPS:                        5000.00\n",
      "Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 cat_l2 cdp_l3 invpcid_single intel_ppin cdp_l2 ssbd mba ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm rdt_a avx512f avx512dq rdseed adx smap avx512ifma clflushopt clwb intel_pt avx512cd sha_ni avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local split_lock_detect avx_vnni avx512_bf16 wbnoinvd dtherm ida arat pln pts hwp hwp_act_window hwp_epp hwp_pkg_req hfi avx512vbmi umip pku ospke waitpkg avx512_vbmi2 gfni vaes vpclmulqdq avx512_vnni avx512_bitalg tme avx512_vpopcntdq la57 rdpid bus_lock_detect cldemote movdiri movdir64b enqcmd fsrm md_clear serialize tsxldtrk pconfig arch_lbr ibt amx_bf16 avx512_fp16 amx_tile amx_int8 flush_l1d arch_capabilities\n",
      "Virtualization:                  VT-x\n",
      "L1d cache:                       1.5 MiB (32 instances)\n",
      "L1i cache:                       1 MiB (32 instances)\n",
      "L2 cache:                        64 MiB (32 instances)\n",
      "L3 cache:                        75 MiB (2 instances)\n",
      "NUMA node(s):                    2\n",
      "NUMA node0 CPU(s):               0-15\n",
      "NUMA node1 CPU(s):               16-31\n",
      "Vulnerability Itlb multihit:     Not affected\n",
      "Vulnerability L1tf:              Not affected\n",
      "Vulnerability Mds:               Not affected\n",
      "Vulnerability Meltdown:          Not affected\n",
      "Vulnerability Mmio stale data:   Not affected\n",
      "Vulnerability Retbleed:          Not affected\n",
      "Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl\n",
      "Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization\n",
      "Vulnerability Spectre v2:        Mitigation; Enhanced IBRS, IBPB conditional, RSB filling, PBRSB-eIBRS SW sequence\n",
      "Vulnerability Srbds:             Not affected\n",
      "Vulnerability Tsx async abort:   Not affected\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] flake8==3.7.9\n",
      "[pip3] mypy-extensions==1.0.0\n",
      "[pip3] numpy==1.23.0\n",
      "[pip3] numpydoc==1.5.0\n",
      "[pip3] optree==0.12.1\n",
      "[pip3] torch==2.4.0\n",
      "[pip3] torchvision==0.19.0\n",
      "[pip3] triton==3.0.0\n",
      "[conda] _anaconda_depends         2023.09             py311_mkl_1  \n",
      "[conda] blas                      1.0                         mkl  \n",
      "[conda] mkl                       2023.1.0         h213fc3f_46343  \n",
      "[conda] mkl-service               2.4.0           py311h5eee18b_1  \n",
      "[conda] mkl_fft                   1.3.8           py311h5eee18b_0  \n",
      "[conda] mkl_random                1.2.4           py311hdb19cb5_0  \n",
      "[conda] numpy                     1.24.3          py311h08b1b3b_1  \n",
      "[conda] numpy-base                1.24.3          py311hf175353_1  \n",
      "[conda] numpydoc                  1.5.0           py311h06a4308_0  \n",
      "        Pillow (9.4.0)\n",
      "\n",
      "Loading trainer: DAMP\n",
      "Building transform_train\n",
      "+ resize to 224x224\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
      "Building transform_train\n",
      "+ resize to 224x224\n",
      "+ randaugment (n=2, m=10)\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
      "Loading dataset: VISDA_C\n",
      "* Using custom transform for training\n",
      "Building transform_test\n",
      "+ resize the smaller edge to 224\n",
      "+ 224x224 center crop\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
      "---------  -------------\n",
      "Dataset    VISDA_C\n",
      "Source     ['synthetic']\n",
      "Target     ['real']\n",
      "# classes  12\n",
      "# train_x  152,397\n",
      "# train_u  55,388\n",
      "# test     55,388\n",
      "---------  -------------\n",
      "['aeroplane', 'bicycle', 'bus', 'car', 'horse', 'knife', 'motorcycle', 'person', 'plant', 'skateboard', 'train', 'truck']\n",
      "Loading CLIP (backbone: ViT-B/16)\n",
      "./assets/ViT-B-16.pt\n",
      "Building custom CLIP\n",
      "ContextDecoder(\n",
      "  (memory_proj): Sequential(\n",
      "    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (text_proj): Sequential(\n",
      "    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "  )\n",
      "  (decoder): ModuleList(\n",
      "    (0-5): 6 x TransformerDecoderLayer(\n",
      "      (self_attn): Attention(\n",
      "        (q_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (k_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (v_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (cross_attn): Attention(\n",
      "        (q_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (k_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (v_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "        (3): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (out_proj): Sequential(\n",
      "    (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=256, out_features=512, bias=True)\n",
      "  )\n",
      ")\n",
      "Initializing a generic context\n",
      "ctx vectors size: \n",
      "Initial context: \"X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X\"\n",
      "Number of context words (tokens): 32\n",
      "Number of cls words (tokens): 2\n",
      "Prompts: \"X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X aeroplane.\"\n",
      "Naive Prompts: \"a real photo of a aeroplane.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turning off gradients in both the image and the text encoder\n",
      "Loading evaluator: Classification\n",
      "No checkpoint found, train from scratch\n",
      "Initialize tensorboard (log_dir=output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/tensorboard)\n",
      "epoch [1/30][100/500]\ttime 0.192 (0.203)\tdata 0.000 (0.003)\teta 0:50:31\tloss 10.0588 (14.7765) loss_x 0.7612 (0.6495) loss_u 0.2815 (0.4472) acc_x 71.8750 (84.7500) acc_u 84.3750 (85.1250) gamma_v 0.0137 (0.0197) gamma_t 0.1109 (0.0591) loss_ind 1.6309 (5.0756) loss_im -1.5647 (-1.2247) loss_new 6.9047 (7.3450)\tlr 6.183221e-04\n",
      "epoch [1/30][200/500]\ttime 0.197 (0.202)\tdata 0.000 (0.002)\teta 0:49:48\tloss 6.5167 (11.4806) loss_x 0.2271 (0.5369) loss_u 0.1321 (0.3290) acc_x 96.8750 (86.5312) acc_u 81.2500 (85.6094) gamma_v 0.0074 (0.0142) gamma_t 0.1738 (0.1046) loss_ind 0.6981 (3.1833) loss_im -1.7753 (-1.4707) loss_new 5.9782 (6.9188)\tlr 8.898950e-04\n",
      "epoch [1/30][300/500]\ttime 0.226 (0.209)\tdata 0.000 (0.001)\teta 0:51:12\tloss 7.3959 (9.9672) loss_x 0.5054 (0.4836) loss_u 0.1081 (0.2719) acc_x 78.1250 (87.6458) acc_u 87.5000 (85.2708) gamma_v 0.0102 (0.0121) gamma_t 0.1920 (0.1303) loss_ind 1.0147 (2.4219) loss_im -1.7837 (-1.6009) loss_new 5.7477 (6.6253)\tlr 2.991783e-03\n",
      "epoch [1/30][400/500]\ttime 0.242 (0.219)\tdata 0.000 (0.001)\teta 0:53:11\tloss 6.5461 (9.0902) loss_x 0.3244 (0.4450) loss_u 0.1774 (0.2385) acc_x 90.6250 (88.4766) acc_u 81.2500 (85.3125) gamma_v 0.0091 (0.0115) gamma_t 0.2011 (0.1469) loss_ind 0.5712 (2.0203) loss_im -1.9595 (-1.6791) loss_new 5.7352 (6.4378)\tlr 6.183221e-04\n",
      "epoch [1/30][500/500]\ttime 0.211 (0.221)\tdata 0.001 (0.001)\teta 0:53:28\tloss 5.9594 (8.5533) loss_x 0.2937 (0.4231) loss_u 0.1056 (0.2225) acc_x 93.7500 (88.8063) acc_u 90.6250 (85.2000) gamma_v 0.0110 (0.0112) gamma_t 0.2091 (0.1588) loss_ind 0.7048 (1.7659) loss_im -1.9503 (-1.7259) loss_new 5.8606 (6.3079)\tlr 8.898950e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 47,264\n",
      "* accuracy: 85.3%\n",
      "* error: 14.7%\n",
      "* macro_f1: 85.9%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,598\tacc: 98.7%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,240\tacc: 93.2%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,469\tacc: 95.3%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,964\tacc: 76.6%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,591\tacc: 97.9%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,929\tacc: 93.0%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,307\tacc: 91.6%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,232\tacc: 80.8%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,090\tacc: 89.9%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,192\tacc: 96.1%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,878\tacc: 91.5%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 2,774\tacc: 50.0%\n",
      "* average: 87.9%\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/prompt_learner/model-best.pth.tar\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/context_decoder/model-best.pth.tar\n",
      "epoch [2/30][100/500]\ttime 0.564 (0.220)\tdata 0.001 (0.003)\teta 0:52:42\tloss 5.5358 (5.9511) loss_x 0.3148 (0.2885) loss_u 0.1400 (0.1284) acc_x 90.6250 (91.1250) acc_u 87.5000 (85.0312) gamma_v 0.0130 (0.0108) gamma_t 0.2201 (0.2153) loss_ind 0.6052 (0.6384) loss_im -2.0849 (-1.9584) loss_new 5.6002 (5.7045)\tlr 2.991783e-03\n",
      "epoch [2/30][200/500]\ttime 0.201 (0.214)\tdata 0.001 (0.002)\teta 0:51:01\tloss 5.7829 (5.8916) loss_x 0.3843 (0.2928) loss_u 0.1357 (0.1282) acc_x 90.6250 (90.9375) acc_u 87.5000 (85.0156) gamma_v 0.0115 (0.0107) gamma_t 0.2297 (0.2207) loss_ind 0.5871 (0.6163) loss_im -1.8962 (-1.9682) loss_new 5.5228 (5.6555)\tlr 6.183221e-04\n",
      "epoch [2/30][300/500]\ttime 0.238 (0.226)\tdata 0.001 (0.001)\teta 0:53:31\tloss 5.0237 (5.8413) loss_x 0.4335 (0.2914) loss_u 0.0563 (0.1283) acc_x 84.3750 (91.0104) acc_u 81.2500 (85.3854) gamma_v 0.0104 (0.0110) gamma_t 0.2339 (0.2242) loss_ind 0.3525 (0.6001) loss_im -2.0767 (-1.9782) loss_new 5.5686 (5.6196)\tlr 8.898950e-04\n",
      "epoch [2/30][400/500]\ttime 0.241 (0.232)\tdata 0.001 (0.001)\teta 0:54:33\tloss 5.5195 (5.7615) loss_x 0.5083 (0.2888) loss_u 0.0588 (0.1281) acc_x 84.3750 (91.0547) acc_u 90.6250 (85.2266) gamma_v 0.0115 (0.0113) gamma_t 0.2416 (0.2275) loss_ind 0.4347 (0.5725) loss_im -2.0861 (-1.9799) loss_new 5.5212 (5.5824)\tlr 2.991783e-03\n",
      "epoch [2/30][500/500]\ttime 0.240 (0.234)\tdata 0.001 (0.001)\teta 0:54:33\tloss 5.2330 (5.7045) loss_x 0.2539 (0.2860) loss_u 0.0871 (0.1254) acc_x 93.7500 (91.1437) acc_u 90.6250 (85.1750) gamma_v 0.0114 (0.0113) gamma_t 0.2481 (0.2310) loss_ind 0.4420 (0.5608) loss_im -2.0082 (-1.9824) loss_new 5.2522 (5.5570)\tlr 6.183221e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 47,729\n",
      "* accuracy: 86.2%\n",
      "* error: 13.8%\n",
      "* macro_f1: 86.9%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,597\tacc: 98.7%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,223\tacc: 92.7%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,375\tacc: 93.3%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,770\tacc: 74.7%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,620\tacc: 98.5%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,955\tacc: 94.2%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,442\tacc: 93.9%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,219\tacc: 80.5%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,053\tacc: 89.1%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,165\tacc: 94.9%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,944\tacc: 93.1%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,366\tacc: 60.7%\n",
      "* average: 88.7%\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/prompt_learner/model-best.pth.tar\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/context_decoder/model-best.pth.tar\n",
      "epoch [3/30][100/500]\ttime 0.239 (0.236)\tdata 0.001 (0.003)\teta 0:54:39\tloss 5.0798 (5.2984) loss_x 0.2912 (0.2419) loss_u 0.1065 (0.1145) acc_x 93.7500 (92.7500) acc_u 84.3750 (85.6875) gamma_v 0.0128 (0.0130) gamma_t 0.2511 (0.2537) loss_ind 0.3196 (0.4603) loss_im -2.0739 (-2.0121) loss_new 5.3841 (5.4055)\tlr 8.898950e-04\n",
      "epoch [3/30][200/500]\ttime 0.239 (0.245)\tdata 0.001 (0.002)\teta 0:56:15\tloss 5.5232 (5.2852) loss_x 0.4052 (0.2488) loss_u 0.1765 (0.1151) acc_x 84.3750 (92.2812) acc_u 87.5000 (85.7031) gamma_v 0.0152 (0.0135) gamma_t 0.2603 (0.2542) loss_ind 0.3957 (0.4456) loss_im -2.1225 (-2.0216) loss_new 5.5374 (5.4047)\tlr 2.991783e-03\n",
      "epoch [3/30][300/500]\ttime 0.223 (0.246)\tdata 0.000 (0.001)\teta 0:56:04\tloss 5.9748 (5.2860) loss_x 0.3092 (0.2464) loss_u 0.1489 (0.1162) acc_x 93.7500 (92.3750) acc_u 87.5000 (85.6875) gamma_v 0.0132 (0.0136) gamma_t 0.2624 (0.2564) loss_ind 0.6255 (0.4390) loss_im -1.9951 (-2.0254) loss_new 5.3430 (5.4018)\tlr 6.183221e-04\n",
      "epoch [3/30][400/500]\ttime 0.238 (0.243)\tdata 0.000 (0.001)\teta 0:55:07\tloss 5.5264 (5.2629) loss_x 0.3013 (0.2520) loss_u 0.0925 (0.1150) acc_x 84.3750 (92.0469) acc_u 90.6250 (85.5625) gamma_v 0.0100 (0.0135) gamma_t 0.2719 (0.2589) loss_ind 0.3205 (0.4325) loss_im -2.0452 (-2.0313) loss_new 5.2850 (5.3942)\tlr 8.898950e-04\n",
      "epoch [3/30][500/500]\ttime 0.226 (0.245)\tdata 0.001 (0.001)\teta 0:55:03\tloss 5.3770 (5.2221) loss_x 0.1641 (0.2476) loss_u 0.1843 (0.1135) acc_x 93.7500 (92.0938) acc_u 84.3750 (85.3125) gamma_v 0.0124 (0.0131) gamma_t 0.2803 (0.2623) loss_ind 0.5320 (0.4231) loss_im -2.1162 (-2.0372) loss_new 5.3454 (5.3816)\tlr 2.991783e-03\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 47,182\n",
      "* accuracy: 85.2%\n",
      "* error: 14.8%\n",
      "* macro_f1: 86.0%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,592\tacc: 98.5%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,200\tacc: 92.1%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,351\tacc: 92.8%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,827\tacc: 75.3%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,599\tacc: 98.0%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,797\tacc: 86.6%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,540\tacc: 95.6%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,354\tacc: 83.8%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 3,878\tacc: 85.2%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,125\tacc: 93.2%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,992\tacc: 94.2%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 2,927\tacc: 52.8%\n",
      "* average: 87.3%\n",
      "epoch [4/30][100/500]\ttime 0.217 (0.227)\tdata 0.000 (0.003)\teta 0:50:43\tloss 4.3596 (5.0569) loss_x 0.1180 (0.2275) loss_u 0.0256 (0.1012) acc_x 93.7500 (92.7500) acc_u 84.3750 (85.0000) gamma_v 0.0142 (0.0128) gamma_t 0.2805 (0.2793) loss_ind 0.2857 (0.3781) loss_im -2.1124 (-2.0528) loss_new 5.3446 (5.3408)\tlr 6.183221e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [4/30][200/500]\ttime 0.237 (0.240)\tdata 0.000 (0.002)\teta 0:53:07\tloss 4.7486 (5.0170) loss_x 0.1540 (0.2345) loss_u 0.0980 (0.0985) acc_x 96.8750 (92.2188) acc_u 84.3750 (85.4062) gamma_v 0.0123 (0.0126) gamma_t 0.2875 (0.2837) loss_ind 0.5088 (0.3671) loss_im -1.9807 (-2.0679) loss_new 5.2394 (5.3237)\tlr 8.898950e-04\n",
      "epoch [4/30][300/500]\ttime 0.236 (0.239)\tdata 0.001 (0.001)\teta 0:52:37\tloss 5.3106 (4.9739) loss_x 0.3821 (0.2355) loss_u 0.1815 (0.0942) acc_x 87.5000 (92.0833) acc_u 90.6250 (85.3854) gamma_v 0.0148 (0.0127) gamma_t 0.2984 (0.2865) loss_ind 0.2712 (0.3537) loss_im -1.9336 (-2.0659) loss_new 5.3057 (5.3070)\tlr 2.991783e-03\n",
      "epoch [4/30][400/500]\ttime 0.194 (0.232)\tdata 0.000 (0.001)\teta 0:50:38\tloss 4.3746 (4.9623) loss_x 0.0560 (0.2351) loss_u 0.0426 (0.0985) acc_x 100.0000 (92.1484) acc_u 87.5000 (85.5391) gamma_v 0.0115 (0.0129) gamma_t 0.3018 (0.2901) loss_ind 0.2667 (0.3481) loss_im -2.0595 (-2.0647) loss_new 5.4348 (5.2976)\tlr 6.183221e-04\n",
      "epoch [4/30][500/500]\ttime 0.197 (0.232)\tdata 0.001 (0.001)\teta 0:50:16\tloss 4.6669 (4.9530) loss_x 0.1896 (0.2342) loss_u 0.0407 (0.0991) acc_x 93.7500 (92.2313) acc_u 87.5000 (85.5000) gamma_v 0.0156 (0.0130) gamma_t 0.3075 (0.2934) loss_ind 0.5122 (0.3437) loss_im -1.9726 (-2.0693) loss_new 5.3098 (5.2912)\tlr 8.898950e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 47,468\n",
      "* accuracy: 85.7%\n",
      "* error: 14.3%\n",
      "* macro_f1: 86.5%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,597\tacc: 98.7%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,247\tacc: 93.4%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,475\tacc: 95.4%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,946\tacc: 76.4%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,595\tacc: 98.0%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,980\tacc: 95.4%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,336\tacc: 92.1%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,276\tacc: 81.9%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,121\tacc: 90.6%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,142\tacc: 93.9%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,999\tacc: 94.4%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 2,754\tacc: 49.6%\n",
      "* average: 88.3%\n",
      "epoch [5/30][100/500]\ttime 0.199 (0.254)\tdata 0.001 (0.003)\teta 0:54:35\tloss 5.0716 (4.7805) loss_x 0.3048 (0.2132) loss_u 0.0129 (0.0904) acc_x 87.5000 (92.8438) acc_u 84.3750 (85.2188) gamma_v 0.0134 (0.0145) gamma_t 0.3177 (0.3143) loss_ind 0.1431 (0.2923) loss_im -2.0838 (-2.0956) loss_new 5.4112 (5.2298)\tlr 2.991783e-03\n",
      "epoch [5/30][200/500]\ttime 0.239 (0.236)\tdata 0.000 (0.002)\teta 0:50:17\tloss 3.6610 (4.7703) loss_x 0.0994 (0.2173) loss_u 0.0377 (0.0966) acc_x 100.0000 (92.5781) acc_u 90.6250 (85.3906) gamma_v 0.0126 (0.0133) gamma_t 0.3225 (0.3176) loss_ind 0.3170 (0.2901) loss_im -2.0336 (-2.0949) loss_new 4.9891 (5.2304)\tlr 6.183221e-04\n",
      "epoch [5/30][300/500]\ttime 0.230 (0.241)\tdata 0.000 (0.002)\teta 0:51:04\tloss 4.5649 (4.7675) loss_x 0.4166 (0.2207) loss_u 0.0358 (0.0949) acc_x 84.3750 (92.4792) acc_u 90.6250 (85.5208) gamma_v 0.0113 (0.0126) gamma_t 0.3318 (0.3214) loss_ind 0.2809 (0.2868) loss_im -2.0314 (-2.1005) loss_new 5.1976 (5.2347)\tlr 8.898950e-04\n",
      "epoch [5/30][400/500]\ttime 0.229 (0.243)\tdata 0.000 (0.001)\teta 0:51:02\tloss 5.4030 (4.7717) loss_x 0.3721 (0.2258) loss_u 0.1953 (0.0964) acc_x 87.5000 (92.2734) acc_u 87.5000 (85.5234) gamma_v 0.0127 (0.0127) gamma_t 0.3351 (0.3238) loss_ind 0.1656 (0.2818) loss_im -1.8719 (-2.0972) loss_new 5.1730 (5.2345)\tlr 2.991783e-03\n",
      "epoch [5/30][500/500]\ttime 0.231 (0.241)\tdata 0.000 (0.001)\teta 0:50:06\tloss 5.0338 (4.7671) loss_x 0.3098 (0.2237) loss_u 0.1174 (0.0948) acc_x 90.6250 (92.3125) acc_u 78.1250 (85.6813) gamma_v 0.0128 (0.0127) gamma_t 0.3347 (0.3262) loss_ind 0.1749 (0.2791) loss_im -2.0907 (-2.0931) loss_new 5.1876 (5.2339)\tlr 6.183221e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 47,699\n",
      "* accuracy: 86.1%\n",
      "* error: 13.9%\n",
      "* macro_f1: 86.6%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,603\tacc: 98.8%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,142\tacc: 90.4%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,387\tacc: 93.5%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,816\tacc: 75.1%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,633\tacc: 98.8%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,981\tacc: 95.5%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,491\tacc: 94.7%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,098\tacc: 77.5%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,262\tacc: 93.7%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,112\tacc: 92.6%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,953\tacc: 93.3%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,221\tacc: 58.1%\n",
      "* average: 88.5%\n",
      "epoch [6/30][100/500]\ttime 0.237 (0.251)\tdata 0.000 (0.003)\teta 0:51:48\tloss 4.8684 (4.8663) loss_x 0.3096 (0.2187) loss_u 0.0615 (0.1011) acc_x 84.3750 (92.5625) acc_u 87.5000 (85.2812) gamma_v 0.0109 (0.0111) gamma_t 0.3460 (0.3429) loss_ind 0.2854 (0.2685) loss_im -2.0458 (-2.0798) loss_new 5.1963 (5.2099)\tlr 8.898950e-04\n",
      "epoch [6/30][200/500]\ttime 0.222 (0.250)\tdata 0.001 (0.002)\teta 0:51:12\tloss 4.6954 (4.7436) loss_x 0.2249 (0.2213) loss_u 0.1185 (0.0898) acc_x 90.6250 (92.4531) acc_u 90.6250 (85.5625) gamma_v 0.0102 (0.0111) gamma_t 0.3581 (0.3469) loss_ind 0.1965 (0.2508) loss_im -2.0531 (-2.0968) loss_new 5.2167 (5.2004)\tlr 2.991783e-03\n",
      "epoch [6/30][300/500]\ttime 0.229 (0.242)\tdata 0.001 (0.001)\teta 0:49:13\tloss 4.5597 (4.7288) loss_x 0.1913 (0.2215) loss_u 0.0246 (0.0905) acc_x 96.8750 (92.5000) acc_u 93.7500 (85.6458) gamma_v 0.0095 (0.0109) gamma_t 0.3535 (0.3501) loss_ind 0.1980 (0.2431) loss_im -2.0544 (-2.0990) loss_new 5.1989 (5.1962)\tlr 6.183221e-04\n",
      "epoch [6/30][400/500]\ttime 0.229 (0.245)\tdata 0.001 (0.001)\teta 0:49:20\tloss 4.4775 (4.6835) loss_x 0.2557 (0.2202) loss_u 0.0783 (0.0894) acc_x 93.7500 (92.6172) acc_u 71.8750 (85.7031) gamma_v 0.0115 (0.0111) gamma_t 0.3677 (0.3535) loss_ind 0.2361 (0.2394) loss_im -2.0318 (-2.1017) loss_new 5.2425 (5.1914)\tlr 8.898950e-04\n",
      "epoch [6/30][500/500]\ttime 0.228 (0.245)\tdata 0.001 (0.001)\teta 0:49:03\tloss 4.8107 (4.6691) loss_x 0.1910 (0.2189) loss_u 0.1092 (0.0884) acc_x 93.7500 (92.7313) acc_u 84.3750 (85.7750) gamma_v 0.0101 (0.0111) gamma_t 0.3721 (0.3566) loss_ind 0.1463 (0.2344) loss_im -2.1032 (-2.1015) loss_new 5.3213 (5.1923)\tlr 2.991783e-03\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 47,357\n",
      "* accuracy: 85.5%\n",
      "* error: 14.5%\n",
      "* macro_f1: 86.9%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,614\tacc: 99.1%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,143\tacc: 90.4%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,315\tacc: 92.0%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 6,666\tacc: 64.1%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,634\tacc: 98.8%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,957\tacc: 94.3%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,515\tacc: 95.2%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,328\tacc: 83.2%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,123\tacc: 90.6%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,120\tacc: 92.9%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,028\tacc: 95.1%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,914\tacc: 70.5%\n",
      "* average: 88.9%\n",
      "epoch [7/30][100/500]\ttime 0.214 (0.244)\tdata 0.001 (0.003)\teta 0:48:27\tloss 4.1536 (4.6279) loss_x 0.1753 (0.2397) loss_u 0.0429 (0.0783) acc_x 93.7500 (91.9688) acc_u 87.5000 (86.0938) gamma_v 0.0105 (0.0116) gamma_t 0.3772 (0.3740) loss_ind 0.3097 (0.2235) loss_im -1.9563 (-2.0989) loss_new 5.1161 (5.1903)\tlr 6.183221e-04\n",
      "epoch [7/30][200/500]\ttime 0.222 (0.241)\tdata 0.001 (0.002)\teta 0:47:18\tloss 4.9449 (4.6023) loss_x 0.1473 (0.2240) loss_u 0.0862 (0.0794) acc_x 93.7500 (92.5156) acc_u 65.6250 (86.4219) gamma_v 0.0113 (0.0109) gamma_t 0.3822 (0.3776) loss_ind 0.1655 (0.2109) loss_im -1.8647 (-2.0997) loss_new 4.8128 (5.1904)\tlr 8.898950e-04\n",
      "epoch [7/30][300/500]\ttime 0.242 (0.246)\tdata 0.000 (0.001)\teta 0:47:52\tloss 4.4279 (4.6160) loss_x 0.1761 (0.2257) loss_u 0.0399 (0.0805) acc_x 90.6250 (92.3438) acc_u 81.2500 (86.0312) gamma_v 0.0106 (0.0108) gamma_t 0.3936 (0.3805) loss_ind 0.2365 (0.2052) loss_im -2.1684 (-2.1004) loss_new 5.2957 (5.1908)\tlr 2.991783e-03\n",
      "epoch [7/30][400/500]\ttime 0.229 (0.247)\tdata 0.000 (0.001)\teta 0:47:50\tloss 4.4946 (4.6107) loss_x 0.3394 (0.2214) loss_u 0.0451 (0.0804) acc_x 87.5000 (92.5234) acc_u 87.5000 (85.9297) gamma_v 0.0069 (0.0107) gamma_t 0.3930 (0.3835) loss_ind 0.2268 (0.2033) loss_im -2.1070 (-2.1033) loss_new 5.0927 (5.1881)\tlr 6.183221e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [7/30][500/500]\ttime 0.245 (0.245)\tdata 0.001 (0.001)\teta 0:46:57\tloss 3.6198 (4.5774) loss_x 0.1957 (0.2165) loss_u 0.0228 (0.0800) acc_x 93.7500 (92.7562) acc_u 93.7500 (85.8937) gamma_v 0.0104 (0.0101) gamma_t 0.4003 (0.3866) loss_ind 0.1175 (0.1995) loss_im -2.1959 (-2.1088) loss_new 5.1347 (5.1880)\tlr 8.898950e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 47,798\n",
      "* accuracy: 86.3%\n",
      "* error: 13.7%\n",
      "* macro_f1: 87.2%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,584\tacc: 98.3%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,238\tacc: 93.2%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,369\tacc: 93.2%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,805\tacc: 75.0%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,616\tacc: 98.4%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,982\tacc: 95.5%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,448\tacc: 94.0%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,311\tacc: 82.8%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,138\tacc: 91.0%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,145\tacc: 94.0%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,004\tacc: 94.5%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,158\tacc: 56.9%\n",
      "* average: 88.9%\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/prompt_learner/model-best.pth.tar\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/context_decoder/model-best.pth.tar\n",
      "epoch [8/30][100/500]\ttime 0.191 (0.220)\tdata 0.000 (0.003)\teta 0:41:43\tloss 4.9706 (4.4105) loss_x 0.2360 (0.2075) loss_u 0.0829 (0.0621) acc_x 90.6250 (92.8750) acc_u 81.2500 (86.0938) gamma_v 0.0080 (0.0092) gamma_t 0.4143 (0.4061) loss_ind 0.0957 (0.1726) loss_im -2.1398 (-2.1349) loss_new 5.0631 (5.1804)\tlr 2.991783e-03\n",
      "epoch [8/30][200/500]\ttime 0.210 (0.217)\tdata 0.000 (0.002)\teta 0:40:46\tloss 4.4579 (4.4300) loss_x 0.2715 (0.1982) loss_u 0.0164 (0.0675) acc_x 90.6250 (93.4375) acc_u 96.8750 (86.5000) gamma_v 0.0083 (0.0092) gamma_t 0.4157 (0.4096) loss_ind 0.4213 (0.1734) loss_im -2.0798 (-2.1287) loss_new 5.1349 (5.1765)\tlr 6.183221e-04\n",
      "epoch [8/30][300/500]\ttime 0.210 (0.215)\tdata 0.000 (0.001)\teta 0:40:02\tloss 4.1667 (4.4519) loss_x 0.1400 (0.1996) loss_u 0.0324 (0.0685) acc_x 96.8750 (93.3854) acc_u 84.3750 (86.1667) gamma_v 0.0095 (0.0090) gamma_t 0.4238 (0.4135) loss_ind 0.1825 (0.1721) loss_im -2.2187 (-2.1283) loss_new 5.3116 (5.1842)\tlr 8.898950e-04\n",
      "epoch [8/30][400/500]\ttime 0.239 (0.218)\tdata 0.001 (0.001)\teta 0:40:25\tloss 4.8002 (4.4433) loss_x 0.2754 (0.1949) loss_u 0.1869 (0.0707) acc_x 93.7500 (93.5391) acc_u 90.6250 (86.1719) gamma_v 0.0067 (0.0090) gamma_t 0.4306 (0.4165) loss_ind 0.1148 (0.1681) loss_im -2.0895 (-2.1272) loss_new 5.1021 (5.1803)\tlr 2.991783e-03\n",
      "epoch [8/30][500/500]\ttime 0.203 (0.223)\tdata 0.001 (0.001)\teta 0:40:57\tloss 3.9468 (4.4349) loss_x 0.0918 (0.1956) loss_u 0.0653 (0.0713) acc_x 96.8750 (93.4688) acc_u 81.2500 (86.1500) gamma_v 0.0088 (0.0087) gamma_t 0.4364 (0.4196) loss_ind 0.1217 (0.1666) loss_im -2.1819 (-2.1278) loss_new 5.0596 (5.1772)\tlr 6.183221e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 47,733\n",
      "* accuracy: 86.2%\n",
      "* error: 13.8%\n",
      "* macro_f1: 87.0%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,592\tacc: 98.5%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,129\tacc: 90.0%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,414\tacc: 94.1%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,963\tacc: 76.6%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,613\tacc: 98.3%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,860\tacc: 89.6%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,471\tacc: 94.4%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,434\tacc: 85.8%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,057\tacc: 89.2%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,160\tacc: 94.7%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,956\tacc: 93.4%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,084\tacc: 55.6%\n",
      "* average: 88.4%\n",
      "epoch [9/30][100/500]\ttime 0.385 (0.241)\tdata 0.000 (0.003)\teta 0:43:48\tloss 5.5033 (4.4775) loss_x 0.2132 (0.2006) loss_u 0.0542 (0.0767) acc_x 93.7500 (93.1875) acc_u 90.6250 (85.8125) gamma_v 0.0094 (0.0080) gamma_t 0.4391 (0.4386) loss_ind 0.2078 (0.1624) loss_im -2.0652 (-2.1202) loss_new 5.3407 (5.1440)\tlr 8.898950e-04\n",
      "epoch [9/30][200/500]\ttime 0.238 (0.240)\tdata 0.000 (0.002)\teta 0:43:10\tloss 4.8468 (4.4128) loss_x 0.2784 (0.1965) loss_u 0.0209 (0.0662) acc_x 90.6250 (93.2344) acc_u 81.2500 (85.6406) gamma_v 0.0115 (0.0082) gamma_t 0.4499 (0.4412) loss_ind 0.1271 (0.1577) loss_im -2.2201 (-2.1314) loss_new 5.2047 (5.1522)\tlr 2.991783e-03\n",
      "epoch [9/30][300/500]\ttime 0.239 (0.245)\tdata 0.001 (0.002)\teta 0:43:37\tloss 4.3675 (4.4212) loss_x 0.0190 (0.1974) loss_u 0.0445 (0.0678) acc_x 100.0000 (93.2708) acc_u 87.5000 (85.3750) gamma_v 0.0072 (0.0079) gamma_t 0.4527 (0.4445) loss_ind 0.1819 (0.1599) loss_im -2.0884 (-2.1375) loss_new 4.9513 (5.1525)\tlr 6.183221e-04\n",
      "epoch [9/30][400/500]\ttime 0.235 (0.246)\tdata 0.001 (0.001)\teta 0:43:27\tloss 4.0143 (4.4228) loss_x 0.0460 (0.1996) loss_u 0.0463 (0.0672) acc_x 100.0000 (93.2188) acc_u 87.5000 (85.3438) gamma_v 0.0074 (0.0075) gamma_t 0.4651 (0.4476) loss_ind 0.2414 (0.1603) loss_im -2.1115 (-2.1383) loss_new 5.0016 (5.1542)\tlr 8.898950e-04\n",
      "epoch [9/30][500/500]\ttime 0.244 (0.245)\tdata 0.001 (0.001)\teta 0:42:47\tloss 6.4646 (4.4232) loss_x 0.2368 (0.2016) loss_u 0.5076 (0.0680) acc_x 90.6250 (93.1813) acc_u 84.3750 (85.4500) gamma_v 0.0102 (0.0076) gamma_t 0.4665 (0.4509) loss_ind 0.2127 (0.1595) loss_im -2.1139 (-2.1379) loss_new 5.1435 (5.1510)\tlr 2.991783e-03\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 47,822\n",
      "* accuracy: 86.3%\n",
      "* error: 13.7%\n",
      "* macro_f1: 86.9%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,574\tacc: 98.0%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,285\tacc: 94.5%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,379\tacc: 93.4%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 8,662\tacc: 83.3%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,599\tacc: 98.0%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,956\tacc: 94.3%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,388\tacc: 93.0%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,365\tacc: 84.1%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,265\tacc: 93.8%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,073\tacc: 90.9%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,970\tacc: 93.7%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 2,306\tacc: 41.6%\n",
      "* average: 88.2%\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/prompt_learner/model-best.pth.tar\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/context_decoder/model-best.pth.tar\n",
      "epoch [10/30][100/500]\ttime 0.237 (0.248)\tdata 0.001 (0.003)\teta 0:42:56\tloss 4.1152 (4.4181) loss_x 0.2238 (0.2034) loss_u 0.0406 (0.0573) acc_x 93.7500 (92.8438) acc_u 93.7500 (85.8750) gamma_v 0.0089 (0.0083) gamma_t 0.4684 (0.4651) loss_ind 0.0874 (0.1485) loss_im -2.2370 (-2.1390) loss_new 5.0988 (5.1646)\tlr 6.183221e-04\n",
      "epoch [10/30][200/500]\ttime 0.240 (0.249)\tdata 0.001 (0.002)\teta 0:42:41\tloss 4.7185 (4.3773) loss_x 0.0826 (0.2020) loss_u 0.0207 (0.0591) acc_x 96.8750 (92.9062) acc_u 84.3750 (85.8594) gamma_v 0.0080 (0.0082) gamma_t 0.4741 (0.4701) loss_ind 0.1513 (0.1483) loss_im -2.1091 (-2.1440) loss_new 5.2053 (5.1498)\tlr 8.898950e-04\n",
      "epoch [10/30][300/500]\ttime 0.469 (0.247)\tdata 0.002 (0.001)\teta 0:41:59\tloss 4.7599 (4.3634) loss_x 0.2771 (0.2048) loss_u 0.1433 (0.0568) acc_x 90.6250 (92.8854) acc_u 81.2500 (86.0312) gamma_v 0.0099 (0.0080) gamma_t 0.4877 (0.4739) loss_ind 0.1443 (0.1467) loss_im -2.0926 (-2.1465) loss_new 5.1100 (5.1475)\tlr 2.991783e-03\n",
      "epoch [10/30][400/500]\ttime 0.239 (0.246)\tdata 0.001 (0.001)\teta 0:41:25\tloss 4.0342 (4.3675) loss_x 0.2650 (0.2007) loss_u 0.0227 (0.0566) acc_x 87.5000 (93.1250) acc_u 84.3750 (85.9141) gamma_v 0.0085 (0.0079) gamma_t 0.4905 (0.4773) loss_ind 0.1298 (0.1485) loss_im -2.2135 (-2.1425) loss_new 5.0986 (5.1402)\tlr 6.183221e-04\n",
      "epoch [10/30][500/500]\ttime 0.208 (0.244)\tdata 0.001 (0.001)\teta 0:40:43\tloss 4.5375 (4.3542) loss_x 0.2288 (0.1982) loss_u 0.0619 (0.0575) acc_x 90.6250 (93.2500) acc_u 90.6250 (86.1375) gamma_v 0.0091 (0.0081) gamma_t 0.4962 (0.4804) loss_ind 0.1616 (0.1471) loss_im -2.2231 (-2.1406) loss_new 5.5813 (5.1376)\tlr 8.898950e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 47,932\n",
      "* accuracy: 86.5%\n",
      "* error: 13.5%\n",
      "* macro_f1: 87.2%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,573\tacc: 98.0%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,111\tacc: 89.5%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,359\tacc: 92.9%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,746\tacc: 74.5%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,615\tacc: 98.4%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,889\tacc: 91.0%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,543\tacc: 95.6%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,292\tacc: 82.3%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,360\tacc: 95.8%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,109\tacc: 92.5%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,966\tacc: 93.6%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,369\tacc: 60.7%\n",
      "* average: 88.7%\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/prompt_learner/model-best.pth.tar\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/context_decoder/model-best.pth.tar\n",
      "epoch [11/30][100/500]\ttime 0.223 (0.235)\tdata 0.000 (0.003)\teta 0:38:43\tloss 4.2560 (4.3507) loss_x 0.1022 (0.2147) loss_u 0.0699 (0.0526) acc_x 96.8750 (92.2500) acc_u 90.6250 (87.0938) gamma_v 0.0049 (0.0087) gamma_t 0.5077 (0.5000) loss_ind 0.1913 (0.1438) loss_im -2.1284 (-2.1343) loss_new 5.0370 (5.1073)\tlr 2.991783e-03\n",
      "epoch [11/30][200/500]\ttime 0.221 (0.229)\tdata 0.000 (0.002)\teta 0:37:20\tloss 4.1185 (4.3327) loss_x 0.1875 (0.1958) loss_u 0.0417 (0.0538) acc_x 93.7500 (92.9688) acc_u 87.5000 (86.4844) gamma_v 0.0094 (0.0082) gamma_t 0.5111 (0.5035) loss_ind 0.2464 (0.1475) loss_im -2.1147 (-2.1325) loss_new 5.1563 (5.1234)\tlr 6.183221e-04\n",
      "epoch [11/30][300/500]\ttime 0.220 (0.229)\tdata 0.000 (0.001)\teta 0:37:02\tloss 5.2419 (4.3248) loss_x 0.1118 (0.1925) loss_u 0.1413 (0.0520) acc_x 93.7500 (93.3125) acc_u 81.2500 (86.0312) gamma_v 0.0031 (0.0080) gamma_t 0.5196 (0.5081) loss_ind 0.1341 (0.1465) loss_im -2.1409 (-2.1352) loss_new 5.1591 (5.1264)\tlr 8.898950e-04\n",
      "epoch [11/30][400/500]\ttime 0.223 (0.229)\tdata 0.000 (0.001)\teta 0:36:40\tloss 3.4301 (4.3136) loss_x 0.1040 (0.1904) loss_u 0.0098 (0.0536) acc_x 93.7500 (93.3359) acc_u 87.5000 (85.8516) gamma_v 0.0110 (0.0073) gamma_t 0.5302 (0.5116) loss_ind 0.0683 (0.1441) loss_im -2.2640 (-2.1430) loss_new 5.0985 (5.1258)\tlr 2.991783e-03\n",
      "epoch [11/30][500/500]\ttime 0.223 (0.228)\tdata 0.000 (0.001)\teta 0:36:03\tloss 4.3087 (4.3234) loss_x 0.3944 (0.1934) loss_u 0.1224 (0.0530) acc_x 90.6250 (93.3438) acc_u 84.3750 (85.8688) gamma_v 0.0062 (0.0073) gamma_t 0.5323 (0.5154) loss_ind 0.0610 (0.1431) loss_im -2.1382 (-2.1445) loss_new 4.9951 (5.1309)\tlr 6.183221e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 47,644\n",
      "* accuracy: 86.0%\n",
      "* error: 14.0%\n",
      "* macro_f1: 86.9%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,610\tacc: 99.0%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,177\tacc: 91.4%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,432\tacc: 94.5%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,414\tacc: 71.3%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,614\tacc: 98.4%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,982\tacc: 95.5%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,462\tacc: 94.2%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,243\tacc: 81.1%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,133\tacc: 90.9%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,110\tacc: 92.5%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,930\tacc: 92.8%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,537\tacc: 63.8%\n",
      "* average: 88.8%\n",
      "epoch [12/30][100/500]\ttime 0.240 (0.237)\tdata 0.000 (0.003)\teta 0:37:09\tloss 4.6518 (4.3507) loss_x 0.3403 (0.2016) loss_u 0.0276 (0.0479) acc_x 87.5000 (93.1875) acc_u 84.3750 (85.8438) gamma_v 0.0065 (0.0061) gamma_t 0.5394 (0.5371) loss_ind 0.1467 (0.1443) loss_im -2.0937 (-2.1379) loss_new 5.2642 (5.1241)\tlr 8.898950e-04\n",
      "epoch [12/30][200/500]\ttime 0.248 (0.245)\tdata 0.001 (0.002)\teta 0:38:02\tloss 4.6545 (4.3036) loss_x 0.3741 (0.1937) loss_u 0.0199 (0.0459) acc_x 87.5000 (93.3594) acc_u 78.1250 (85.7031) gamma_v 0.0031 (0.0061) gamma_t 0.5533 (0.5431) loss_ind 0.1627 (0.1384) loss_im -2.1074 (-2.1521) loss_new 5.1164 (5.1251)\tlr 2.991783e-03\n",
      "epoch [12/30][300/500]\ttime 0.230 (0.246)\tdata 0.001 (0.001)\teta 0:37:38\tloss 4.0815 (4.2785) loss_x 0.1936 (0.1863) loss_u 0.0554 (0.0473) acc_x 96.8750 (93.5938) acc_u 81.2500 (85.6562) gamma_v 0.0066 (0.0058) gamma_t 0.5530 (0.5461) loss_ind 0.0748 (0.1352) loss_im -2.0464 (-2.1511) loss_new 4.8244 (5.1230)\tlr 6.183221e-04\n",
      "epoch [12/30][400/500]\ttime 0.229 (0.241)\tdata 0.001 (0.001)\teta 0:36:36\tloss 4.0609 (4.2772) loss_x 0.1558 (0.1883) loss_u 0.0437 (0.0476) acc_x 93.7500 (93.5703) acc_u 84.3750 (85.7656) gamma_v 0.0057 (0.0059) gamma_t 0.5589 (0.5495) loss_ind 0.1227 (0.1333) loss_im -2.0828 (-2.1488) loss_new 5.0799 (5.1240)\tlr 8.898950e-04\n",
      "epoch [12/30][500/500]\ttime 0.231 (0.242)\tdata 0.000 (0.001)\teta 0:36:20\tloss 4.0134 (4.2774) loss_x 0.1632 (0.1880) loss_u 0.0100 (0.0485) acc_x 90.6250 (93.6250) acc_u 78.1250 (85.6813) gamma_v 0.0066 (0.0056) gamma_t 0.5705 (0.5525) loss_ind 0.1532 (0.1338) loss_im -2.1868 (-2.1485) loss_new 5.0740 (5.1243)\tlr 2.991783e-03\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 46,347\n",
      "* accuracy: 83.7%\n",
      "* error: 16.3%\n",
      "* macro_f1: 84.0%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,615\tacc: 99.1%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,170\tacc: 91.2%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,372\tacc: 93.2%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 6,787\tacc: 65.3%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,599\tacc: 98.0%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,765\tacc: 85.1%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,441\tacc: 93.9%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 2,327\tacc: 58.2%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 3,985\tacc: 87.6%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,222\tacc: 97.4%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,960\tacc: 93.5%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 4,104\tacc: 74.0%\n",
      "* average: 86.4%\n",
      "epoch [13/30][100/500]\ttime 0.239 (0.241)\tdata 0.001 (0.003)\teta 0:35:48\tloss 4.6036 (4.2661) loss_x 0.1775 (0.1757) loss_u 0.0553 (0.0378) acc_x 93.7500 (94.4688) acc_u 93.7500 (86.6250) gamma_v 0.0059 (0.0041) gamma_t 0.5757 (0.5734) loss_ind 0.1509 (0.1314) loss_im -2.2823 (-2.1676) loss_new 5.1953 (5.1137)\tlr 6.183221e-04\n",
      "epoch [13/30][200/500]\ttime 0.223 (0.241)\tdata 0.000 (0.002)\teta 0:35:18\tloss 4.9064 (4.2454) loss_x 0.3816 (0.1808) loss_u 0.0354 (0.0364) acc_x 90.6250 (94.1875) acc_u 81.2500 (86.3594) gamma_v 0.0074 (0.0049) gamma_t 0.5902 (0.5768) loss_ind 0.1772 (0.1270) loss_im -2.1147 (-2.1667) loss_new 4.9866 (5.1129)\tlr 8.898950e-04\n",
      "epoch [13/30][300/500]\ttime 0.236 (0.245)\tdata 0.000 (0.001)\teta 0:35:29\tloss 4.3696 (4.2350) loss_x 0.1358 (0.1834) loss_u 0.0555 (0.0368) acc_x 93.7500 (93.9792) acc_u 90.6250 (86.3958) gamma_v 0.0036 (0.0052) gamma_t 0.5977 (0.5823) loss_ind 0.1168 (0.1287) loss_im -2.1350 (-2.1726) loss_new 5.1466 (5.1156)\tlr 2.991783e-03\n",
      "epoch [13/30][400/500]\ttime 0.222 (0.244)\tdata 0.001 (0.001)\teta 0:34:56\tloss 3.9755 (4.2241) loss_x 0.2699 (0.1784) loss_u 0.0044 (0.0364) acc_x 87.5000 (94.0859) acc_u 93.7500 (86.4922) gamma_v 0.0074 (0.0050) gamma_t 0.6042 (0.5871) loss_ind 0.1687 (0.1264) loss_im -2.2105 (-2.1685) loss_new 5.2475 (5.1127)\tlr 6.183221e-04\n",
      "epoch [13/30][500/500]\ttime 0.234 (0.241)\tdata 0.000 (0.001)\teta 0:34:07\tloss 4.5835 (4.2244) loss_x 0.1658 (0.1766) loss_u 0.0050 (0.0380) acc_x 93.7500 (94.0625) acc_u 84.3750 (86.3438) gamma_v 0.0042 (0.0054) gamma_t 0.6085 (0.5908) loss_ind 0.0893 (0.1266) loss_im -2.1439 (-2.1669) loss_new 5.0293 (5.1100)\tlr 8.898950e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 47,749\n",
      "* accuracy: 86.2%\n",
      "* error: 13.8%\n",
      "* macro_f1: 86.4%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,614\tacc: 99.1%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,208\tacc: 92.3%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,291\tacc: 91.5%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 8,003\tacc: 76.9%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,612\tacc: 98.3%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,991\tacc: 96.0%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,423\tacc: 93.6%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,161\tacc: 79.0%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,154\tacc: 91.3%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,119\tacc: 92.9%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,042\tacc: 95.4%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,131\tacc: 56.4%\n",
      "* average: 88.6%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [14/30][100/500]\ttime 0.218 (0.225)\tdata 0.000 (0.003)\teta 0:31:33\tloss 4.3015 (4.2364) loss_x 0.0948 (0.1815) loss_u 0.0527 (0.0393) acc_x 96.8750 (93.9375) acc_u 93.7500 (85.6562) gamma_v 0.0041 (0.0052) gamma_t 0.6160 (0.6141) loss_ind 0.1022 (0.1233) loss_im -2.0796 (-2.1719) loss_new 5.0956 (5.1148)\tlr 2.991783e-03\n",
      "epoch [14/30][200/500]\ttime 0.228 (0.234)\tdata 0.001 (0.002)\teta 0:32:19\tloss 4.2599 (4.2318) loss_x 0.1273 (0.1831) loss_u 0.0450 (0.0379) acc_x 96.8750 (93.5781) acc_u 84.3750 (85.5156) gamma_v 0.0047 (0.0045) gamma_t 0.6146 (0.6149) loss_ind 0.1887 (0.1229) loss_im -2.1396 (-2.1685) loss_new 5.0510 (5.1162)\tlr 6.183221e-04\n",
      "epoch [14/30][300/500]\ttime 0.228 (0.237)\tdata 0.001 (0.002)\teta 0:32:25\tloss 4.9418 (4.2428) loss_x 0.1002 (0.1890) loss_u 0.0264 (0.0378) acc_x 100.0000 (93.4688) acc_u 90.6250 (85.4583) gamma_v 0.0065 (0.0047) gamma_t 0.6264 (0.6175) loss_ind 0.1274 (0.1241) loss_im -1.9575 (-2.1664) loss_new 5.3113 (5.1123)\tlr 8.898950e-04\n",
      "epoch [14/30][400/500]\ttime 0.227 (0.235)\tdata 0.000 (0.001)\teta 0:31:45\tloss 4.0513 (4.2455) loss_x 0.1674 (0.1912) loss_u 0.0452 (0.0375) acc_x 90.6250 (93.2969) acc_u 78.1250 (85.8438) gamma_v 0.0036 (0.0049) gamma_t 0.6307 (0.6200) loss_ind 0.1742 (0.1240) loss_im -2.1450 (-2.1622) loss_new 4.9930 (5.1099)\tlr 2.991783e-03\n",
      "epoch [14/30][500/500]\ttime 0.201 (0.233)\tdata 0.000 (0.001)\teta 0:31:06\tloss 4.3508 (4.2392) loss_x 0.2345 (0.1869) loss_u 0.0196 (0.0371) acc_x 90.6250 (93.4500) acc_u 87.5000 (85.8937) gamma_v 0.0064 (0.0051) gamma_t 0.6375 (0.6230) loss_ind 0.0923 (0.1245) loss_im -2.2457 (-2.1613) loss_new 5.0349 (5.1089)\tlr 6.183221e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,223\n",
      "* accuracy: 87.1%\n",
      "* error: 12.9%\n",
      "* macro_f1: 88.0%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,593\tacc: 98.5%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,208\tacc: 92.3%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,326\tacc: 92.2%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,776\tacc: 74.8%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,607\tacc: 98.2%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,912\tacc: 92.1%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,464\tacc: 94.3%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,398\tacc: 85.0%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,111\tacc: 90.4%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,121\tacc: 93.0%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,999\tacc: 94.4%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,708\tacc: 66.8%\n",
      "* average: 89.3%\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/prompt_learner/model-best.pth.tar\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/context_decoder/model-best.pth.tar\n",
      "epoch [15/30][100/500]\ttime 0.218 (0.247)\tdata 0.001 (0.003)\teta 0:32:35\tloss 4.2780 (4.1939) loss_x 0.1840 (0.1816) loss_u 0.0275 (0.0294) acc_x 90.6250 (93.9062) acc_u 78.1250 (85.9688) gamma_v 0.0066 (0.0052) gamma_t 0.6583 (0.6471) loss_ind 0.0583 (0.1242) loss_im -2.1927 (-2.1524) loss_new 5.0944 (5.0889)\tlr 8.898950e-04\n",
      "epoch [15/30][200/500]\ttime 0.239 (0.240)\tdata 0.001 (0.002)\teta 0:31:08\tloss 3.5910 (4.1425) loss_x 0.0410 (0.1709) loss_u 0.0075 (0.0273) acc_x 100.0000 (94.3125) acc_u 93.7500 (86.0312) gamma_v 0.0059 (0.0051) gamma_t 0.6686 (0.6547) loss_ind 0.1014 (0.1251) loss_im -2.0968 (-2.1616) loss_new 4.9236 (5.0796)\tlr 2.991783e-03\n",
      "epoch [15/30][300/500]\ttime 0.218 (0.240)\tdata 0.000 (0.001)\teta 0:30:50\tloss 3.9552 (4.1327) loss_x 0.1546 (0.1760) loss_u 0.0230 (0.0292) acc_x 96.8750 (94.1146) acc_u 84.3750 (85.6667) gamma_v 0.0016 (0.0046) gamma_t 0.6696 (0.6596) loss_ind 0.0648 (0.1219) loss_im -2.2329 (-2.1692) loss_new 5.0083 (5.0879)\tlr 6.183221e-04\n",
      "epoch [15/30][400/500]\ttime 0.236 (0.239)\tdata 0.000 (0.001)\teta 0:30:13\tloss 3.8653 (4.1270) loss_x 0.2288 (0.1741) loss_u 0.0253 (0.0287) acc_x 90.6250 (94.1719) acc_u 81.2500 (85.9141) gamma_v 0.0007 (0.0042) gamma_t 0.6781 (0.6639) loss_ind 0.1686 (0.1216) loss_im -2.2610 (-2.1715) loss_new 4.9123 (5.0885)\tlr 8.898950e-04\n",
      "epoch [15/30][500/500]\ttime 0.231 (0.237)\tdata 0.001 (0.001)\teta 0:29:37\tloss 4.1919 (4.1326) loss_x 0.3186 (0.1738) loss_u 0.0186 (0.0288) acc_x 87.5000 (94.1250) acc_u 84.3750 (86.2062) gamma_v 0.0036 (0.0040) gamma_t 0.6944 (0.6682) loss_ind 0.0944 (0.1213) loss_im -2.0979 (-2.1700) loss_new 5.0257 (5.0879)\tlr 2.991783e-03\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 46,873\n",
      "* accuracy: 84.6%\n",
      "* error: 15.4%\n",
      "* macro_f1: 85.2%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,569\tacc: 97.9%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,308\tacc: 95.2%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,473\tacc: 95.4%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,665\tacc: 73.7%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,589\tacc: 97.8%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,977\tacc: 95.3%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,152\tacc: 88.9%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,188\tacc: 79.7%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,220\tacc: 92.8%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,114\tacc: 92.7%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,961\tacc: 93.5%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 2,657\tacc: 47.9%\n",
      "* average: 87.6%\n",
      "epoch [16/30][100/500]\ttime 0.240 (0.252)\tdata 0.001 (0.004)\teta 0:31:06\tloss 4.1655 (4.1914) loss_x 0.3059 (0.1952) loss_u 0.0062 (0.0270) acc_x 87.5000 (92.9688) acc_u 84.3750 (84.0312) gamma_v 0.0060 (0.0045) gamma_t 0.6969 (0.6961) loss_ind 0.1485 (0.1171) loss_im -2.2098 (-2.1849) loss_new 5.0679 (5.1060)\tlr 6.183221e-04\n",
      "epoch [16/30][200/500]\ttime 0.236 (0.248)\tdata 0.001 (0.002)\teta 0:30:09\tloss 4.6169 (4.2524) loss_x 0.3187 (0.1969) loss_u 0.0143 (0.0303) acc_x 84.3750 (93.1250) acc_u 81.2500 (84.8594) gamma_v 0.0004 (0.0050) gamma_t 0.7024 (0.6981) loss_ind 0.1366 (0.1225) loss_im -2.1968 (-2.1650) loss_new 5.1440 (5.1076)\tlr 8.898950e-04\n",
      "epoch [16/30][300/500]\ttime 0.234 (0.248)\tdata 0.001 (0.002)\teta 0:29:45\tloss 4.8978 (4.2396) loss_x 0.2732 (0.1885) loss_u 0.1000 (0.0301) acc_x 87.5000 (93.4375) acc_u 78.1250 (84.9583) gamma_v 0.0006 (0.0043) gamma_t 0.7145 (0.7017) loss_ind 0.1054 (0.1225) loss_im -1.9830 (-2.1655) loss_new 4.9751 (5.1050)\tlr 2.991783e-03\n",
      "epoch [16/30][400/500]\ttime 0.223 (0.243)\tdata 0.000 (0.001)\teta 0:28:44\tloss 4.4593 (4.2264) loss_x 0.1559 (0.1887) loss_u 0.0207 (0.0298) acc_x 93.7500 (93.5156) acc_u 87.5000 (85.0234) gamma_v 0.0048 (0.0046) gamma_t 0.7179 (0.7048) loss_ind 0.1326 (0.1209) loss_im -2.2500 (-2.1702) loss_new 5.0236 (5.1029)\tlr 6.183221e-04\n",
      "epoch [16/30][500/500]\ttime 0.222 (0.240)\tdata 0.000 (0.001)\teta 0:28:02\tloss 4.7387 (4.2151) loss_x 0.1566 (0.1849) loss_u 0.0310 (0.0293) acc_x 96.8750 (93.7438) acc_u 81.2500 (85.2438) gamma_v 0.0008 (0.0043) gamma_t 0.7260 (0.7088) loss_ind 0.1259 (0.1193) loss_im -2.1860 (-2.1729) loss_new 5.1515 (5.1007)\tlr 8.898950e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,105\n",
      "* accuracy: 86.9%\n",
      "* error: 13.1%\n",
      "* macro_f1: 87.6%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,591\tacc: 98.5%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,288\tacc: 94.6%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,119\tacc: 87.8%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,849\tacc: 75.5%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,627\tacc: 98.6%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,987\tacc: 95.8%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,311\tacc: 91.6%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,284\tacc: 82.1%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,131\tacc: 90.8%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,104\tacc: 92.2%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,084\tacc: 96.4%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,730\tacc: 67.2%\n",
      "* average: 89.3%\n",
      "epoch [17/30][100/500]\ttime 0.238 (0.246)\tdata 0.001 (0.003)\teta 0:28:15\tloss 4.5845 (4.1912) loss_x 0.2065 (0.1771) loss_u 0.0253 (0.0249) acc_x 93.7500 (93.9688) acc_u 87.5000 (85.7812) gamma_v 0.0021 (0.0022) gamma_t 0.7352 (0.7313) loss_ind 0.1332 (0.1149) loss_im -2.1888 (-2.1861) loss_new 5.1652 (5.0998)\tlr 2.991783e-03\n",
      "epoch [17/30][200/500]\ttime 0.242 (0.248)\tdata 0.000 (0.002)\teta 0:28:05\tloss 3.9050 (4.1523) loss_x 0.2180 (0.1738) loss_u 0.0044 (0.0241) acc_x 96.8750 (94.2344) acc_u 78.1250 (85.4531) gamma_v 0.0054 (0.0034) gamma_t 0.7380 (0.7352) loss_ind 0.1073 (0.1130) loss_im -2.2483 (-2.1743) loss_new 5.0731 (5.0849)\tlr 6.183221e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [17/30][300/500]\ttime 0.238 (0.245)\tdata 0.000 (0.001)\teta 0:27:18\tloss 4.2140 (4.1815) loss_x 0.4033 (0.1792) loss_u 0.0012 (0.0257) acc_x 90.6250 (93.9688) acc_u 87.5000 (85.3229) gamma_v 0.0046 (0.0036) gamma_t 0.7428 (0.7377) loss_ind 0.1467 (0.1151) loss_im -2.2914 (-2.1780) loss_new 5.1684 (5.0929)\tlr 8.898950e-04\n",
      "epoch [17/30][400/500]\ttime 0.216 (0.244)\tdata 0.000 (0.001)\teta 0:26:47\tloss 4.0540 (4.1610) loss_x 0.3581 (0.1755) loss_u 0.0141 (0.0258) acc_x 87.5000 (94.0469) acc_u 93.7500 (85.5156) gamma_v 0.0052 (0.0036) gamma_t 0.7547 (0.7404) loss_ind 0.0739 (0.1151) loss_im -2.0733 (-2.1800) loss_new 5.0191 (5.0943)\tlr 2.991783e-03\n",
      "epoch [17/30][500/500]\ttime 0.230 (0.243)\tdata 0.001 (0.001)\teta 0:26:19\tloss 4.4005 (4.1607) loss_x 0.4677 (0.1788) loss_u 0.0258 (0.0253) acc_x 84.3750 (94.0187) acc_u 87.5000 (86.0438) gamma_v 0.0028 (0.0036) gamma_t 0.7669 (0.7444) loss_ind 0.0952 (0.1146) loss_im -2.0972 (-2.1813) loss_new 5.0111 (5.0976)\tlr 6.183221e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,017\n",
      "* accuracy: 86.7%\n",
      "* error: 13.3%\n",
      "* macro_f1: 87.2%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,611\tacc: 99.0%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,241\tacc: 93.3%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,280\tacc: 91.3%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,883\tacc: 75.8%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,620\tacc: 98.5%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 2,027\tacc: 97.7%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,367\tacc: 92.6%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,249\tacc: 81.2%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,175\tacc: 91.8%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,071\tacc: 90.8%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,960\tacc: 93.5%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,533\tacc: 63.7%\n",
      "* average: 89.1%\n",
      "epoch [18/30][100/500]\ttime 0.242 (0.242)\tdata 0.000 (0.003)\teta 0:25:49\tloss 3.9705 (4.1393) loss_x 0.2308 (0.1851) loss_u 0.0099 (0.0211) acc_x 93.7500 (93.6562) acc_u 81.2500 (87.5000) gamma_v 0.0006 (0.0037) gamma_t 0.7753 (0.7735) loss_ind 0.0868 (0.1167) loss_im -2.1287 (-2.1779) loss_new 4.9595 (5.0718)\tlr 8.898950e-04\n",
      "epoch [18/30][200/500]\ttime 0.236 (0.244)\tdata 0.001 (0.002)\teta 0:25:39\tloss 4.8511 (4.1411) loss_x 0.1400 (0.1754) loss_u 0.0743 (0.0249) acc_x 96.8750 (93.9688) acc_u 84.3750 (86.6406) gamma_v 0.0026 (0.0037) gamma_t 0.7827 (0.7759) loss_ind 0.1179 (0.1114) loss_im -2.1626 (-2.1782) loss_new 5.0591 (5.0769)\tlr 2.991783e-03\n",
      "epoch [18/30][300/500]\ttime 0.228 (0.247)\tdata 0.000 (0.001)\teta 0:25:32\tloss 4.7437 (4.1646) loss_x 0.0697 (0.1743) loss_u 0.0368 (0.0262) acc_x 96.8750 (94.1354) acc_u 90.6250 (86.0938) gamma_v 0.0006 (0.0037) gamma_t 0.7876 (0.7787) loss_ind 0.0951 (0.1138) loss_im -2.1352 (-2.1756) loss_new 5.2341 (5.0855)\tlr 6.183221e-04\n",
      "epoch [18/30][400/500]\ttime 0.237 (0.249)\tdata 0.001 (0.001)\teta 0:25:17\tloss 3.5998 (4.1764) loss_x 0.1211 (0.1726) loss_u 0.0119 (0.0273) acc_x 100.0000 (94.1797) acc_u 93.7500 (85.7344) gamma_v 0.0001 (0.0032) gamma_t 0.7858 (0.7815) loss_ind 0.1232 (0.1145) loss_im -2.1982 (-2.1681) loss_new 5.1016 (5.0866)\tlr 8.898950e-04\n",
      "epoch [18/30][500/500]\ttime 0.237 (0.246)\tdata 0.000 (0.001)\teta 0:24:38\tloss 4.1855 (4.1774) loss_x 0.2042 (0.1723) loss_u 0.0464 (0.0272) acc_x 87.5000 (94.1813) acc_u 100.0000 (85.5312) gamma_v 0.0013 (0.0025) gamma_t 0.7950 (0.7829) loss_ind 0.0892 (0.1143) loss_im -2.1410 (-2.1691) loss_new 4.9661 (5.0851)\tlr 2.991783e-03\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 47,351\n",
      "* accuracy: 85.5%\n",
      "* error: 14.5%\n",
      "* macro_f1: 86.1%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,598\tacc: 98.7%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,153\tacc: 90.7%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,273\tacc: 91.1%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,618\tacc: 73.2%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,613\tacc: 98.3%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 2,002\tacc: 96.5%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,451\tacc: 94.0%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,312\tacc: 82.8%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,292\tacc: 94.4%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 1,974\tacc: 86.5%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,012\tacc: 94.7%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,053\tacc: 55.0%\n",
      "* average: 88.0%\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hbcho991/DAMP/DAMP/train.py\", line 229, in <module>\n",
      "    main(args)\n",
      "  File \"/home/hbcho991/DAMP/DAMP/train.py\", line 155, in main\n",
      "    trainer.train()\n",
      "  File \"/home/hbcho991/DAMP/DAMP/trainers/damp.py\", line 617, in train\n",
      "    self.run_epoch()\n",
      "  File \"/home/hbcho991/DAMP/DAMP/trainers/damp.py\", line 660, in run_epoch\n",
      "    loss_summary = self.forward_backward(batch_x, batch_u)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hbcho991/DAMP/DAMP/trainers/damp.py\", line 752, in forward_backward\n",
      "    self.scaler.scale(loss).backward()\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 768, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!sh VisDA17.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e484623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25da905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef8c0ec3",
   "metadata": {},
   "source": [
    "## damp3 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c63d50f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-31 18:35:02.041126: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-31 18:35:02.051986: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-31 18:35:02.064010: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-31 18:35:02.067454: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-31 18:35:02.078094: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-31 18:35:02.767544: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/hbcho991/DAMP/DAMP/trainers/damp.py:196: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/home/hbcho991/DAMP/DAMP/trainers/damp.py:218: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/home/hbcho991/DAMP/DAMP/trainers/damp.py:284: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/home/hbcho991/DAMP/DAMP/trainers/damp.py:385: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/home/hbcho991/DAMP/DAMP/trainers/damp.py:429: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "['TRAINER.DAMP.TAU', '0.5', 'TRAINER.DAMP.U', '2.0']\n",
      "DATALOADER:\n",
      "  K_TRANSFORMS: 1\n",
      "  NUM_WORKERS: 4\n",
      "  RETURN_IMG0: False\n",
      "  TEST:\n",
      "    BATCH_SIZE: 128\n",
      "    SAMPLER: SequentialSampler\n",
      "  TRAIN_U:\n",
      "    BATCH_SIZE: 32\n",
      "    N_DOMAIN: 0\n",
      "    N_INS: 16\n",
      "    SAME_AS_X: True\n",
      "    SAMPLER: RandomSampler\n",
      "  TRAIN_X:\n",
      "    BATCH_SIZE: 32\n",
      "    N_DOMAIN: 0\n",
      "    N_INS: 16\n",
      "    SAMPLER: RandomSampler\n",
      "DATASET:\n",
      "  ALL_AS_UNLABELED: False\n",
      "  CIFAR_C_LEVEL: 1\n",
      "  CIFAR_C_TYPE: \n",
      "  NAME: VISDA_C\n",
      "  NUM_LABELED: -1\n",
      "  NUM_SHOTS: -1\n",
      "  ROOT: /home/dataset/\n",
      "  SOURCE_DOMAINS: ['synthetic']\n",
      "  STL10_FOLD: -1\n",
      "  TARGET_DOMAINS: ['real']\n",
      "  VAL_PERCENT: 0.1\n",
      "INPUT:\n",
      "  COLORJITTER_B: 0.4\n",
      "  COLORJITTER_C: 0.4\n",
      "  COLORJITTER_H: 0.1\n",
      "  COLORJITTER_S: 0.4\n",
      "  CROP_PADDING: 4\n",
      "  CUTOUT_LEN: 16\n",
      "  CUTOUT_N: 1\n",
      "  GB_K: 21\n",
      "  GB_P: 0.5\n",
      "  GN_MEAN: 0.0\n",
      "  GN_STD: 0.15\n",
      "  INTERPOLATION: bicubic\n",
      "  NO_TRANSFORM: False\n",
      "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
      "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
      "  RANDAUGMENT_M: 10\n",
      "  RANDAUGMENT_N: 2\n",
      "  RGS_P: 0.2\n",
      "  RRCROP_SCALE: (0.08, 1.0)\n",
      "  SIZE: (224, 224)\n",
      "  TRANSFORMS: ('normalize',)\n",
      "MODEL:\n",
      "  BACKBONE:\n",
      "    NAME: ViT-B/16\n",
      "    PATH: ./assets\n",
      "    PRETRAINED: True\n",
      "  HEAD:\n",
      "    ACTIVATION: relu\n",
      "    BN: True\n",
      "    DROPOUT: 0.0\n",
      "    HIDDEN_LAYERS: ()\n",
      "    NAME: \n",
      "  INIT_WEIGHTS: \n",
      "  INIT_WEIGHTS_CTX: None\n",
      "  INIT_WEIGHTS_PRO: None\n",
      "OPTIM:\n",
      "  ADAM_BETA1: 0.9\n",
      "  ADAM_BETA2: 0.999\n",
      "  BASE_LR_MULT: 0.1\n",
      "  GAMMA: 0.1\n",
      "  LR: 0.003\n",
      "  LR_SCHEDULER: cosine\n",
      "  MAX_EPOCH: 30\n",
      "  MOMENTUM: 0.9\n",
      "  NAME: adam\n",
      "  NEW_LAYERS: ()\n",
      "  RMSPROP_ALPHA: 0.99\n",
      "  SGD_DAMPNING: 0\n",
      "  SGD_NESTEROV: False\n",
      "  STAGED_LR: False\n",
      "  STEPSIZE: (-1,)\n",
      "  WARMUP_CONS_LR: 1e-05\n",
      "  WARMUP_EPOCH: 1\n",
      "  WARMUP_MIN_LR: 1e-05\n",
      "  WARMUP_RECOUNT: True\n",
      "  WARMUP_TYPE: linear\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "OPTIM_C:\n",
      "  ADAM_BETA1: 0.9\n",
      "  ADAM_BETA2: 0.999\n",
      "  BASE_LR_MULT: 0.1\n",
      "  GAMMA: 0.1\n",
      "  LR: 0.003\n",
      "  LR_SCHEDULER: cosine\n",
      "  MAX_EPOCH: 30\n",
      "  MOMENTUM: 0.9\n",
      "  NAME: adam\n",
      "  NEW_LAYERS: ()\n",
      "  RMSPROP_ALPHA: 0.99\n",
      "  SGD_DAMPNING: 0\n",
      "  SGD_NESTEROV: False\n",
      "  STAGED_LR: False\n",
      "  STEPSIZE: (-1,)\n",
      "  WARMUP_CONS_LR: 1e-05\n",
      "  WARMUP_EPOCH: 1\n",
      "  WARMUP_MIN_LR: 1e-05\n",
      "  WARMUP_RECOUNT: True\n",
      "  WARMUP_TYPE: linear\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "OUTPUT_DIR: output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1\n",
      "RESUME: \n",
      "SEED: 1\n",
      "TEST:\n",
      "  COMPUTE_CMAT: False\n",
      "  EVALUATOR: Classification\n",
      "  FINAL_MODEL: last_step\n",
      "  NO_TEST: False\n",
      "  PER_CLASS_RESULT: True\n",
      "  SPLIT: test\n",
      "TRAIN:\n",
      "  CHECKPOINT_FREQ: 0\n",
      "  COUNT_ITER: train_x\n",
      "  PRINT_FREQ: 100\n",
      "TRAINER:\n",
      "  CDAC:\n",
      "    CLASS_LR_MULTI: 10\n",
      "    P_THRESH: 0.95\n",
      "    RAMPUP_COEF: 30\n",
      "    RAMPUP_ITRS: 1000\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    TOPK_MATCH: 5\n",
      "  CROSSGRAD:\n",
      "    ALPHA_D: 0.5\n",
      "    ALPHA_F: 0.5\n",
      "    EPS_D: 1.0\n",
      "    EPS_F: 1.0\n",
      "  DAEL:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 0.5\n",
      "  DAELDG:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 0.5\n",
      "  DAMP:\n",
      "    CSC: False\n",
      "    IM: 1.0\n",
      "    IND: 1.0\n",
      "    N_CLS: 2\n",
      "    N_CTX: 32\n",
      "    PREC: amp\n",
      "    STRONG_TRANSFORMS: ['randaugment', 'normalize']\n",
      "    TAU: 0.5\n",
      "    U: 2.0\n",
      "  DAPL:\n",
      "    CSC: False\n",
      "    N_CTX: 16\n",
      "    N_DMX: 16\n",
      "    PREC: fp16\n",
      "    T: 1.0\n",
      "    TAU: 0.5\n",
      "    U: 1.0\n",
      "  DDAIG:\n",
      "    ALPHA: 0.5\n",
      "    CLAMP: False\n",
      "    CLAMP_MAX: 1.0\n",
      "    CLAMP_MIN: -1.0\n",
      "    G_ARCH: \n",
      "    LMDA: 0.3\n",
      "    WARMUP: 0\n",
      "  DOMAINMIX:\n",
      "    ALPHA: 1.0\n",
      "    BETA: 1.0\n",
      "    TYPE: crossdomain\n",
      "  ENTMIN:\n",
      "    LMDA: 0.001\n",
      "  FIXMATCH:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 1.0\n",
      "  M3SDA:\n",
      "    LMDA: 0.5\n",
      "    N_STEP_F: 4\n",
      "  MCD:\n",
      "    N_STEP_F: 4\n",
      "  MEANTEACHER:\n",
      "    EMA_ALPHA: 0.999\n",
      "    RAMPUP: 5\n",
      "    WEIGHT_U: 1.0\n",
      "  MIXMATCH:\n",
      "    MIXUP_BETA: 0.75\n",
      "    RAMPUP: 20000\n",
      "    TEMP: 2.0\n",
      "    WEIGHT_U: 100.0\n",
      "  MME:\n",
      "    LMDA: 0.1\n",
      "  NAME: DAMP\n",
      "  SE:\n",
      "    CONF_THRE: 0.95\n",
      "    EMA_ALPHA: 0.999\n",
      "    RAMPUP: 300\n",
      "USE_CUDA: True\n",
      "VERBOSE: True\n",
      "VERSION: 1\n",
      "Setting fixed seed: 1\n",
      "***************\n",
      "** Arguments **\n",
      "***************\n",
      "backbone: \n",
      "config_file: configs/trainers/DAMP/damp.yaml\n",
      "dataset_config_file: configs/datasets/visda17.yaml\n",
      "eval_only: False\n",
      "head: \n",
      "load_epoch: None\n",
      "model_dir: \n",
      "no_train: False\n",
      "opts: ['TRAINER.DAMP.TAU', '0.5', 'TRAINER.DAMP.U', '2.0']\n",
      "output_dir: output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1\n",
      "resume: \n",
      "root: /home/dataset/\n",
      "seed: 1\n",
      "source_domains: ['synthetic']\n",
      "target_domains: ['real']\n",
      "trainer: DAMP\n",
      "transforms: None\n",
      "************\n",
      "** Config **\n",
      "************\n",
      "DATALOADER:\n",
      "  K_TRANSFORMS: 1\n",
      "  NUM_WORKERS: 4\n",
      "  RETURN_IMG0: False\n",
      "  TEST:\n",
      "    BATCH_SIZE: 128\n",
      "    SAMPLER: SequentialSampler\n",
      "  TRAIN_U:\n",
      "    BATCH_SIZE: 32\n",
      "    N_DOMAIN: 0\n",
      "    N_INS: 16\n",
      "    SAME_AS_X: True\n",
      "    SAMPLER: RandomSampler\n",
      "  TRAIN_X:\n",
      "    BATCH_SIZE: 32\n",
      "    N_DOMAIN: 0\n",
      "    N_INS: 16\n",
      "    SAMPLER: RandomSampler\n",
      "DATASET:\n",
      "  ALL_AS_UNLABELED: False\n",
      "  CIFAR_C_LEVEL: 1\n",
      "  CIFAR_C_TYPE: \n",
      "  NAME: VISDA_C\n",
      "  NUM_LABELED: -1\n",
      "  NUM_SHOTS: -1\n",
      "  ROOT: /home/dataset/\n",
      "  SOURCE_DOMAINS: ['synthetic']\n",
      "  STL10_FOLD: -1\n",
      "  TARGET_DOMAINS: ['real']\n",
      "  VAL_PERCENT: 0.1\n",
      "INPUT:\n",
      "  COLORJITTER_B: 0.4\n",
      "  COLORJITTER_C: 0.4\n",
      "  COLORJITTER_H: 0.1\n",
      "  COLORJITTER_S: 0.4\n",
      "  CROP_PADDING: 4\n",
      "  CUTOUT_LEN: 16\n",
      "  CUTOUT_N: 1\n",
      "  GB_K: 21\n",
      "  GB_P: 0.5\n",
      "  GN_MEAN: 0.0\n",
      "  GN_STD: 0.15\n",
      "  INTERPOLATION: bicubic\n",
      "  NO_TRANSFORM: False\n",
      "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
      "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
      "  RANDAUGMENT_M: 10\n",
      "  RANDAUGMENT_N: 2\n",
      "  RGS_P: 0.2\n",
      "  RRCROP_SCALE: (0.08, 1.0)\n",
      "  SIZE: (224, 224)\n",
      "  TRANSFORMS: ('normalize',)\n",
      "MODEL:\n",
      "  BACKBONE:\n",
      "    NAME: ViT-B/16\n",
      "    PATH: ./assets\n",
      "    PRETRAINED: True\n",
      "  HEAD:\n",
      "    ACTIVATION: relu\n",
      "    BN: True\n",
      "    DROPOUT: 0.0\n",
      "    HIDDEN_LAYERS: ()\n",
      "    NAME: \n",
      "  INIT_WEIGHTS: \n",
      "  INIT_WEIGHTS_CTX: None\n",
      "  INIT_WEIGHTS_PRO: None\n",
      "OPTIM:\n",
      "  ADAM_BETA1: 0.9\n",
      "  ADAM_BETA2: 0.999\n",
      "  BASE_LR_MULT: 0.1\n",
      "  GAMMA: 0.1\n",
      "  LR: 0.003\n",
      "  LR_SCHEDULER: cosine\n",
      "  MAX_EPOCH: 30\n",
      "  MOMENTUM: 0.9\n",
      "  NAME: adam\n",
      "  NEW_LAYERS: ()\n",
      "  RMSPROP_ALPHA: 0.99\n",
      "  SGD_DAMPNING: 0\n",
      "  SGD_NESTEROV: False\n",
      "  STAGED_LR: False\n",
      "  STEPSIZE: (-1,)\n",
      "  WARMUP_CONS_LR: 1e-05\n",
      "  WARMUP_EPOCH: 1\n",
      "  WARMUP_MIN_LR: 1e-05\n",
      "  WARMUP_RECOUNT: True\n",
      "  WARMUP_TYPE: linear\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "OPTIM_C:\n",
      "  ADAM_BETA1: 0.9\n",
      "  ADAM_BETA2: 0.999\n",
      "  BASE_LR_MULT: 0.1\n",
      "  GAMMA: 0.1\n",
      "  LR: 0.003\n",
      "  LR_SCHEDULER: cosine\n",
      "  MAX_EPOCH: 30\n",
      "  MOMENTUM: 0.9\n",
      "  NAME: adam\n",
      "  NEW_LAYERS: ()\n",
      "  RMSPROP_ALPHA: 0.99\n",
      "  SGD_DAMPNING: 0\n",
      "  SGD_NESTEROV: False\n",
      "  STAGED_LR: False\n",
      "  STEPSIZE: (-1,)\n",
      "  WARMUP_CONS_LR: 1e-05\n",
      "  WARMUP_EPOCH: 1\n",
      "  WARMUP_MIN_LR: 1e-05\n",
      "  WARMUP_RECOUNT: True\n",
      "  WARMUP_TYPE: linear\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "OUTPUT_DIR: output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1\n",
      "RESUME: \n",
      "SEED: 1\n",
      "TEST:\n",
      "  COMPUTE_CMAT: False\n",
      "  EVALUATOR: Classification\n",
      "  FINAL_MODEL: last_step\n",
      "  NO_TEST: False\n",
      "  PER_CLASS_RESULT: True\n",
      "  SPLIT: test\n",
      "TRAIN:\n",
      "  CHECKPOINT_FREQ: 0\n",
      "  COUNT_ITER: train_x\n",
      "  PRINT_FREQ: 100\n",
      "TRAINER:\n",
      "  CDAC:\n",
      "    CLASS_LR_MULTI: 10\n",
      "    P_THRESH: 0.95\n",
      "    RAMPUP_COEF: 30\n",
      "    RAMPUP_ITRS: 1000\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    TOPK_MATCH: 5\n",
      "  CROSSGRAD:\n",
      "    ALPHA_D: 0.5\n",
      "    ALPHA_F: 0.5\n",
      "    EPS_D: 1.0\n",
      "    EPS_F: 1.0\n",
      "  DAEL:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 0.5\n",
      "  DAELDG:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 0.5\n",
      "  DAMP:\n",
      "    CSC: False\n",
      "    IM: 1.0\n",
      "    IND: 1.0\n",
      "    N_CLS: 2\n",
      "    N_CTX: 32\n",
      "    PREC: amp\n",
      "    STRONG_TRANSFORMS: ['randaugment', 'normalize']\n",
      "    TAU: 0.5\n",
      "    U: 2.0\n",
      "  DAPL:\n",
      "    CSC: False\n",
      "    N_CTX: 16\n",
      "    N_DMX: 16\n",
      "    PREC: fp16\n",
      "    T: 1.0\n",
      "    TAU: 0.5\n",
      "    U: 1.0\n",
      "  DDAIG:\n",
      "    ALPHA: 0.5\n",
      "    CLAMP: False\n",
      "    CLAMP_MAX: 1.0\n",
      "    CLAMP_MIN: -1.0\n",
      "    G_ARCH: \n",
      "    LMDA: 0.3\n",
      "    WARMUP: 0\n",
      "  DOMAINMIX:\n",
      "    ALPHA: 1.0\n",
      "    BETA: 1.0\n",
      "    TYPE: crossdomain\n",
      "  ENTMIN:\n",
      "    LMDA: 0.001\n",
      "  FIXMATCH:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 1.0\n",
      "  M3SDA:\n",
      "    LMDA: 0.5\n",
      "    N_STEP_F: 4\n",
      "  MCD:\n",
      "    N_STEP_F: 4\n",
      "  MEANTEACHER:\n",
      "    EMA_ALPHA: 0.999\n",
      "    RAMPUP: 5\n",
      "    WEIGHT_U: 1.0\n",
      "  MIXMATCH:\n",
      "    MIXUP_BETA: 0.75\n",
      "    RAMPUP: 20000\n",
      "    TEMP: 2.0\n",
      "    WEIGHT_U: 100.0\n",
      "  MME:\n",
      "    LMDA: 0.1\n",
      "  NAME: DAMP\n",
      "  SE:\n",
      "    CONF_THRE: 0.95\n",
      "    EMA_ALPHA: 0.999\n",
      "    RAMPUP: 300\n",
      "USE_CUDA: True\n",
      "VERBOSE: True\n",
      "VERSION: 1\n",
      "Collecting env info ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** System info **\n",
      "PyTorch version: 2.4.0+cu121\n",
      "Is debug build: False\n",
      "CUDA used to build PyTorch: 12.1\n",
      "ROCM used to build PyTorch: N/A\n",
      "\n",
      "OS: Ubuntu 22.04.3 LTS (x86_64)\n",
      "GCC version: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Clang version: Could not collect\n",
      "CMake version: version 3.22.1\n",
      "Libc version: glibc-2.35\n",
      "\n",
      "Python version: 3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0] (64-bit runtime)\n",
      "Python platform: Linux-6.2.0-26-generic-x86_64-with-glibc2.35\n",
      "Is CUDA available: True\n",
      "CUDA runtime version: 12.3.103\n",
      "CUDA_MODULE_LOADING set to: LAZY\n",
      "GPU models and configuration: \n",
      "GPU 0: NVIDIA GeForce RTX 4090\n",
      "GPU 1: NVIDIA GeForce RTX 4090\n",
      "GPU 2: NVIDIA GeForce RTX 4090\n",
      "GPU 3: NVIDIA GeForce RTX 4090\n",
      "GPU 4: NVIDIA GeForce RTX 4090\n",
      "GPU 5: NVIDIA GeForce RTX 4090\n",
      "GPU 6: NVIDIA GeForce RTX 4090\n",
      "GPU 7: NVIDIA GeForce RTX 4090\n",
      "\n",
      "Nvidia driver version: 535.129.03\n",
      "cuDNN version: Could not collect\n",
      "HIP runtime version: N/A\n",
      "MIOpen runtime version: N/A\n",
      "Is XNNPACK available: True\n",
      "\n",
      "CPU:\n",
      "Architecture:                    x86_64\n",
      "CPU op-mode(s):                  32-bit, 64-bit\n",
      "Address sizes:                   46 bits physical, 57 bits virtual\n",
      "Byte Order:                      Little Endian\n",
      "CPU(s):                          32\n",
      "On-line CPU(s) list:             0-31\n",
      "Vendor ID:                       GenuineIntel\n",
      "Model name:                      Intel(R) Xeon(R) Gold 6426Y\n",
      "CPU family:                      6\n",
      "Model:                           143\n",
      "Thread(s) per core:              1\n",
      "Core(s) per socket:              16\n",
      "Socket(s):                       2\n",
      "Stepping:                        8\n",
      "CPU max MHz:                     4100.0000\n",
      "CPU min MHz:                     800.0000\n",
      "BogoMIPS:                        5000.00\n",
      "Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 cat_l2 cdp_l3 invpcid_single intel_ppin cdp_l2 ssbd mba ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm rdt_a avx512f avx512dq rdseed adx smap avx512ifma clflushopt clwb intel_pt avx512cd sha_ni avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local split_lock_detect avx_vnni avx512_bf16 wbnoinvd dtherm ida arat pln pts hwp hwp_act_window hwp_epp hwp_pkg_req hfi avx512vbmi umip pku ospke waitpkg avx512_vbmi2 gfni vaes vpclmulqdq avx512_vnni avx512_bitalg tme avx512_vpopcntdq la57 rdpid bus_lock_detect cldemote movdiri movdir64b enqcmd fsrm md_clear serialize tsxldtrk pconfig arch_lbr ibt amx_bf16 avx512_fp16 amx_tile amx_int8 flush_l1d arch_capabilities\n",
      "Virtualization:                  VT-x\n",
      "L1d cache:                       1.5 MiB (32 instances)\n",
      "L1i cache:                       1 MiB (32 instances)\n",
      "L2 cache:                        64 MiB (32 instances)\n",
      "L3 cache:                        75 MiB (2 instances)\n",
      "NUMA node(s):                    2\n",
      "NUMA node0 CPU(s):               0-15\n",
      "NUMA node1 CPU(s):               16-31\n",
      "Vulnerability Itlb multihit:     Not affected\n",
      "Vulnerability L1tf:              Not affected\n",
      "Vulnerability Mds:               Not affected\n",
      "Vulnerability Meltdown:          Not affected\n",
      "Vulnerability Mmio stale data:   Not affected\n",
      "Vulnerability Retbleed:          Not affected\n",
      "Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl\n",
      "Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization\n",
      "Vulnerability Spectre v2:        Mitigation; Enhanced IBRS, IBPB conditional, RSB filling, PBRSB-eIBRS SW sequence\n",
      "Vulnerability Srbds:             Not affected\n",
      "Vulnerability Tsx async abort:   Not affected\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] flake8==3.7.9\n",
      "[pip3] mypy-extensions==1.0.0\n",
      "[pip3] numpy==1.23.0\n",
      "[pip3] numpydoc==1.5.0\n",
      "[pip3] optree==0.12.1\n",
      "[pip3] torch==2.4.0\n",
      "[pip3] torchvision==0.19.0\n",
      "[pip3] triton==3.0.0\n",
      "[conda] _anaconda_depends         2023.09             py311_mkl_1  \n",
      "[conda] blas                      1.0                         mkl  \n",
      "[conda] mkl                       2023.1.0         h213fc3f_46343  \n",
      "[conda] mkl-service               2.4.0           py311h5eee18b_1  \n",
      "[conda] mkl_fft                   1.3.8           py311h5eee18b_0  \n",
      "[conda] mkl_random                1.2.4           py311hdb19cb5_0  \n",
      "[conda] numpy                     1.24.3          py311h08b1b3b_1  \n",
      "[conda] numpy-base                1.24.3          py311hf175353_1  \n",
      "[conda] numpydoc                  1.5.0           py311h06a4308_0  \n",
      "        Pillow (9.4.0)\n",
      "\n",
      "Loading trainer: DAMP\n",
      "Building transform_train\n",
      "+ resize to 224x224\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
      "Building transform_train\n",
      "+ resize to 224x224\n",
      "+ randaugment (n=2, m=10)\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
      "Loading dataset: VISDA_C\n",
      "* Using custom transform for training\n",
      "Building transform_test\n",
      "+ resize the smaller edge to 224\n",
      "+ 224x224 center crop\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
      "---------  -------------\n",
      "Dataset    VISDA_C\n",
      "Source     ['synthetic']\n",
      "Target     ['real']\n",
      "# classes  12\n",
      "# train_x  152,397\n",
      "# train_u  55,388\n",
      "# test     55,388\n",
      "---------  -------------\n",
      "['aeroplane', 'bicycle', 'bus', 'car', 'horse', 'knife', 'motorcycle', 'person', 'plant', 'skateboard', 'train', 'truck']\n",
      "Loading CLIP (backbone: ViT-B/16)\n",
      "./assets/ViT-B-16.pt\n",
      "Building custom CLIP\n",
      "ContextDecoder(\n",
      "  (memory_proj): Sequential(\n",
      "    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (text_proj): Sequential(\n",
      "    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "  )\n",
      "  (decoder): ModuleList(\n",
      "    (0-5): 6 x TransformerDecoderLayer(\n",
      "      (self_attn): Attention(\n",
      "        (q_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (k_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (v_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (cross_attn): Attention(\n",
      "        (q_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (k_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (v_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "        (3): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (out_proj): Sequential(\n",
      "    (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=256, out_features=512, bias=True)\n",
      "  )\n",
      ")\n",
      "Initializing a generic context\n",
      "ctx vectors size: \n",
      "Initial context: \"X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X\"\n",
      "Number of context words (tokens): 32\n",
      "Number of cls words (tokens): 2\n",
      "Prompts: \"X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X aeroplane.\"\n",
      "Naive Prompts: \"a real photo of a aeroplane.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turning off gradients in both the image and the text encoder\n",
      "Loading evaluator: Classification\n",
      "No checkpoint found, train from scratch\n",
      "Initialize tensorboard (log_dir=output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/tensorboard)\n",
      "epoch [1/30][100/500]\ttime 0.207 (0.246)\tdata 0.001 (0.004)\teta 1:00:59\tloss 2.3524 (5.3388) loss_x 0.3503 (0.4481) loss_u 0.0491 (0.1634) acc_x 87.5000 (85.0625) acc_u 90.6250 (84.4375) gamma_v 0.0124 (0.0148) gamma_t 0.0731 (0.0497) loss_x_ind 1.1629 (2.3870) loss_im -1.9168 (-1.8583)\tlr 6.183221e-04\n",
      "epoch [1/30][200/500]\ttime 0.254 (0.232)\tdata 0.000 (0.002)\teta 0:57:14\tloss 1.2480 (3.5624) loss_x 0.2867 (0.3827) loss_u 0.0618 (0.1263) acc_x 81.2500 (87.1719) acc_u 84.3750 (84.6562) gamma_v 0.0156 (0.0160) gamma_t 0.0951 (0.0689) loss_x_ind 1.0468 (1.7136) loss_im -1.9218 (-1.9462)\tlr 8.898950e-04\n",
      "epoch [1/30][300/500]\ttime 0.223 (0.235)\tdata 0.001 (0.002)\teta 0:57:32\tloss 0.4950 (2.6007) loss_x 0.3480 (0.3466) loss_u 0.1067 (0.1157) acc_x 87.5000 (88.3750) acc_u 90.6250 (84.7708) gamma_v 0.0193 (0.0162) gamma_t 0.1049 (0.0796) loss_x_ind 0.6260 (1.3504) loss_im -1.9307 (-1.9818)\tlr 2.991783e-03\n",
      "epoch [1/30][400/500]\ttime 0.239 (0.237)\tdata 0.001 (0.002)\teta 0:57:41\tloss -0.3022 (1.9923) loss_x 0.1939 (0.3208) loss_u 0.0302 (0.1065) acc_x 96.8750 (89.1172) acc_u 78.1250 (84.6719) gamma_v 0.0206 (0.0170) gamma_t 0.1161 (0.0877) loss_x_ind 0.2545 (1.1175) loss_im -2.0775 (-1.9949)\tlr 6.183221e-04\n",
      "epoch [1/30][500/500]\ttime 0.241 (0.237)\tdata 0.001 (0.002)\teta 0:57:22\tloss 1.3774 (1.5693) loss_x 0.2806 (0.3078) loss_u 0.1865 (0.1014) acc_x 90.6250 (89.4750) acc_u 81.2500 (84.5500) gamma_v 0.0228 (0.0181) gamma_t 0.1194 (0.0942) loss_x_ind 0.3311 (0.9589) loss_im -1.8714 (-2.0126)\tlr 8.898950e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 47,317\n",
      "* accuracy: 85.4%\n",
      "* error: 14.6%\n",
      "* macro_f1: 86.2%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,606\tacc: 98.9%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,158\tacc: 90.9%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,417\tacc: 94.2%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,208\tacc: 69.3%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,631\tacc: 98.7%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,856\tacc: 89.4%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,516\tacc: 95.2%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,117\tacc: 77.9%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,160\tacc: 91.4%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,207\tacc: 96.8%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,009\tacc: 94.6%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,432\tacc: 61.9%\n",
      "* average: 88.3%\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/prompt_learner/model-best.pth.tar\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/context_decoder/model-best.pth.tar\n",
      "epoch [2/30][100/500]\ttime 0.561 (0.275)\tdata 0.001 (0.003)\teta 1:05:53\tloss -0.4594 (-0.3368) loss_x 0.1429 (0.2066) loss_u 0.0261 (0.0668) acc_x 93.7500 (93.0000) acc_u 93.7500 (85.2812) gamma_v 0.0234 (0.0225) gamma_t 0.1241 (0.1237) loss_x_ind 0.2016 (0.2384) loss_im -2.0875 (-2.0678)\tlr 2.991783e-03\n",
      "epoch [2/30][200/500]\ttime 0.256 (0.275)\tdata 0.001 (0.002)\teta 1:05:30\tloss 0.0547 (-0.3372) loss_x 0.4133 (0.2122) loss_u 0.0379 (0.0723) acc_x 90.6250 (92.7969) acc_u 81.2500 (85.1406) gamma_v 0.0208 (0.0224) gamma_t 0.1301 (0.1258) loss_x_ind 0.1663 (0.2280) loss_im -2.1320 (-2.0753)\tlr 6.183221e-04\n",
      "epoch [2/30][300/500]\ttime 0.277 (0.273)\tdata 0.001 (0.002)\teta 1:04:31\tloss 0.0734 (-0.3977) loss_x 0.1894 (0.2125) loss_u 0.0922 (0.0704) acc_x 90.6250 (92.6354) acc_u 87.5000 (85.3229) gamma_v 0.0211 (0.0223) gamma_t 0.1275 (0.1266) loss_x_ind 0.2263 (0.2154) loss_im -2.0475 (-2.0763)\tlr 8.898950e-04\n",
      "epoch [2/30][400/500]\ttime 0.264 (0.277)\tdata 0.001 (0.002)\teta 1:05:10\tloss -1.3523 (-0.4514) loss_x 0.2089 (0.2094) loss_u 0.0048 (0.0680) acc_x 96.8750 (92.7891) acc_u 84.3750 (85.2578) gamma_v 0.0273 (0.0222) gamma_t 0.1244 (0.1266) loss_x_ind 0.0680 (0.2032) loss_im -2.1473 (-2.0807)\tlr 2.991783e-03\n",
      "epoch [2/30][500/500]\ttime 0.277 (0.276)\tdata 0.001 (0.002)\teta 1:04:30\tloss -0.8848 (-0.4902) loss_x 0.3398 (0.2039) loss_u 0.0187 (0.0672) acc_x 87.5000 (92.9562) acc_u 90.6250 (85.3250) gamma_v 0.0262 (0.0233) gamma_t 0.1259 (0.1266) loss_x_ind 0.1314 (0.1921) loss_im -2.2517 (-2.0851)\tlr 6.183221e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,047\n",
      "* accuracy: 86.7%\n",
      "* error: 13.3%\n",
      "* macro_f1: 87.6%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,606\tacc: 98.9%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,195\tacc: 91.9%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,404\tacc: 93.9%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,860\tacc: 75.6%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,628\tacc: 98.7%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,960\tacc: 94.5%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,449\tacc: 94.0%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,216\tacc: 80.4%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,059\tacc: 89.2%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,174\tacc: 95.3%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,990\tacc: 94.2%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,506\tacc: 63.2%\n",
      "* average: 89.1%\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/prompt_learner/model-best.pth.tar\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/context_decoder/model-best.pth.tar\n",
      "epoch [3/30][100/500]\ttime 0.274 (0.276)\tdata 0.000 (0.003)\teta 1:03:59\tloss -0.6903 (-0.6691) loss_x 0.2029 (0.1976) loss_u 0.0744 (0.0652) acc_x 93.7500 (93.3125) acc_u 78.1250 (85.6562) gamma_v 0.0241 (0.0256) gamma_t 0.1354 (0.1315) loss_x_ind 0.1258 (0.1394) loss_im -1.9852 (-2.1156)\tlr 8.898950e-04\n",
      "epoch [3/30][200/500]\ttime 0.261 (0.272)\tdata 0.000 (0.002)\teta 1:02:38\tloss -0.9103 (-0.6668) loss_x 0.1940 (0.1937) loss_u 0.0884 (0.0646) acc_x 87.5000 (93.1875) acc_u 84.3750 (85.6875) gamma_v 0.0271 (0.0264) gamma_t 0.1344 (0.1323) loss_x_ind 0.1204 (0.1374) loss_im -2.0443 (-2.1129)\tlr 2.991783e-03\n",
      "epoch [3/30][300/500]\ttime 0.255 (0.274)\tdata 0.001 (0.002)\teta 1:02:29\tloss -0.6874 (-0.6804) loss_x 0.1460 (0.1979) loss_u 0.0439 (0.0646) acc_x 93.7500 (93.0729) acc_u 96.8750 (85.5208) gamma_v 0.0268 (0.0267) gamma_t 0.1363 (0.1338) loss_x_ind 0.1035 (0.1309) loss_im -2.0832 (-2.1137)\tlr 6.183221e-04\n",
      "epoch [3/30][400/500]\ttime 0.263 (0.277)\tdata 0.001 (0.002)\teta 1:02:47\tloss -0.9204 (-0.6826) loss_x 0.1465 (0.1986) loss_u 0.0267 (0.0639) acc_x 96.8750 (93.0859) acc_u 81.2500 (85.6094) gamma_v 0.0264 (0.0265) gamma_t 0.1418 (0.1353) loss_x_ind 0.1075 (0.1285) loss_im -1.9651 (-2.1137)\tlr 8.898950e-04\n",
      "epoch [3/30][500/500]\ttime 0.279 (0.276)\tdata 0.000 (0.001)\teta 1:02:12\tloss -0.9853 (-0.6924) loss_x 0.1109 (0.1954) loss_u 0.0820 (0.0627) acc_x 93.7500 (93.1437) acc_u 90.6250 (85.5938) gamma_v 0.0301 (0.0271) gamma_t 0.1458 (0.1366) loss_x_ind 0.0906 (0.1240) loss_im -1.9869 (-2.1157)\tlr 2.991783e-03\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 47,641\n",
      "* accuracy: 86.0%\n",
      "* error: 14.0%\n",
      "* macro_f1: 87.2%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,605\tacc: 98.9%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,248\tacc: 93.5%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,407\tacc: 94.0%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,236\tacc: 69.6%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,616\tacc: 98.4%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,908\tacc: 92.0%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,464\tacc: 94.3%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,393\tacc: 84.8%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,126\tacc: 90.7%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,168\tacc: 95.0%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,979\tacc: 93.9%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,491\tacc: 62.9%\n",
      "* average: 89.0%\n",
      "epoch [4/30][100/500]\ttime 0.278 (0.268)\tdata 0.001 (0.004)\teta 0:59:50\tloss -1.0560 (-0.7333) loss_x 0.0267 (0.1914) loss_u 0.0648 (0.0575) acc_x 100.0000 (93.0000) acc_u 81.2500 (85.2812) gamma_v 0.0299 (0.0276) gamma_t 0.1405 (0.1420) loss_x_ind 0.0960 (0.1034) loss_im -2.1285 (-2.1092)\tlr 6.183221e-04\n",
      "epoch [4/30][200/500]\ttime 0.266 (0.274)\tdata 0.001 (0.002)\teta 1:00:39\tloss -1.4177 (-0.7847) loss_x 0.0276 (0.1919) loss_u 0.1254 (0.0555) acc_x 100.0000 (92.9062) acc_u 84.3750 (85.2969) gamma_v 0.0267 (0.0286) gamma_t 0.1418 (0.1419) loss_x_ind 0.1597 (0.1012) loss_im -2.2310 (-2.1145)\tlr 8.898950e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [4/30][300/500]\ttime 0.261 (0.276)\tdata 0.001 (0.002)\teta 1:00:37\tloss -1.4009 (-0.7830) loss_x 0.0666 (0.1839) loss_u 0.0843 (0.0563) acc_x 100.0000 (93.1979) acc_u 93.7500 (85.4792) gamma_v 0.0302 (0.0286) gamma_t 0.1488 (0.1425) loss_x_ind 0.1738 (0.1014) loss_im -2.2280 (-2.1109)\tlr 2.991783e-03\n",
      "epoch [4/30][400/500]\ttime 0.573 (0.276)\tdata 0.005 (0.002)\teta 1:00:21\tloss -1.0120 (-0.7800) loss_x 0.2226 (0.1858) loss_u 0.0261 (0.0562) acc_x 93.7500 (93.1953) acc_u 87.5000 (85.5234) gamma_v 0.0331 (0.0292) gamma_t 0.1433 (0.1427) loss_x_ind 0.0510 (0.1050) loss_im -2.3197 (-2.1122)\tlr 6.183221e-04\n",
      "epoch [4/30][500/500]\ttime 0.276 (0.275)\tdata 0.001 (0.002)\teta 0:59:35\tloss -0.3727 (-0.7783) loss_x 0.1299 (0.1836) loss_u 0.0845 (0.0564) acc_x 96.8750 (93.2812) acc_u 78.1250 (85.5250) gamma_v 0.0301 (0.0297) gamma_t 0.1474 (0.1435) loss_x_ind 0.0617 (0.1044) loss_im -2.1104 (-2.1138)\tlr 8.898950e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,376\n",
      "* accuracy: 87.3%\n",
      "* error: 12.7%\n",
      "* macro_f1: 88.2%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,607\tacc: 98.9%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,169\tacc: 91.2%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,289\tacc: 91.4%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,979\tacc: 76.7%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,614\tacc: 98.4%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,940\tacc: 93.5%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,475\tacc: 94.5%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,304\tacc: 82.6%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,156\tacc: 91.4%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,188\tacc: 95.9%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,013\tacc: 94.7%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,642\tacc: 65.6%\n",
      "* average: 89.6%\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/prompt_learner/model-best.pth.tar\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/context_decoder/model-best.pth.tar\n",
      "epoch [5/30][100/500]\ttime 0.256 (0.289)\tdata 0.001 (0.004)\teta 1:02:13\tloss -0.4469 (-0.9131) loss_x 0.1868 (0.1769) loss_u 0.0211 (0.0494) acc_x 84.3750 (93.0000) acc_u 75.0000 (84.7812) gamma_v 0.0342 (0.0312) gamma_t 0.1460 (0.1503) loss_x_ind 0.1028 (0.0979) loss_im -2.0799 (-2.1172)\tlr 2.991783e-03\n",
      "epoch [5/30][200/500]\ttime 0.233 (0.271)\tdata 0.001 (0.002)\teta 0:57:43\tloss -0.9074 (-0.8536) loss_x 0.1281 (0.1701) loss_u 0.0478 (0.0491) acc_x 93.7500 (93.4844) acc_u 87.5000 (85.0156) gamma_v 0.0290 (0.0307) gamma_t 0.1495 (0.1500) loss_x_ind 0.0797 (0.0988) loss_im -2.0736 (-2.1138)\tlr 6.183221e-04\n",
      "epoch [5/30][300/500]\ttime 0.271 (0.268)\tdata 0.001 (0.002)\teta 0:56:46\tloss -1.2105 (-0.8444) loss_x 0.1769 (0.1740) loss_u 0.0140 (0.0513) acc_x 93.7500 (93.5521) acc_u 90.6250 (85.2292) gamma_v 0.0341 (0.0317) gamma_t 0.1589 (0.1504) loss_x_ind 0.2223 (0.0986) loss_im -2.2126 (-2.1172)\tlr 8.898950e-04\n",
      "epoch [5/30][400/500]\ttime 0.254 (0.264)\tdata 0.001 (0.002)\teta 0:55:31\tloss -0.0338 (-0.8555) loss_x 0.1853 (0.1727) loss_u 0.1508 (0.0509) acc_x 93.7500 (93.5703) acc_u 68.7500 (85.3984) gamma_v 0.0347 (0.0325) gamma_t 0.1568 (0.1520) loss_x_ind 0.0737 (0.0954) loss_im -2.1103 (-2.1225)\tlr 2.991783e-03\n",
      "epoch [5/30][500/500]\ttime 0.255 (0.265)\tdata 0.000 (0.002)\teta 0:55:18\tloss -0.8887 (-0.8435) loss_x 0.0494 (0.1712) loss_u 0.1195 (0.0511) acc_x 100.0000 (93.6500) acc_u 81.2500 (85.3438) gamma_v 0.0364 (0.0330) gamma_t 0.1601 (0.1531) loss_x_ind 0.0457 (0.0954) loss_im -2.1417 (-2.1206)\tlr 6.183221e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,172\n",
      "* accuracy: 87.0%\n",
      "* error: 13.0%\n",
      "* macro_f1: 87.7%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,605\tacc: 98.9%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,202\tacc: 92.1%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,376\tacc: 93.3%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,959\tacc: 76.5%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,631\tacc: 98.7%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,958\tacc: 94.4%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,470\tacc: 94.4%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,278\tacc: 82.0%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,104\tacc: 90.2%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,183\tacc: 95.7%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,023\tacc: 95.0%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,383\tacc: 61.0%\n",
      "* average: 89.3%\n",
      "epoch [6/30][100/500]\ttime 0.253 (0.271)\tdata 0.001 (0.004)\teta 0:55:58\tloss -1.0964 (-0.8094) loss_x 0.1311 (0.1761) loss_u 0.0146 (0.0459) acc_x 96.8750 (93.3438) acc_u 87.5000 (85.6875) gamma_v 0.0333 (0.0341) gamma_t 0.1656 (0.1609) loss_x_ind 0.0265 (0.0885) loss_im -2.0966 (-2.1167)\tlr 8.898950e-04\n",
      "epoch [6/30][200/500]\ttime 0.240 (0.265)\tdata 0.001 (0.002)\teta 0:54:24\tloss -0.8345 (-0.8720) loss_x 0.1134 (0.1716) loss_u 0.0616 (0.0469) acc_x 90.6250 (93.6250) acc_u 81.2500 (85.2969) gamma_v 0.0366 (0.0325) gamma_t 0.1622 (0.1621) loss_x_ind 0.0895 (0.0841) loss_im -1.9344 (-2.1280)\tlr 2.991783e-03\n",
      "epoch [6/30][300/500]\ttime 0.259 (0.263)\tdata 0.001 (0.002)\teta 0:53:23\tloss -1.0140 (-0.8794) loss_x 0.1882 (0.1756) loss_u 0.0612 (0.0450) acc_x 87.5000 (93.6146) acc_u 81.2500 (85.6042) gamma_v 0.0376 (0.0339) gamma_t 0.1617 (0.1625) loss_x_ind 0.0693 (0.0854) loss_im -2.1420 (-2.1244)\tlr 6.183221e-04\n",
      "epoch [6/30][400/500]\ttime 0.256 (0.261)\tdata 0.001 (0.002)\teta 0:52:38\tloss -1.1889 (-0.8803) loss_x 0.0616 (0.1770) loss_u 0.0132 (0.0463) acc_x 96.8750 (93.7031) acc_u 93.7500 (85.6406) gamma_v 0.0435 (0.0348) gamma_t 0.1654 (0.1631) loss_x_ind 0.1076 (0.0845) loss_im -2.1397 (-2.1269)\tlr 8.898950e-04\n",
      "epoch [6/30][500/500]\ttime 0.235 (0.263)\tdata 0.000 (0.002)\teta 0:52:36\tloss -0.4999 (-0.8819) loss_x 0.1846 (0.1758) loss_u 0.0171 (0.0464) acc_x 90.6250 (93.7500) acc_u 84.3750 (85.6125) gamma_v 0.0348 (0.0356) gamma_t 0.1719 (0.1640) loss_x_ind 0.0902 (0.0828) loss_im -2.0710 (-2.1257)\tlr 2.991783e-03\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,034\n",
      "* accuracy: 86.7%\n",
      "* error: 13.3%\n",
      "* macro_f1: 87.6%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,607\tacc: 98.9%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,206\tacc: 92.3%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,387\tacc: 93.5%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,974\tacc: 76.7%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,621\tacc: 98.5%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,982\tacc: 95.5%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,513\tacc: 95.1%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,411\tacc: 85.3%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,034\tacc: 88.7%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,136\tacc: 93.6%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,026\tacc: 95.0%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,137\tacc: 56.5%\n",
      "* average: 89.1%\n",
      "epoch [7/30][100/500]\ttime 0.249 (0.271)\tdata 0.001 (0.003)\teta 0:53:47\tloss -0.7471 (-0.8733) loss_x 0.2128 (0.1696) loss_u 0.0812 (0.0472) acc_x 90.6250 (93.7500) acc_u 78.1250 (84.5312) gamma_v 0.0365 (0.0363) gamma_t 0.1695 (0.1689) loss_x_ind 0.0477 (0.0820) loss_im -1.9138 (-2.1193)\tlr 6.183221e-04\n",
      "epoch [7/30][200/500]\ttime 0.254 (0.271)\tdata 0.000 (0.002)\teta 0:53:21\tloss -0.6941 (-0.9223) loss_x 0.0613 (0.1651) loss_u 0.0224 (0.0449) acc_x 100.0000 (94.0938) acc_u 84.3750 (85.2031) gamma_v 0.0380 (0.0382) gamma_t 0.1750 (0.1696) loss_x_ind 0.0872 (0.0776) loss_im -2.0684 (-2.1281)\tlr 8.898950e-04\n",
      "epoch [7/30][300/500]\ttime 0.202 (0.265)\tdata 0.001 (0.002)\teta 0:51:36\tloss -1.2615 (-0.8930) loss_x 0.2186 (0.1699) loss_u 0.0125 (0.0431) acc_x 93.7500 (93.7292) acc_u 78.1250 (85.6146) gamma_v 0.0405 (0.0383) gamma_t 0.1763 (0.1719) loss_x_ind 0.1094 (0.0769) loss_im -2.0333 (-2.1306)\tlr 2.991783e-03\n",
      "epoch [7/30][400/500]\ttime 0.234 (0.258)\tdata 0.001 (0.002)\teta 0:49:57\tloss -1.6496 (-0.8866) loss_x 0.0547 (0.1705) loss_u 0.0424 (0.0443) acc_x 96.8750 (93.5547) acc_u 90.6250 (85.5703) gamma_v 0.0395 (0.0380) gamma_t 0.1815 (0.1729) loss_x_ind 0.0478 (0.0788) loss_im -2.2955 (-2.1307)\tlr 6.183221e-04\n",
      "epoch [7/30][500/500]\ttime 0.277 (0.261)\tdata 0.000 (0.002)\teta 0:49:57\tloss -0.1804 (-0.8978) loss_x 0.0610 (0.1682) loss_u 0.0830 (0.0446) acc_x 100.0000 (93.7250) acc_u 87.5000 (85.7438) gamma_v 0.0381 (0.0386) gamma_t 0.1822 (0.1742) loss_x_ind 0.1802 (0.0784) loss_im -1.9818 (-2.1289)\tlr 8.898950e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,348\n",
      "* accuracy: 87.3%\n",
      "* error: 12.7%\n",
      "* macro_f1: 88.1%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,606\tacc: 98.9%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,243\tacc: 93.3%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,346\tacc: 92.7%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,760\tacc: 74.6%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,622\tacc: 98.5%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,984\tacc: 95.6%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,443\tacc: 93.9%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,242\tacc: 81.0%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,137\tacc: 90.9%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,192\tacc: 96.1%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,004\tacc: 94.5%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,769\tacc: 67.9%\n",
      "* average: 89.8%\n",
      "epoch [8/30][100/500]\ttime 0.230 (0.253)\tdata 0.001 (0.004)\teta 0:48:03\tloss -0.9114 (-0.9305) loss_x 0.1956 (0.1722) loss_u 0.0741 (0.0403) acc_x 90.6250 (93.8438) acc_u 93.7500 (85.5312) gamma_v 0.0406 (0.0406) gamma_t 0.1764 (0.1826) loss_x_ind 0.1259 (0.0788) loss_im -2.1620 (-2.1360)\tlr 2.991783e-03\n",
      "epoch [8/30][200/500]\ttime 0.258 (0.257)\tdata 0.001 (0.002)\teta 0:48:24\tloss -1.0975 (-0.9219) loss_x 0.1355 (0.1719) loss_u 0.0252 (0.0419) acc_x 96.8750 (93.7656) acc_u 84.3750 (85.9844) gamma_v 0.0451 (0.0396) gamma_t 0.1872 (0.1842) loss_x_ind 0.0628 (0.0775) loss_im -1.9941 (-2.1320)\tlr 6.183221e-04\n",
      "epoch [8/30][300/500]\ttime 0.281 (0.265)\tdata 0.001 (0.002)\teta 0:49:22\tloss -0.2079 (-0.9430) loss_x 0.4391 (0.1687) loss_u 0.0310 (0.0415) acc_x 81.2500 (93.8854) acc_u 78.1250 (85.9688) gamma_v 0.0427 (0.0410) gamma_t 0.1874 (0.1841) loss_x_ind 0.0337 (0.0757) loss_im -2.0817 (-2.1370)\tlr 8.898950e-04\n",
      "epoch [8/30][400/500]\ttime 0.261 (0.268)\tdata 0.001 (0.002)\teta 0:49:33\tloss -0.7260 (-0.9408) loss_x 0.0530 (0.1664) loss_u 0.0415 (0.0419) acc_x 100.0000 (93.9609) acc_u 81.2500 (85.7656) gamma_v 0.0423 (0.0412) gamma_t 0.1822 (0.1849) loss_x_ind 0.0329 (0.0728) loss_im -2.0761 (-2.1366)\tlr 2.991783e-03\n",
      "epoch [8/30][500/500]\ttime 0.264 (0.272)\tdata 0.001 (0.002)\teta 0:49:49\tloss -1.0262 (-0.9273) loss_x 0.2091 (0.1663) loss_u 0.0043 (0.0419) acc_x 93.7500 (93.9500) acc_u 93.7500 (86.0000) gamma_v 0.0466 (0.0414) gamma_t 0.1886 (0.1857) loss_x_ind 0.0507 (0.0728) loss_im -2.0174 (-2.1366)\tlr 6.183221e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,283\n",
      "* accuracy: 87.2%\n",
      "* error: 12.8%\n",
      "* macro_f1: 88.0%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,608\tacc: 99.0%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,222\tacc: 92.7%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,329\tacc: 92.3%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,920\tacc: 76.1%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,621\tacc: 98.5%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,960\tacc: 94.5%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,466\tacc: 94.3%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,333\tacc: 83.3%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,162\tacc: 91.5%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,186\tacc: 95.8%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,009\tacc: 94.6%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,467\tacc: 62.5%\n",
      "* average: 89.6%\n",
      "epoch [9/30][100/500]\ttime 0.376 (0.258)\tdata 0.000 (0.004)\teta 0:46:49\tloss -0.6771 (-0.9800) loss_x 0.1840 (0.1658) loss_u 0.0555 (0.0372) acc_x 93.7500 (93.9375) acc_u 84.3750 (86.4375) gamma_v 0.0406 (0.0404) gamma_t 0.1849 (0.1885) loss_x_ind 0.0299 (0.0652) loss_im -2.0322 (-2.1298)\tlr 8.898950e-04\n",
      "epoch [9/30][200/500]\ttime 0.254 (0.263)\tdata 0.001 (0.002)\teta 0:47:22\tloss -1.0561 (-0.9810) loss_x 0.2437 (0.1658) loss_u 0.0109 (0.0360) acc_x 96.8750 (94.2344) acc_u 90.6250 (85.8125) gamma_v 0.0476 (0.0411) gamma_t 0.1947 (0.1897) loss_x_ind 0.0835 (0.0619) loss_im -2.0653 (-2.1423)\tlr 2.991783e-03\n",
      "epoch [9/30][300/500]\ttime 0.255 (0.266)\tdata 0.001 (0.002)\teta 0:47:22\tloss -1.3799 (-0.9764) loss_x 0.1472 (0.1685) loss_u 0.0306 (0.0369) acc_x 96.8750 (94.1458) acc_u 87.5000 (86.1250) gamma_v 0.0436 (0.0416) gamma_t 0.1938 (0.1917) loss_x_ind 0.0280 (0.0643) loss_im -2.2252 (-2.1395)\tlr 6.183221e-04\n",
      "epoch [9/30][400/500]\ttime 0.237 (0.265)\tdata 0.001 (0.002)\teta 0:46:52\tloss -0.9704 (-0.9661) loss_x 0.1592 (0.1676) loss_u 0.0123 (0.0371) acc_x 93.7500 (94.2031) acc_u 87.5000 (86.3203) gamma_v 0.0425 (0.0418) gamma_t 0.2035 (0.1929) loss_x_ind 0.1235 (0.0647) loss_im -2.0474 (-2.1402)\tlr 8.898950e-04\n",
      "epoch [9/30][500/500]\ttime 0.240 (0.260)\tdata 0.001 (0.002)\teta 0:45:30\tloss -1.1537 (-0.9554) loss_x 0.1563 (0.1685) loss_u 0.0304 (0.0385) acc_x 90.6250 (94.2000) acc_u 78.1250 (86.1437) gamma_v 0.0436 (0.0421) gamma_t 0.2030 (0.1950) loss_x_ind 0.0908 (0.0664) loss_im -2.3027 (-2.1380)\tlr 2.991783e-03\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,115\n",
      "* accuracy: 86.9%\n",
      "* error: 13.1%\n",
      "* macro_f1: 87.8%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,606\tacc: 98.9%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,182\tacc: 91.6%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,422\tacc: 94.3%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,722\tacc: 74.2%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,630\tacc: 98.7%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,967\tacc: 94.8%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,506\tacc: 95.0%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,304\tacc: 82.6%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,148\tacc: 91.2%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,176\tacc: 95.4%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,970\tacc: 93.7%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,482\tacc: 62.8%\n",
      "* average: 89.4%\n",
      "epoch [10/30][100/500]\ttime 0.258 (0.251)\tdata 0.001 (0.004)\teta 0:43:28\tloss -1.2036 (-0.9547) loss_x 0.1320 (0.1623) loss_u 0.0121 (0.0344) acc_x 96.8750 (94.0938) acc_u 87.5000 (86.3438) gamma_v 0.0467 (0.0469) gamma_t 0.2024 (0.2005) loss_x_ind 0.0870 (0.0693) loss_im -1.9746 (-2.1192)\tlr 6.183221e-04\n",
      "epoch [10/30][200/500]\ttime 0.223 (0.249)\tdata 0.001 (0.002)\teta 0:42:40\tloss -0.5115 (-0.9457) loss_x 0.1473 (0.1568) loss_u 0.0404 (0.0379) acc_x 93.7500 (94.3594) acc_u 78.1250 (86.1094) gamma_v 0.0449 (0.0457) gamma_t 0.2047 (0.2016) loss_x_ind 0.0592 (0.0695) loss_im -2.1396 (-2.1236)\tlr 8.898950e-04\n",
      "epoch [10/30][300/500]\ttime 0.219 (0.244)\tdata 0.001 (0.002)\teta 0:41:29\tloss -1.6925 (-0.9728) loss_x 0.0493 (0.1568) loss_u 0.0033 (0.0375) acc_x 96.8750 (94.2708) acc_u 90.6250 (86.3125) gamma_v 0.0514 (0.0454) gamma_t 0.1988 (0.2016) loss_x_ind 0.0194 (0.0666) loss_im -2.0773 (-2.1309)\tlr 2.991783e-03\n",
      "epoch [10/30][400/500]\ttime 0.273 (0.248)\tdata 0.001 (0.002)\teta 0:41:40\tloss -0.1228 (-0.9678) loss_x 0.1805 (0.1607) loss_u 0.0841 (0.0392) acc_x 93.7500 (94.1953) acc_u 81.2500 (86.2031) gamma_v 0.0471 (0.0451) gamma_t 0.2078 (0.2029) loss_x_ind 0.0396 (0.0664) loss_im -1.9901 (-2.1334)\tlr 6.183221e-04\n",
      "epoch [10/30][500/500]\ttime 0.275 (0.249)\tdata 0.001 (0.002)\teta 0:41:34\tloss -0.0527 (-0.9779) loss_x 0.0523 (0.1583) loss_u 0.0645 (0.0399) acc_x 100.0000 (94.2875) acc_u 81.2500 (85.9938) gamma_v 0.0503 (0.0458) gamma_t 0.2057 (0.2038) loss_x_ind 0.0881 (0.0659) loss_im -2.0657 (-2.1364)\tlr 8.898950e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,091\n",
      "* accuracy: 86.8%\n",
      "* error: 13.2%\n",
      "* macro_f1: 87.8%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,603\tacc: 98.8%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,184\tacc: 91.6%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,342\tacc: 92.6%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,454\tacc: 71.7%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,627\tacc: 98.6%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,971\tacc: 95.0%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,538\tacc: 95.5%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,299\tacc: 82.5%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,101\tacc: 90.2%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,181\tacc: 95.6%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,013\tacc: 94.7%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,778\tacc: 68.1%\n",
      "* average: 89.6%\n",
      "epoch [11/30][100/500]\ttime 0.259 (0.270)\tdata 0.000 (0.003)\teta 0:44:30\tloss -1.1741 (-0.9352) loss_x 0.2445 (0.1481) loss_u 0.0328 (0.0394) acc_x 93.7500 (94.6875) acc_u 90.6250 (84.9688) gamma_v 0.0383 (0.0473) gamma_t 0.2127 (0.2103) loss_x_ind 0.0434 (0.0623) loss_im -2.2537 (-2.1312)\tlr 2.991783e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [11/30][200/500]\ttime 0.240 (0.267)\tdata 0.001 (0.002)\teta 0:43:34\tloss -0.3151 (-0.9566) loss_x 0.1342 (0.1511) loss_u 0.0120 (0.0391) acc_x 93.7500 (94.8125) acc_u 90.6250 (85.5000) gamma_v 0.0497 (0.0477) gamma_t 0.2104 (0.2101) loss_x_ind 0.0715 (0.0605) loss_im -2.2466 (-2.1379)\tlr 6.183221e-04\n",
      "epoch [11/30][300/500]\ttime 0.344 (0.257)\tdata 0.001 (0.002)\teta 0:41:30\tloss -0.3630 (-0.9630) loss_x 0.1673 (0.1508) loss_u 0.0364 (0.0394) acc_x 96.8750 (94.7917) acc_u 78.1250 (85.4688) gamma_v 0.0507 (0.0482) gamma_t 0.2125 (0.2102) loss_x_ind 0.0775 (0.0621) loss_im -1.9613 (-2.1378)\tlr 8.898950e-04\n",
      "epoch [11/30][400/500]\ttime 0.236 (0.255)\tdata 0.001 (0.002)\teta 0:40:48\tloss -0.9761 (-0.9755) loss_x 0.1819 (0.1517) loss_u 0.0298 (0.0384) acc_x 93.7500 (94.6719) acc_u 90.6250 (85.4844) gamma_v 0.0446 (0.0485) gamma_t 0.2166 (0.2114) loss_x_ind 0.0685 (0.0616) loss_im -2.1176 (-2.1358)\tlr 2.991783e-03\n",
      "epoch [11/30][500/500]\ttime 0.295 (0.256)\tdata 0.000 (0.002)\teta 0:40:36\tloss -0.8539 (-0.9917) loss_x 0.1017 (0.1513) loss_u 0.0041 (0.0372) acc_x 93.7500 (94.6813) acc_u 93.7500 (85.7062) gamma_v 0.0479 (0.0481) gamma_t 0.2220 (0.2131) loss_x_ind 0.0342 (0.0615) loss_im -2.0548 (-2.1407)\tlr 6.183221e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 47,990\n",
      "* accuracy: 86.6%\n",
      "* error: 13.4%\n",
      "* macro_f1: 87.5%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,609\tacc: 99.0%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,284\tacc: 94.5%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,364\tacc: 93.0%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,915\tacc: 76.1%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,625\tacc: 98.6%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 2,017\tacc: 97.2%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,410\tacc: 93.3%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,351\tacc: 83.8%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,089\tacc: 89.9%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,092\tacc: 91.7%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,969\tacc: 93.7%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,265\tacc: 58.9%\n",
      "* average: 89.1%\n",
      "epoch [12/30][100/500]\ttime 0.259 (0.265)\tdata 0.001 (0.004)\teta 0:41:27\tloss -0.5662 (-0.9845) loss_x 0.3052 (0.1598) loss_u 0.0252 (0.0341) acc_x 93.7500 (94.2500) acc_u 84.3750 (86.0938) gamma_v 0.0458 (0.0509) gamma_t 0.2258 (0.2194) loss_x_ind 0.0402 (0.0594) loss_im -2.0406 (-2.1425)\tlr 8.898950e-04\n",
      "epoch [12/30][200/500]\ttime 0.458 (0.256)\tdata 0.001 (0.003)\teta 0:39:37\tloss 0.1051 (-0.9579) loss_x 0.1135 (0.1588) loss_u 0.1199 (0.0369) acc_x 96.8750 (94.2969) acc_u 81.2500 (86.3438) gamma_v 0.0503 (0.0497) gamma_t 0.2332 (0.2229) loss_x_ind 0.1130 (0.0594) loss_im -2.0926 (-2.1458)\tlr 2.991783e-03\n",
      "epoch [12/30][300/500]\ttime 0.252 (0.260)\tdata 0.001 (0.002)\teta 0:39:49\tloss -1.5008 (-1.0066) loss_x 0.1249 (0.1527) loss_u 0.0430 (0.0366) acc_x 96.8750 (94.6771) acc_u 81.2500 (86.2396) gamma_v 0.0531 (0.0503) gamma_t 0.2235 (0.2248) loss_x_ind 0.0596 (0.0606) loss_im -2.2638 (-2.1459)\tlr 6.183221e-04\n",
      "epoch [12/30][400/500]\ttime 0.223 (0.258)\tdata 0.001 (0.002)\teta 0:39:07\tloss -1.0481 (-1.0218) loss_x 0.1266 (0.1537) loss_u 0.0198 (0.0357) acc_x 93.7500 (94.5859) acc_u 84.3750 (86.5391) gamma_v 0.0526 (0.0507) gamma_t 0.2245 (0.2249) loss_x_ind 0.0390 (0.0619) loss_im -2.3078 (-2.1491)\tlr 8.898950e-04\n",
      "epoch [12/30][500/500]\ttime 0.255 (0.257)\tdata 0.001 (0.002)\teta 0:38:29\tloss -1.5318 (-1.0170) loss_x 0.0856 (0.1549) loss_u 0.0093 (0.0366) acc_x 96.8750 (94.4688) acc_u 90.6250 (86.4062) gamma_v 0.0447 (0.0505) gamma_t 0.2253 (0.2254) loss_x_ind 0.0690 (0.0604) loss_im -2.2641 (-2.1480)\tlr 2.991783e-03\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,607\n",
      "* accuracy: 87.8%\n",
      "* error: 12.2%\n",
      "* macro_f1: 88.6%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,605\tacc: 98.9%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,182\tacc: 91.6%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,334\tacc: 92.4%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 8,050\tacc: 77.4%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,633\tacc: 98.8%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,984\tacc: 95.6%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,435\tacc: 93.8%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,314\tacc: 82.8%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,174\tacc: 91.8%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,113\tacc: 92.6%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,030\tacc: 95.1%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,753\tacc: 67.6%\n",
      "* average: 89.9%\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/prompt_learner/model-best.pth.tar\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/context_decoder/model-best.pth.tar\n",
      "epoch [13/30][100/500]\ttime 0.224 (0.251)\tdata 0.001 (0.004)\teta 0:37:13\tloss -0.6281 (-0.9662) loss_x 0.0607 (0.1591) loss_u 0.0669 (0.0358) acc_x 100.0000 (94.2500) acc_u 87.5000 (86.5312) gamma_v 0.0460 (0.0473) gamma_t 0.2291 (0.2247) loss_x_ind 0.0648 (0.0594) loss_im -2.1050 (-2.1474)\tlr 6.183221e-04\n",
      "epoch [13/30][200/500]\ttime 0.277 (0.251)\tdata 0.001 (0.002)\teta 0:36:52\tloss -1.0440 (-0.9714) loss_x 0.2574 (0.1578) loss_u 0.0125 (0.0372) acc_x 87.5000 (94.6094) acc_u 81.2500 (86.5781) gamma_v 0.0480 (0.0499) gamma_t 0.2350 (0.2276) loss_x_ind 0.0636 (0.0574) loss_im -2.3483 (-2.1396)\tlr 8.898950e-04\n",
      "epoch [13/30][300/500]\ttime 0.260 (0.256)\tdata 0.001 (0.002)\teta 0:37:05\tloss -0.8321 (-0.9849) loss_x 0.0736 (0.1561) loss_u 0.0204 (0.0364) acc_x 96.8750 (94.5938) acc_u 96.8750 (86.4688) gamma_v 0.0533 (0.0513) gamma_t 0.2288 (0.2287) loss_x_ind 0.0589 (0.0563) loss_im -2.0861 (-2.1368)\tlr 2.991783e-03\n",
      "epoch [13/30][400/500]\ttime 0.279 (0.258)\tdata 0.001 (0.002)\teta 0:36:56\tloss -0.4659 (-0.9908) loss_x 0.4200 (0.1560) loss_u 0.0323 (0.0365) acc_x 87.5000 (94.5000) acc_u 90.6250 (86.5391) gamma_v 0.0511 (0.0511) gamma_t 0.2345 (0.2300) loss_x_ind 0.0534 (0.0554) loss_im -2.0439 (-2.1399)\tlr 6.183221e-04\n",
      "epoch [13/30][500/500]\ttime 0.258 (0.257)\tdata 0.001 (0.001)\teta 0:36:24\tloss -0.7106 (-0.9964) loss_x 0.2397 (0.1555) loss_u 0.0593 (0.0354) acc_x 84.3750 (94.4750) acc_u 90.6250 (86.5312) gamma_v 0.0622 (0.0518) gamma_t 0.2369 (0.2315) loss_x_ind 0.0767 (0.0560) loss_im -1.9032 (-2.1396)\tlr 8.898950e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,033\n",
      "* accuracy: 86.7%\n",
      "* error: 13.3%\n",
      "* macro_f1: 87.9%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,592\tacc: 98.5%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,166\tacc: 91.1%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,266\tacc: 91.0%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,280\tacc: 70.0%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,621\tacc: 98.5%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,979\tacc: 95.4%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,459\tacc: 94.2%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,377\tacc: 84.4%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,079\tacc: 89.7%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,164\tacc: 94.9%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,970\tacc: 93.7%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 4,080\tacc: 73.5%\n",
      "* average: 89.6%\n",
      "epoch [14/30][100/500]\ttime 0.247 (0.249)\tdata 0.001 (0.003)\teta 0:34:49\tloss -1.5380 (-1.0781) loss_x 0.0499 (0.1543) loss_u 0.0213 (0.0316) acc_x 100.0000 (94.4688) acc_u 81.2500 (86.7188) gamma_v 0.0549 (0.0598) gamma_t 0.2416 (0.2387) loss_x_ind 0.0129 (0.0542) loss_im -2.0827 (-2.1439)\tlr 2.991783e-03\n",
      "epoch [14/30][200/500]\ttime 0.258 (0.255)\tdata 0.001 (0.002)\teta 0:35:15\tloss -1.2473 (-1.0175) loss_x 0.0442 (0.1579) loss_u 0.0314 (0.0346) acc_x 100.0000 (94.5156) acc_u 87.5000 (86.2812) gamma_v 0.0586 (0.0592) gamma_t 0.2408 (0.2387) loss_x_ind 0.0521 (0.0534) loss_im -2.1145 (-2.1368)\tlr 6.183221e-04\n",
      "epoch [14/30][300/500]\ttime 0.260 (0.257)\tdata 0.001 (0.002)\teta 0:35:05\tloss -1.3578 (-1.0110) loss_x 0.0656 (0.1583) loss_u 0.0499 (0.0348) acc_x 96.8750 (94.4271) acc_u 87.5000 (86.1562) gamma_v 0.0588 (0.0574) gamma_t 0.2369 (0.2408) loss_x_ind 0.0423 (0.0560) loss_im -2.0949 (-2.1424)\tlr 8.898950e-04\n",
      "epoch [14/30][400/500]\ttime 0.228 (0.260)\tdata 0.001 (0.002)\teta 0:35:04\tloss -1.1666 (-0.9932) loss_x 0.1391 (0.1593) loss_u 0.0739 (0.0351) acc_x 93.7500 (94.3672) acc_u 84.3750 (85.9141) gamma_v 0.0556 (0.0571) gamma_t 0.2430 (0.2413) loss_x_ind 0.0419 (0.0554) loss_im -2.1410 (-2.1417)\tlr 2.991783e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [14/30][500/500]\ttime 0.256 (0.259)\tdata 0.001 (0.002)\teta 0:34:28\tloss -1.1427 (-1.0012) loss_x 0.1195 (0.1573) loss_u 0.0091 (0.0345) acc_x 96.8750 (94.3250) acc_u 87.5000 (86.0687) gamma_v 0.0583 (0.0572) gamma_t 0.2411 (0.2415) loss_x_ind 0.0338 (0.0555) loss_im -2.2012 (-2.1429)\tlr 6.183221e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,314\n",
      "* accuracy: 87.2%\n",
      "* error: 12.8%\n",
      "* macro_f1: 88.1%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,607\tacc: 98.9%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,194\tacc: 91.9%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,397\tacc: 93.8%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,822\tacc: 75.2%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,632\tacc: 98.7%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,966\tacc: 94.7%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,505\tacc: 95.0%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,304\tacc: 82.6%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,157\tacc: 91.4%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,173\tacc: 95.3%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,949\tacc: 93.2%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,608\tacc: 65.0%\n",
      "* average: 89.6%\n",
      "epoch [15/30][100/500]\ttime 0.277 (0.280)\tdata 0.001 (0.004)\teta 0:36:52\tloss -0.8533 (-0.9354) loss_x 0.2004 (0.1601) loss_u 0.0709 (0.0359) acc_x 93.7500 (94.0625) acc_u 87.5000 (86.0625) gamma_v 0.0541 (0.0539) gamma_t 0.2487 (0.2460) loss_x_ind 0.0196 (0.0546) loss_im -2.0864 (-2.1312)\tlr 8.898950e-04\n",
      "epoch [15/30][200/500]\ttime 0.260 (0.277)\tdata 0.001 (0.002)\teta 0:36:00\tloss -1.6567 (-0.9636) loss_x 0.0590 (0.1574) loss_u 0.0148 (0.0354) acc_x 96.8750 (94.2344) acc_u 90.6250 (85.5156) gamma_v 0.0517 (0.0550) gamma_t 0.2467 (0.2451) loss_x_ind 0.1212 (0.0556) loss_im -2.2323 (-2.1360)\tlr 2.991783e-03\n",
      "epoch [15/30][300/500]\ttime 0.283 (0.274)\tdata 0.001 (0.002)\teta 0:35:07\tloss 0.0077 (-0.9945) loss_x 0.1087 (0.1508) loss_u 0.0213 (0.0341) acc_x 93.7500 (94.5312) acc_u 87.5000 (86.1250) gamma_v 0.0651 (0.0575) gamma_t 0.2423 (0.2446) loss_x_ind 0.0479 (0.0579) loss_im -2.1321 (-2.1456)\tlr 6.183221e-04\n",
      "epoch [15/30][400/500]\ttime 0.257 (0.274)\tdata 0.001 (0.002)\teta 0:34:45\tloss -1.0910 (-1.0175) loss_x 0.0423 (0.1453) loss_u 0.0668 (0.0343) acc_x 100.0000 (94.7109) acc_u 90.6250 (86.3203) gamma_v 0.0549 (0.0577) gamma_t 0.2466 (0.2453) loss_x_ind 0.0943 (0.0569) loss_im -2.0533 (-2.1442)\tlr 8.898950e-04\n",
      "epoch [15/30][500/500]\ttime 0.261 (0.276)\tdata 0.001 (0.002)\teta 0:34:28\tloss -1.3156 (-1.0169) loss_x 0.1515 (0.1479) loss_u 0.0530 (0.0337) acc_x 93.7500 (94.6437) acc_u 87.5000 (86.4437) gamma_v 0.0550 (0.0575) gamma_t 0.2515 (0.2458) loss_x_ind 0.0298 (0.0572) loss_im -2.1286 (-2.1426)\tlr 2.991783e-03\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,853\n",
      "* accuracy: 88.2%\n",
      "* error: 11.8%\n",
      "* macro_f1: 88.9%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,601\tacc: 98.8%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,217\tacc: 92.6%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,248\tacc: 90.6%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 8,325\tacc: 80.0%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,616\tacc: 98.4%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,990\tacc: 95.9%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,437\tacc: 93.8%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,302\tacc: 82.5%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,222\tacc: 92.8%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,163\tacc: 94.8%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,056\tacc: 95.8%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,676\tacc: 66.3%\n",
      "* average: 90.2%\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/prompt_learner/model-best.pth.tar\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/context_decoder/model-best.pth.tar\n",
      "epoch [16/30][100/500]\ttime 0.240 (0.275)\tdata 0.001 (0.004)\teta 0:33:56\tloss -1.2473 (-1.0122) loss_x 0.1195 (0.1332) loss_u 0.0184 (0.0324) acc_x 96.8750 (94.9688) acc_u 87.5000 (86.2188) gamma_v 0.0598 (0.0604) gamma_t 0.2499 (0.2490) loss_x_ind 0.0740 (0.0581) loss_im -2.2359 (-2.1385)\tlr 6.183221e-04\n",
      "epoch [16/30][200/500]\ttime 0.257 (0.266)\tdata 0.001 (0.003)\teta 0:32:24\tloss -1.4285 (-1.0371) loss_x 0.0162 (0.1387) loss_u 0.0793 (0.0340) acc_x 100.0000 (94.9375) acc_u 87.5000 (85.8438) gamma_v 0.0682 (0.0605) gamma_t 0.2468 (0.2487) loss_x_ind 0.0354 (0.0565) loss_im -2.3049 (-2.1503)\tlr 8.898950e-04\n",
      "epoch [16/30][300/500]\ttime 0.276 (0.270)\tdata 0.001 (0.002)\teta 0:32:24\tloss -1.4534 (-1.0205) loss_x 0.1634 (0.1457) loss_u 0.0258 (0.0345) acc_x 96.8750 (94.6458) acc_u 90.6250 (85.8958) gamma_v 0.0510 (0.0601) gamma_t 0.2523 (0.2501) loss_x_ind 0.0654 (0.0572) loss_im -2.2682 (-2.1489)\tlr 2.991783e-03\n",
      "epoch [16/30][400/500]\ttime 0.262 (0.270)\tdata 0.001 (0.002)\teta 0:32:00\tloss -1.5714 (-1.0164) loss_x 0.0773 (0.1463) loss_u 0.0269 (0.0347) acc_x 96.8750 (94.6328) acc_u 87.5000 (85.9844) gamma_v 0.0543 (0.0589) gamma_t 0.2594 (0.2515) loss_x_ind 0.0490 (0.0565) loss_im -2.1993 (-2.1481)\tlr 6.183221e-04\n",
      "epoch [16/30][500/500]\ttime 0.498 (0.273)\tdata 0.002 (0.002)\teta 0:31:50\tloss -0.9576 (-1.0145) loss_x 0.1050 (0.1476) loss_u 0.0460 (0.0347) acc_x 96.8750 (94.6312) acc_u 90.6250 (86.1375) gamma_v 0.0591 (0.0592) gamma_t 0.2613 (0.2527) loss_x_ind 0.0692 (0.0554) loss_im -2.2351 (-2.1481)\tlr 8.898950e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,258\n",
      "* accuracy: 87.1%\n",
      "* error: 12.9%\n",
      "* macro_f1: 87.9%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,593\tacc: 98.5%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,240\tacc: 93.2%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,294\tacc: 91.6%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,737\tacc: 74.4%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,634\tacc: 98.8%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,989\tacc: 95.9%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,448\tacc: 94.0%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,152\tacc: 78.8%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,249\tacc: 93.4%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,162\tacc: 94.8%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,005\tacc: 94.5%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,755\tacc: 67.7%\n",
      "* average: 89.6%\n",
      "epoch [17/30][100/500]\ttime 0.253 (0.264)\tdata 0.000 (0.003)\teta 0:30:18\tloss -0.3979 (-1.0631) loss_x 0.3260 (0.1423) loss_u 0.0432 (0.0349) acc_x 87.5000 (95.0312) acc_u 90.6250 (86.7812) gamma_v 0.0574 (0.0609) gamma_t 0.2555 (0.2587) loss_x_ind 0.0662 (0.0536) loss_im -1.9517 (-2.1416)\tlr 2.991783e-03\n",
      "epoch [17/30][200/500]\ttime 0.257 (0.268)\tdata 0.001 (0.002)\teta 0:30:24\tloss -1.0719 (-1.0507) loss_x 0.1926 (0.1427) loss_u 0.0227 (0.0342) acc_x 93.7500 (94.9375) acc_u 87.5000 (86.9375) gamma_v 0.0607 (0.0584) gamma_t 0.2560 (0.2566) loss_x_ind 0.0331 (0.0552) loss_im -2.0784 (-2.1456)\tlr 6.183221e-04\n",
      "epoch [17/30][300/500]\ttime 0.256 (0.270)\tdata 0.001 (0.002)\teta 0:30:09\tloss -0.5046 (-1.0414) loss_x 0.1724 (0.1419) loss_u 0.0375 (0.0340) acc_x 90.6250 (94.9479) acc_u 78.1250 (86.5312) gamma_v 0.0616 (0.0592) gamma_t 0.2620 (0.2577) loss_x_ind 0.0321 (0.0544) loss_im -2.1022 (-2.1436)\tlr 8.898950e-04\n",
      "epoch [17/30][400/500]\ttime 0.255 (0.271)\tdata 0.000 (0.001)\teta 0:29:45\tloss -0.3575 (-1.0419) loss_x 0.1721 (0.1435) loss_u 0.0729 (0.0340) acc_x 93.7500 (94.8594) acc_u 81.2500 (86.5391) gamma_v 0.0603 (0.0601) gamma_t 0.2620 (0.2583) loss_x_ind 0.0456 (0.0546) loss_im -2.0814 (-2.1439)\tlr 2.991783e-03\n",
      "epoch [17/30][500/500]\ttime 0.256 (0.268)\tdata 0.001 (0.001)\teta 0:29:00\tloss -1.1250 (-1.0375) loss_x 0.1149 (0.1450) loss_u 0.0284 (0.0345) acc_x 93.7500 (94.7500) acc_u 87.5000 (86.5062) gamma_v 0.0636 (0.0602) gamma_t 0.2596 (0.2590) loss_x_ind 0.0505 (0.0555) loss_im -1.9286 (-2.1434)\tlr 6.183221e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,201\n",
      "* accuracy: 87.0%\n",
      "* error: 13.0%\n",
      "* macro_f1: 88.0%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,590\tacc: 98.5%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,246\tacc: 93.4%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,314\tacc: 92.0%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,627\tacc: 73.3%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,629\tacc: 98.7%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 2,012\tacc: 97.0%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,463\tacc: 94.3%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,308\tacc: 82.7%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,205\tacc: 92.4%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,155\tacc: 94.5%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,007\tacc: 94.6%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,645\tacc: 65.7%\n",
      "* average: 89.7%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [18/30][100/500]\ttime 0.276 (0.256)\tdata 0.001 (0.004)\teta 0:27:15\tloss -0.8367 (-1.0039) loss_x 0.1791 (0.1654) loss_u 0.0379 (0.0333) acc_x 93.7500 (93.6875) acc_u 90.6250 (86.5938) gamma_v 0.0647 (0.0610) gamma_t 0.2603 (0.2608) loss_x_ind 0.0949 (0.0579) loss_im -2.1719 (-2.1544)\tlr 8.898950e-04\n",
      "epoch [18/30][200/500]\ttime 0.278 (0.274)\tdata 0.001 (0.002)\teta 0:28:45\tloss -0.5796 (-0.9919) loss_x 0.1755 (0.1564) loss_u 0.0131 (0.0354) acc_x 93.7500 (94.1406) acc_u 87.5000 (86.1094) gamma_v 0.0630 (0.0610) gamma_t 0.2676 (0.2626) loss_x_ind 0.0342 (0.0551) loss_im -2.0411 (-2.1483)\tlr 2.991783e-03\n",
      "epoch [18/30][300/500]\ttime 0.281 (0.278)\tdata 0.001 (0.002)\teta 0:28:40\tloss -0.2752 (-1.0240) loss_x 0.2457 (0.1501) loss_u 0.0556 (0.0336) acc_x 90.6250 (94.4062) acc_u 84.3750 (86.3021) gamma_v 0.0580 (0.0615) gamma_t 0.2706 (0.2648) loss_x_ind 0.0562 (0.0538) loss_im -2.2251 (-2.1530)\tlr 6.183221e-04\n",
      "epoch [18/30][400/500]\ttime 0.260 (0.276)\tdata 0.001 (0.002)\teta 0:28:05\tloss -1.2326 (-1.0436) loss_x 0.1384 (0.1441) loss_u 0.0440 (0.0334) acc_x 96.8750 (94.6016) acc_u 93.7500 (86.7266) gamma_v 0.0685 (0.0612) gamma_t 0.2633 (0.2653) loss_x_ind 0.0516 (0.0517) loss_im -2.2737 (-2.1544)\tlr 8.898950e-04\n",
      "epoch [18/30][500/500]\ttime 0.262 (0.274)\tdata 0.001 (0.002)\teta 0:27:26\tloss -1.0883 (-1.0429) loss_x 0.1064 (0.1436) loss_u 0.0183 (0.0329) acc_x 96.8750 (94.5812) acc_u 90.6250 (86.8563) gamma_v 0.0652 (0.0613) gamma_t 0.2779 (0.2663) loss_x_ind 0.1161 (0.0534) loss_im -2.1299 (-2.1559)\tlr 2.991783e-03\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,386\n",
      "* accuracy: 87.4%\n",
      "* error: 12.6%\n",
      "* macro_f1: 87.7%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,589\tacc: 98.4%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,261\tacc: 93.8%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,239\tacc: 90.4%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 8,166\tacc: 78.5%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,631\tacc: 98.7%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 2,037\tacc: 98.2%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,401\tacc: 93.2%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,121\tacc: 78.0%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,188\tacc: 92.1%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,109\tacc: 92.5%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,013\tacc: 94.7%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,631\tacc: 65.4%\n",
      "* average: 89.5%\n",
      "epoch [19/30][100/500]\ttime 0.221 (0.255)\tdata 0.001 (0.003)\teta 0:25:07\tloss -1.0349 (-1.0365) loss_x 0.0406 (0.1571) loss_u 0.0334 (0.0321) acc_x 100.0000 (94.4688) acc_u 90.6250 (86.3125) gamma_v 0.0659 (0.0671) gamma_t 0.2666 (0.2674) loss_x_ind 0.0771 (0.0581) loss_im -2.1310 (-2.1629)\tlr 6.183221e-04\n",
      "epoch [19/30][200/500]\ttime 0.227 (0.242)\tdata 0.000 (0.002)\teta 0:23:23\tloss -1.1564 (-1.0402) loss_x 0.1377 (0.1527) loss_u 0.0253 (0.0323) acc_x 96.8750 (94.6875) acc_u 90.6250 (86.6719) gamma_v 0.0648 (0.0636) gamma_t 0.2746 (0.2697) loss_x_ind 0.0529 (0.0550) loss_im -2.2393 (-2.1507)\tlr 8.898950e-04\n",
      "epoch [19/30][300/500]\ttime 0.256 (0.250)\tdata 0.000 (0.002)\teta 0:23:45\tloss -0.8211 (-1.0421) loss_x 0.1259 (0.1481) loss_u 0.0229 (0.0319) acc_x 93.7500 (94.7604) acc_u 93.7500 (87.0208) gamma_v 0.0690 (0.0624) gamma_t 0.2740 (0.2710) loss_x_ind 0.0438 (0.0519) loss_im -2.0944 (-2.1479)\tlr 2.991783e-03\n",
      "epoch [19/30][400/500]\ttime 0.264 (0.256)\tdata 0.001 (0.002)\teta 0:23:53\tloss -0.4559 (-1.0312) loss_x 0.2537 (0.1470) loss_u 0.0126 (0.0333) acc_x 93.7500 (94.8125) acc_u 93.7500 (86.9219) gamma_v 0.0666 (0.0632) gamma_t 0.2751 (0.2718) loss_x_ind 0.0679 (0.0528) loss_im -2.2528 (-2.1473)\tlr 6.183221e-04\n",
      "epoch [19/30][500/500]\ttime 0.254 (0.257)\tdata 0.001 (0.001)\teta 0:23:32\tloss -0.5718 (-1.0296) loss_x 0.1824 (0.1451) loss_u 0.0687 (0.0337) acc_x 93.7500 (94.8688) acc_u 87.5000 (86.6312) gamma_v 0.0635 (0.0622) gamma_t 0.2743 (0.2722) loss_x_ind 0.1235 (0.0534) loss_im -2.0438 (-2.1482)\tlr 8.898950e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,386\n",
      "* accuracy: 87.4%\n",
      "* error: 12.6%\n",
      "* macro_f1: 88.1%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,606\tacc: 98.9%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,219\tacc: 92.6%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,288\tacc: 91.4%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 8,247\tacc: 79.3%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,616\tacc: 98.4%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,976\tacc: 95.2%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,454\tacc: 94.1%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,286\tacc: 82.2%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,066\tacc: 89.4%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,188\tacc: 95.9%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,993\tacc: 94.3%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,447\tacc: 62.1%\n",
      "* average: 89.5%\n",
      "epoch [20/30][100/500]\ttime 0.217 (0.247)\tdata 0.001 (0.004)\teta 0:22:15\tloss -1.6731 (-1.0091) loss_x 0.1143 (0.1554) loss_u 0.0269 (0.0322) acc_x 93.7500 (94.2812) acc_u 93.7500 (86.7188) gamma_v 0.0686 (0.0630) gamma_t 0.2623 (0.2686) loss_x_ind 0.0550 (0.0523) loss_im -2.3404 (-2.1350)\tlr 2.991783e-03\n",
      "epoch [20/30][200/500]\ttime 0.262 (0.249)\tdata 0.000 (0.002)\teta 0:22:00\tloss -1.2258 (-1.0158) loss_x 0.2425 (0.1503) loss_u 0.0076 (0.0337) acc_x 87.5000 (94.5156) acc_u 87.5000 (86.2969) gamma_v 0.0650 (0.0620) gamma_t 0.2708 (0.2679) loss_x_ind 0.0169 (0.0532) loss_im -2.2120 (-2.1334)\tlr 6.183221e-04\n",
      "epoch [20/30][300/500]\ttime 0.255 (0.256)\tdata 0.000 (0.002)\teta 0:22:10\tloss -1.7550 (-1.0240) loss_x 0.0213 (0.1435) loss_u 0.0235 (0.0347) acc_x 100.0000 (94.7188) acc_u 90.6250 (86.1042) gamma_v 0.0779 (0.0637) gamma_t 0.2672 (0.2685) loss_x_ind 0.0722 (0.0504) loss_im -2.1667 (-2.1357)\tlr 8.898950e-04\n",
      "epoch [20/30][400/500]\ttime 0.223 (0.255)\tdata 0.001 (0.002)\teta 0:21:39\tloss -1.5319 (-1.0116) loss_x 0.1767 (0.1409) loss_u 0.0200 (0.0355) acc_x 96.8750 (94.9297) acc_u 87.5000 (86.0781) gamma_v 0.0667 (0.0640) gamma_t 0.2793 (0.2699) loss_x_ind 0.0522 (0.0510) loss_im -2.1090 (-2.1407)\tlr 2.991783e-03\n",
      "epoch [20/30][500/500]\ttime 0.277 (0.257)\tdata 0.000 (0.002)\teta 0:21:27\tloss -1.3370 (-1.0126) loss_x 0.1088 (0.1412) loss_u 0.0427 (0.0349) acc_x 93.7500 (94.9688) acc_u 81.2500 (86.1562) gamma_v 0.0650 (0.0650) gamma_t 0.2731 (0.2709) loss_x_ind 0.0370 (0.0511) loss_im -2.1708 (-2.1403)\tlr 6.183221e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,506\n",
      "* accuracy: 87.6%\n",
      "* error: 12.4%\n",
      "* macro_f1: 88.2%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,603\tacc: 98.8%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,234\tacc: 93.1%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,313\tacc: 92.0%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 8,545\tacc: 82.2%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,624\tacc: 98.6%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,968\tacc: 94.8%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,458\tacc: 94.2%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,333\tacc: 83.3%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,213\tacc: 92.6%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,174\tacc: 95.3%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,991\tacc: 94.2%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,050\tacc: 55.0%\n",
      "* average: 89.5%\n",
      "epoch [21/30][100/500]\ttime 0.275 (0.283)\tdata 0.001 (0.003)\teta 0:23:06\tloss -0.7568 (-1.0115) loss_x 0.0606 (0.1415) loss_u 0.0502 (0.0307) acc_x 96.8750 (94.8438) acc_u 90.6250 (86.5938) gamma_v 0.0640 (0.0615) gamma_t 0.2766 (0.2782) loss_x_ind 0.0695 (0.0610) loss_im -2.1119 (-2.1317)\tlr 8.898950e-04\n",
      "epoch [21/30][200/500]\ttime 0.251 (0.280)\tdata 0.001 (0.002)\teta 0:22:23\tloss -0.4614 (-1.0104) loss_x 0.0744 (0.1458) loss_u 0.0875 (0.0324) acc_x 96.8750 (94.7500) acc_u 90.6250 (86.7344) gamma_v 0.0679 (0.0629) gamma_t 0.2770 (0.2805) loss_x_ind 0.0312 (0.0566) loss_im -2.1369 (-2.1390)\tlr 2.991783e-03\n",
      "epoch [21/30][300/500]\ttime 0.285 (0.282)\tdata 0.001 (0.002)\teta 0:22:03\tloss -0.4581 (-1.0097) loss_x 0.0906 (0.1453) loss_u 0.0768 (0.0337) acc_x 96.8750 (94.7083) acc_u 87.5000 (86.4583) gamma_v 0.0604 (0.0643) gamma_t 0.2786 (0.2802) loss_x_ind 0.0594 (0.0539) loss_im -2.1075 (-2.1415)\tlr 6.183221e-04\n",
      "epoch [21/30][400/500]\ttime 0.276 (0.276)\tdata 0.001 (0.002)\teta 0:21:10\tloss -1.3510 (-1.0160) loss_x 0.1211 (0.1449) loss_u 0.0236 (0.0336) acc_x 96.8750 (94.7109) acc_u 96.8750 (86.4609) gamma_v 0.0634 (0.0642) gamma_t 0.2851 (0.2806) loss_x_ind 0.0533 (0.0530) loss_im -2.1775 (-2.1449)\tlr 8.898950e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [21/30][500/500]\ttime 0.280 (0.278)\tdata 0.001 (0.002)\teta 0:20:52\tloss -1.1726 (-1.0215) loss_x 0.2010 (0.1474) loss_u 0.0306 (0.0339) acc_x 87.5000 (94.6250) acc_u 84.3750 (86.4437) gamma_v 0.0736 (0.0650) gamma_t 0.2805 (0.2811) loss_x_ind 0.0340 (0.0520) loss_im -2.1804 (-2.1456)\tlr 2.991783e-03\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,033\n",
      "* accuracy: 86.7%\n",
      "* error: 13.3%\n",
      "* macro_f1: 87.8%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,607\tacc: 98.9%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,163\tacc: 91.0%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,339\tacc: 92.5%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,480\tacc: 71.9%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,627\tacc: 98.6%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,982\tacc: 95.5%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,534\tacc: 95.5%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,375\tacc: 84.4%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,156\tacc: 91.4%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,173\tacc: 95.3%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,960\tacc: 93.5%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,637\tacc: 65.6%\n",
      "* average: 89.5%\n",
      "epoch [22/30][100/500]\ttime 0.254 (0.240)\tdata 0.001 (0.003)\teta 0:17:34\tloss -1.1728 (-1.0214) loss_x 0.0657 (0.1556) loss_u 0.0241 (0.0357) acc_x 96.8750 (94.1875) acc_u 87.5000 (86.0938) gamma_v 0.0651 (0.0700) gamma_t 0.2808 (0.2819) loss_x_ind 0.0442 (0.0533) loss_im -2.1612 (-2.1374)\tlr 6.183221e-04\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hbcho991/DAMP/DAMP/train.py\", line 229, in <module>\n",
      "    main(args)\n",
      "  File \"/home/hbcho991/DAMP/DAMP/train.py\", line 155, in main\n",
      "    trainer.train()\n",
      "  File \"/home/hbcho991/DAMP/DAMP/trainers/damp.py\", line 621, in train\n",
      "    self.run_epoch()\n",
      "  File \"/home/hbcho991/DAMP/DAMP/trainers/damp.py\", line 664, in run_epoch\n",
      "    loss_summary = self.forward_backward(batch_x, batch_u)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hbcho991/DAMP/DAMP/trainers/damp.py\", line 707, in forward_backward\n",
      "    output_x, output_x_ind = self.model(image_x, ind =True, pse=False)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/amp/autocast_mode.py\", line 43, in decorate_autocast\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hbcho991/DAMP/DAMP/trainers/damp.py\", line 443, in forward\n",
      "    text_embeddings, text_contexts = self.text_encoder(raw_prompt, tokenized_prompts)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/amp/autocast_mode.py\", line 43, in decorate_autocast\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hbcho991/DAMP/DAMP/trainers/damp.py\", line 203, in forward\n",
      "    text_embedding_at_eos = x[torch.arange(x.shape[0]), tokenized_prompts.argmax(dim=-1)] @ self.text_projection\n",
      "                                                                                            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1716, in __getattr__\n",
      "    def __getattr__(self, name: str) -> Any:\n",
      "\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!sh VisDA17.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7737d66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77e42b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a189b5a9",
   "metadata": {},
   "source": [
    "## damp4 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1c934cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-31 19:38:14.436318: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-31 19:38:14.446782: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-31 19:38:14.458479: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-31 19:38:14.461978: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-31 19:38:14.471429: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-31 19:38:15.113313: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/hbcho991/DAMP/DAMP/trainers/damp.py:287: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/home/hbcho991/DAMP/DAMP/trainers/damp.py:309: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/home/hbcho991/DAMP/DAMP/trainers/damp.py:375: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/home/hbcho991/DAMP/DAMP/trainers/damp.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "/home/hbcho991/DAMP/DAMP/trainers/damp.py:520: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast()\n",
      "['TRAINER.DAMP.TAU', '0.5', 'TRAINER.DAMP.U', '2.0']\n",
      "DATALOADER:\n",
      "  K_TRANSFORMS: 1\n",
      "  NUM_WORKERS: 4\n",
      "  RETURN_IMG0: False\n",
      "  TEST:\n",
      "    BATCH_SIZE: 128\n",
      "    SAMPLER: SequentialSampler\n",
      "  TRAIN_U:\n",
      "    BATCH_SIZE: 32\n",
      "    N_DOMAIN: 0\n",
      "    N_INS: 16\n",
      "    SAME_AS_X: True\n",
      "    SAMPLER: RandomSampler\n",
      "  TRAIN_X:\n",
      "    BATCH_SIZE: 32\n",
      "    N_DOMAIN: 0\n",
      "    N_INS: 16\n",
      "    SAMPLER: RandomSampler\n",
      "DATASET:\n",
      "  ALL_AS_UNLABELED: False\n",
      "  CIFAR_C_LEVEL: 1\n",
      "  CIFAR_C_TYPE: \n",
      "  NAME: VISDA_C\n",
      "  NUM_LABELED: -1\n",
      "  NUM_SHOTS: -1\n",
      "  ROOT: /home/dataset/\n",
      "  SOURCE_DOMAINS: ['synthetic']\n",
      "  STL10_FOLD: -1\n",
      "  TARGET_DOMAINS: ['real']\n",
      "  VAL_PERCENT: 0.1\n",
      "INPUT:\n",
      "  COLORJITTER_B: 0.4\n",
      "  COLORJITTER_C: 0.4\n",
      "  COLORJITTER_H: 0.1\n",
      "  COLORJITTER_S: 0.4\n",
      "  CROP_PADDING: 4\n",
      "  CUTOUT_LEN: 16\n",
      "  CUTOUT_N: 1\n",
      "  GB_K: 21\n",
      "  GB_P: 0.5\n",
      "  GN_MEAN: 0.0\n",
      "  GN_STD: 0.15\n",
      "  INTERPOLATION: bicubic\n",
      "  NO_TRANSFORM: False\n",
      "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
      "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
      "  RANDAUGMENT_M: 10\n",
      "  RANDAUGMENT_N: 2\n",
      "  RGS_P: 0.2\n",
      "  RRCROP_SCALE: (0.08, 1.0)\n",
      "  SIZE: (224, 224)\n",
      "  TRANSFORMS: ('normalize',)\n",
      "MODEL:\n",
      "  BACKBONE:\n",
      "    NAME: ViT-B/16\n",
      "    PATH: ./assets\n",
      "    PRETRAINED: True\n",
      "  HEAD:\n",
      "    ACTIVATION: relu\n",
      "    BN: True\n",
      "    DROPOUT: 0.0\n",
      "    HIDDEN_LAYERS: ()\n",
      "    NAME: \n",
      "  INIT_WEIGHTS: \n",
      "  INIT_WEIGHTS_CTX: None\n",
      "  INIT_WEIGHTS_PRO: None\n",
      "OPTIM:\n",
      "  ADAM_BETA1: 0.9\n",
      "  ADAM_BETA2: 0.999\n",
      "  BASE_LR_MULT: 0.1\n",
      "  GAMMA: 0.1\n",
      "  LR: 0.003\n",
      "  LR_SCHEDULER: cosine\n",
      "  MAX_EPOCH: 30\n",
      "  MOMENTUM: 0.9\n",
      "  NAME: adam\n",
      "  NEW_LAYERS: ()\n",
      "  RMSPROP_ALPHA: 0.99\n",
      "  SGD_DAMPNING: 0\n",
      "  SGD_NESTEROV: False\n",
      "  STAGED_LR: False\n",
      "  STEPSIZE: (-1,)\n",
      "  WARMUP_CONS_LR: 1e-05\n",
      "  WARMUP_EPOCH: 1\n",
      "  WARMUP_MIN_LR: 1e-05\n",
      "  WARMUP_RECOUNT: True\n",
      "  WARMUP_TYPE: linear\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "OPTIM_C:\n",
      "  ADAM_BETA1: 0.9\n",
      "  ADAM_BETA2: 0.999\n",
      "  BASE_LR_MULT: 0.1\n",
      "  GAMMA: 0.1\n",
      "  LR: 0.003\n",
      "  LR_SCHEDULER: cosine\n",
      "  MAX_EPOCH: 30\n",
      "  MOMENTUM: 0.9\n",
      "  NAME: adam\n",
      "  NEW_LAYERS: ()\n",
      "  RMSPROP_ALPHA: 0.99\n",
      "  SGD_DAMPNING: 0\n",
      "  SGD_NESTEROV: False\n",
      "  STAGED_LR: False\n",
      "  STEPSIZE: (-1,)\n",
      "  WARMUP_CONS_LR: 1e-05\n",
      "  WARMUP_EPOCH: 1\n",
      "  WARMUP_MIN_LR: 1e-05\n",
      "  WARMUP_RECOUNT: True\n",
      "  WARMUP_TYPE: linear\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "OUTPUT_DIR: output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1\n",
      "RESUME: \n",
      "SEED: 1\n",
      "TEST:\n",
      "  COMPUTE_CMAT: False\n",
      "  EVALUATOR: Classification\n",
      "  FINAL_MODEL: last_step\n",
      "  NO_TEST: False\n",
      "  PER_CLASS_RESULT: True\n",
      "  SPLIT: test\n",
      "TRAIN:\n",
      "  CHECKPOINT_FREQ: 0\n",
      "  COUNT_ITER: train_x\n",
      "  PRINT_FREQ: 100\n",
      "TRAINER:\n",
      "  CDAC:\n",
      "    CLASS_LR_MULTI: 10\n",
      "    P_THRESH: 0.95\n",
      "    RAMPUP_COEF: 30\n",
      "    RAMPUP_ITRS: 1000\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    TOPK_MATCH: 5\n",
      "  CROSSGRAD:\n",
      "    ALPHA_D: 0.5\n",
      "    ALPHA_F: 0.5\n",
      "    EPS_D: 1.0\n",
      "    EPS_F: 1.0\n",
      "  DAEL:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 0.5\n",
      "  DAELDG:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 0.5\n",
      "  DAMP:\n",
      "    CSC: False\n",
      "    IM: 1.0\n",
      "    IND: 1.0\n",
      "    N_CLS: 2\n",
      "    N_CTX: 32\n",
      "    PREC: amp\n",
      "    STRONG_TRANSFORMS: ['randaugment', 'normalize']\n",
      "    TAU: 0.5\n",
      "    U: 2.0\n",
      "  DAPL:\n",
      "    CSC: False\n",
      "    N_CTX: 16\n",
      "    N_DMX: 16\n",
      "    PREC: fp16\n",
      "    T: 1.0\n",
      "    TAU: 0.5\n",
      "    U: 1.0\n",
      "  DDAIG:\n",
      "    ALPHA: 0.5\n",
      "    CLAMP: False\n",
      "    CLAMP_MAX: 1.0\n",
      "    CLAMP_MIN: -1.0\n",
      "    G_ARCH: \n",
      "    LMDA: 0.3\n",
      "    WARMUP: 0\n",
      "  DOMAINMIX:\n",
      "    ALPHA: 1.0\n",
      "    BETA: 1.0\n",
      "    TYPE: crossdomain\n",
      "  ENTMIN:\n",
      "    LMDA: 0.001\n",
      "  FIXMATCH:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 1.0\n",
      "  M3SDA:\n",
      "    LMDA: 0.5\n",
      "    N_STEP_F: 4\n",
      "  MCD:\n",
      "    N_STEP_F: 4\n",
      "  MEANTEACHER:\n",
      "    EMA_ALPHA: 0.999\n",
      "    RAMPUP: 5\n",
      "    WEIGHT_U: 1.0\n",
      "  MIXMATCH:\n",
      "    MIXUP_BETA: 0.75\n",
      "    RAMPUP: 20000\n",
      "    TEMP: 2.0\n",
      "    WEIGHT_U: 100.0\n",
      "  MME:\n",
      "    LMDA: 0.1\n",
      "  NAME: DAMP\n",
      "  SE:\n",
      "    CONF_THRE: 0.95\n",
      "    EMA_ALPHA: 0.999\n",
      "    RAMPUP: 300\n",
      "USE_CUDA: True\n",
      "VERBOSE: True\n",
      "VERSION: 1\n",
      "Setting fixed seed: 1\n",
      "***************\n",
      "** Arguments **\n",
      "***************\n",
      "backbone: \n",
      "config_file: configs/trainers/DAMP/damp.yaml\n",
      "dataset_config_file: configs/datasets/visda17.yaml\n",
      "eval_only: False\n",
      "head: \n",
      "load_epoch: None\n",
      "model_dir: \n",
      "no_train: False\n",
      "opts: ['TRAINER.DAMP.TAU', '0.5', 'TRAINER.DAMP.U', '2.0']\n",
      "output_dir: output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1\n",
      "resume: \n",
      "root: /home/dataset/\n",
      "seed: 1\n",
      "source_domains: ['synthetic']\n",
      "target_domains: ['real']\n",
      "trainer: DAMP\n",
      "transforms: None\n",
      "************\n",
      "** Config **\n",
      "************\n",
      "DATALOADER:\n",
      "  K_TRANSFORMS: 1\n",
      "  NUM_WORKERS: 4\n",
      "  RETURN_IMG0: False\n",
      "  TEST:\n",
      "    BATCH_SIZE: 128\n",
      "    SAMPLER: SequentialSampler\n",
      "  TRAIN_U:\n",
      "    BATCH_SIZE: 32\n",
      "    N_DOMAIN: 0\n",
      "    N_INS: 16\n",
      "    SAME_AS_X: True\n",
      "    SAMPLER: RandomSampler\n",
      "  TRAIN_X:\n",
      "    BATCH_SIZE: 32\n",
      "    N_DOMAIN: 0\n",
      "    N_INS: 16\n",
      "    SAMPLER: RandomSampler\n",
      "DATASET:\n",
      "  ALL_AS_UNLABELED: False\n",
      "  CIFAR_C_LEVEL: 1\n",
      "  CIFAR_C_TYPE: \n",
      "  NAME: VISDA_C\n",
      "  NUM_LABELED: -1\n",
      "  NUM_SHOTS: -1\n",
      "  ROOT: /home/dataset/\n",
      "  SOURCE_DOMAINS: ['synthetic']\n",
      "  STL10_FOLD: -1\n",
      "  TARGET_DOMAINS: ['real']\n",
      "  VAL_PERCENT: 0.1\n",
      "INPUT:\n",
      "  COLORJITTER_B: 0.4\n",
      "  COLORJITTER_C: 0.4\n",
      "  COLORJITTER_H: 0.1\n",
      "  COLORJITTER_S: 0.4\n",
      "  CROP_PADDING: 4\n",
      "  CUTOUT_LEN: 16\n",
      "  CUTOUT_N: 1\n",
      "  GB_K: 21\n",
      "  GB_P: 0.5\n",
      "  GN_MEAN: 0.0\n",
      "  GN_STD: 0.15\n",
      "  INTERPOLATION: bicubic\n",
      "  NO_TRANSFORM: False\n",
      "  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]\n",
      "  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]\n",
      "  RANDAUGMENT_M: 10\n",
      "  RANDAUGMENT_N: 2\n",
      "  RGS_P: 0.2\n",
      "  RRCROP_SCALE: (0.08, 1.0)\n",
      "  SIZE: (224, 224)\n",
      "  TRANSFORMS: ('normalize',)\n",
      "MODEL:\n",
      "  BACKBONE:\n",
      "    NAME: ViT-B/16\n",
      "    PATH: ./assets\n",
      "    PRETRAINED: True\n",
      "  HEAD:\n",
      "    ACTIVATION: relu\n",
      "    BN: True\n",
      "    DROPOUT: 0.0\n",
      "    HIDDEN_LAYERS: ()\n",
      "    NAME: \n",
      "  INIT_WEIGHTS: \n",
      "  INIT_WEIGHTS_CTX: None\n",
      "  INIT_WEIGHTS_PRO: None\n",
      "OPTIM:\n",
      "  ADAM_BETA1: 0.9\n",
      "  ADAM_BETA2: 0.999\n",
      "  BASE_LR_MULT: 0.1\n",
      "  GAMMA: 0.1\n",
      "  LR: 0.003\n",
      "  LR_SCHEDULER: cosine\n",
      "  MAX_EPOCH: 30\n",
      "  MOMENTUM: 0.9\n",
      "  NAME: adam\n",
      "  NEW_LAYERS: ()\n",
      "  RMSPROP_ALPHA: 0.99\n",
      "  SGD_DAMPNING: 0\n",
      "  SGD_NESTEROV: False\n",
      "  STAGED_LR: False\n",
      "  STEPSIZE: (-1,)\n",
      "  WARMUP_CONS_LR: 1e-05\n",
      "  WARMUP_EPOCH: 1\n",
      "  WARMUP_MIN_LR: 1e-05\n",
      "  WARMUP_RECOUNT: True\n",
      "  WARMUP_TYPE: linear\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "OPTIM_C:\n",
      "  ADAM_BETA1: 0.9\n",
      "  ADAM_BETA2: 0.999\n",
      "  BASE_LR_MULT: 0.1\n",
      "  GAMMA: 0.1\n",
      "  LR: 0.003\n",
      "  LR_SCHEDULER: cosine\n",
      "  MAX_EPOCH: 30\n",
      "  MOMENTUM: 0.9\n",
      "  NAME: adam\n",
      "  NEW_LAYERS: ()\n",
      "  RMSPROP_ALPHA: 0.99\n",
      "  SGD_DAMPNING: 0\n",
      "  SGD_NESTEROV: False\n",
      "  STAGED_LR: False\n",
      "  STEPSIZE: (-1,)\n",
      "  WARMUP_CONS_LR: 1e-05\n",
      "  WARMUP_EPOCH: 1\n",
      "  WARMUP_MIN_LR: 1e-05\n",
      "  WARMUP_RECOUNT: True\n",
      "  WARMUP_TYPE: linear\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "OUTPUT_DIR: output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1\n",
      "RESUME: \n",
      "SEED: 1\n",
      "TEST:\n",
      "  COMPUTE_CMAT: False\n",
      "  EVALUATOR: Classification\n",
      "  FINAL_MODEL: last_step\n",
      "  NO_TEST: False\n",
      "  PER_CLASS_RESULT: True\n",
      "  SPLIT: test\n",
      "TRAIN:\n",
      "  CHECKPOINT_FREQ: 0\n",
      "  COUNT_ITER: train_x\n",
      "  PRINT_FREQ: 100\n",
      "TRAINER:\n",
      "  CDAC:\n",
      "    CLASS_LR_MULTI: 10\n",
      "    P_THRESH: 0.95\n",
      "    RAMPUP_COEF: 30\n",
      "    RAMPUP_ITRS: 1000\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    TOPK_MATCH: 5\n",
      "  CROSSGRAD:\n",
      "    ALPHA_D: 0.5\n",
      "    ALPHA_F: 0.5\n",
      "    EPS_D: 1.0\n",
      "    EPS_F: 1.0\n",
      "  DAEL:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 0.5\n",
      "  DAELDG:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 0.5\n",
      "  DAMP:\n",
      "    CSC: False\n",
      "    IM: 1.0\n",
      "    IND: 1.0\n",
      "    N_CLS: 2\n",
      "    N_CTX: 32\n",
      "    PREC: amp\n",
      "    STRONG_TRANSFORMS: ['randaugment', 'normalize']\n",
      "    TAU: 0.5\n",
      "    U: 2.0\n",
      "  DAPL:\n",
      "    CSC: False\n",
      "    N_CTX: 16\n",
      "    N_DMX: 16\n",
      "    PREC: fp16\n",
      "    T: 1.0\n",
      "    TAU: 0.5\n",
      "    U: 1.0\n",
      "  DDAIG:\n",
      "    ALPHA: 0.5\n",
      "    CLAMP: False\n",
      "    CLAMP_MAX: 1.0\n",
      "    CLAMP_MIN: -1.0\n",
      "    G_ARCH: \n",
      "    LMDA: 0.3\n",
      "    WARMUP: 0\n",
      "  DOMAINMIX:\n",
      "    ALPHA: 1.0\n",
      "    BETA: 1.0\n",
      "    TYPE: crossdomain\n",
      "  ENTMIN:\n",
      "    LMDA: 0.001\n",
      "  FIXMATCH:\n",
      "    CONF_THRE: 0.95\n",
      "    STRONG_TRANSFORMS: ()\n",
      "    WEIGHT_U: 1.0\n",
      "  M3SDA:\n",
      "    LMDA: 0.5\n",
      "    N_STEP_F: 4\n",
      "  MCD:\n",
      "    N_STEP_F: 4\n",
      "  MEANTEACHER:\n",
      "    EMA_ALPHA: 0.999\n",
      "    RAMPUP: 5\n",
      "    WEIGHT_U: 1.0\n",
      "  MIXMATCH:\n",
      "    MIXUP_BETA: 0.75\n",
      "    RAMPUP: 20000\n",
      "    TEMP: 2.0\n",
      "    WEIGHT_U: 100.0\n",
      "  MME:\n",
      "    LMDA: 0.1\n",
      "  NAME: DAMP\n",
      "  SE:\n",
      "    CONF_THRE: 0.95\n",
      "    EMA_ALPHA: 0.999\n",
      "    RAMPUP: 300\n",
      "USE_CUDA: True\n",
      "VERBOSE: True\n",
      "VERSION: 1\n",
      "Collecting env info ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** System info **\n",
      "PyTorch version: 2.4.0+cu121\n",
      "Is debug build: False\n",
      "CUDA used to build PyTorch: 12.1\n",
      "ROCM used to build PyTorch: N/A\n",
      "\n",
      "OS: Ubuntu 22.04.3 LTS (x86_64)\n",
      "GCC version: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Clang version: Could not collect\n",
      "CMake version: version 3.22.1\n",
      "Libc version: glibc-2.35\n",
      "\n",
      "Python version: 3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0] (64-bit runtime)\n",
      "Python platform: Linux-6.2.0-26-generic-x86_64-with-glibc2.35\n",
      "Is CUDA available: True\n",
      "CUDA runtime version: 12.3.103\n",
      "CUDA_MODULE_LOADING set to: LAZY\n",
      "GPU models and configuration: \n",
      "GPU 0: NVIDIA GeForce RTX 4090\n",
      "GPU 1: NVIDIA GeForce RTX 4090\n",
      "GPU 2: NVIDIA GeForce RTX 4090\n",
      "GPU 3: NVIDIA GeForce RTX 4090\n",
      "GPU 4: NVIDIA GeForce RTX 4090\n",
      "GPU 5: NVIDIA GeForce RTX 4090\n",
      "GPU 6: NVIDIA GeForce RTX 4090\n",
      "GPU 7: NVIDIA GeForce RTX 4090\n",
      "\n",
      "Nvidia driver version: 535.129.03\n",
      "cuDNN version: Could not collect\n",
      "HIP runtime version: N/A\n",
      "MIOpen runtime version: N/A\n",
      "Is XNNPACK available: True\n",
      "\n",
      "CPU:\n",
      "Architecture:                    x86_64\n",
      "CPU op-mode(s):                  32-bit, 64-bit\n",
      "Address sizes:                   46 bits physical, 57 bits virtual\n",
      "Byte Order:                      Little Endian\n",
      "CPU(s):                          32\n",
      "On-line CPU(s) list:             0-31\n",
      "Vendor ID:                       GenuineIntel\n",
      "Model name:                      Intel(R) Xeon(R) Gold 6426Y\n",
      "CPU family:                      6\n",
      "Model:                           143\n",
      "Thread(s) per core:              1\n",
      "Core(s) per socket:              16\n",
      "Socket(s):                       2\n",
      "Stepping:                        8\n",
      "CPU max MHz:                     4100.0000\n",
      "CPU min MHz:                     800.0000\n",
      "BogoMIPS:                        5000.00\n",
      "Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 cat_l2 cdp_l3 invpcid_single intel_ppin cdp_l2 ssbd mba ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm rdt_a avx512f avx512dq rdseed adx smap avx512ifma clflushopt clwb intel_pt avx512cd sha_ni avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local split_lock_detect avx_vnni avx512_bf16 wbnoinvd dtherm ida arat pln pts hwp hwp_act_window hwp_epp hwp_pkg_req hfi avx512vbmi umip pku ospke waitpkg avx512_vbmi2 gfni vaes vpclmulqdq avx512_vnni avx512_bitalg tme avx512_vpopcntdq la57 rdpid bus_lock_detect cldemote movdiri movdir64b enqcmd fsrm md_clear serialize tsxldtrk pconfig arch_lbr ibt amx_bf16 avx512_fp16 amx_tile amx_int8 flush_l1d arch_capabilities\n",
      "Virtualization:                  VT-x\n",
      "L1d cache:                       1.5 MiB (32 instances)\n",
      "L1i cache:                       1 MiB (32 instances)\n",
      "L2 cache:                        64 MiB (32 instances)\n",
      "L3 cache:                        75 MiB (2 instances)\n",
      "NUMA node(s):                    2\n",
      "NUMA node0 CPU(s):               0-15\n",
      "NUMA node1 CPU(s):               16-31\n",
      "Vulnerability Itlb multihit:     Not affected\n",
      "Vulnerability L1tf:              Not affected\n",
      "Vulnerability Mds:               Not affected\n",
      "Vulnerability Meltdown:          Not affected\n",
      "Vulnerability Mmio stale data:   Not affected\n",
      "Vulnerability Retbleed:          Not affected\n",
      "Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl\n",
      "Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization\n",
      "Vulnerability Spectre v2:        Mitigation; Enhanced IBRS, IBPB conditional, RSB filling, PBRSB-eIBRS SW sequence\n",
      "Vulnerability Srbds:             Not affected\n",
      "Vulnerability Tsx async abort:   Not affected\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] flake8==3.7.9\n",
      "[pip3] mypy-extensions==1.0.0\n",
      "[pip3] numpy==1.23.0\n",
      "[pip3] numpydoc==1.5.0\n",
      "[pip3] optree==0.12.1\n",
      "[pip3] torch==2.4.0\n",
      "[pip3] torchvision==0.19.0\n",
      "[pip3] triton==3.0.0\n",
      "[conda] _anaconda_depends         2023.09             py311_mkl_1  \n",
      "[conda] blas                      1.0                         mkl  \n",
      "[conda] mkl                       2023.1.0         h213fc3f_46343  \n",
      "[conda] mkl-service               2.4.0           py311h5eee18b_1  \n",
      "[conda] mkl_fft                   1.3.8           py311h5eee18b_0  \n",
      "[conda] mkl_random                1.2.4           py311hdb19cb5_0  \n",
      "[conda] numpy                     1.24.3          py311h08b1b3b_1  \n",
      "[conda] numpy-base                1.24.3          py311hf175353_1  \n",
      "[conda] numpydoc                  1.5.0           py311h06a4308_0  \n",
      "        Pillow (9.4.0)\n",
      "\n",
      "Loading trainer: DAMP\n",
      "Building transform_train\n",
      "+ resize to 224x224\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
      "Building transform_train\n",
      "+ resize to 224x224\n",
      "+ randaugment (n=2, m=10)\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
      "Loading dataset: VISDA_C\n",
      "* Using custom transform for training\n",
      "Building transform_test\n",
      "+ resize the smaller edge to 224\n",
      "+ 224x224 center crop\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
      "---------  -------------\n",
      "Dataset    VISDA_C\n",
      "Source     ['synthetic']\n",
      "Target     ['real']\n",
      "# classes  12\n",
      "# train_x  152,397\n",
      "# train_u  55,388\n",
      "# test     55,388\n",
      "---------  -------------\n",
      "['aeroplane', 'bicycle', 'bus', 'car', 'horse', 'knife', 'motorcycle', 'person', 'plant', 'skateboard', 'train', 'truck']\n",
      "Loading CLIP (backbone: ViT-B/16)\n",
      "./assets/ViT-B-16.pt\n",
      "Building custom CLIP\n",
      "ContextDecoder(\n",
      "  (memory_proj): Sequential(\n",
      "    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (text_proj): Sequential(\n",
      "    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "  )\n",
      "  (decoder): ModuleList(\n",
      "    (0-5): 6 x TransformerDecoderLayer(\n",
      "      (self_attn): Attention(\n",
      "        (q_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (k_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (v_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (cross_attn): Attention(\n",
      "        (q_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (k_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (v_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "        (3): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (out_proj): Sequential(\n",
      "    (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=256, out_features=512, bias=True)\n",
      "  )\n",
      ")\n",
      "Initializing a generic context\n",
      "ctx vectors size: \n",
      "Initial context: \"X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X\"\n",
      "Number of context words (tokens): 32\n",
      "Number of cls words (tokens): 2\n",
      "Prompts: \"X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X aeroplane.\"\n",
      "Naive Prompts: \"a real photo of a aeroplane.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turning off gradients in both the image and the text encoder\n",
      "Loading evaluator: Classification\n",
      "No checkpoint found, train from scratch\n",
      "Initialize tensorboard (log_dir=output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/tensorboard)\n",
      "epoch [1/30][100/500]\ttime 0.271 (0.279)\tdata 0.000 (0.005)\teta 1:09:23\tloss 6.5638 (7.8511) loss_x 0.3696 (0.4781) loss_u 0.0802 (0.2129) acc_x 87.5000 (85.5312) acc_u 93.7500 (84.1875) gamma_v 0.0133 (0.0197) gamma_t 0.0420 (0.0259) loss_x_ind 2.8744 (3.5008) loss_im -1.8582 (-1.8018) loss_new 0.0159 (0.0984)\tlr 6.183221e-04\n",
      "epoch [1/30][200/500]\ttime 0.252 (0.277)\tdata 0.000 (0.003)\teta 1:08:19\tloss 1.9910 (5.6791) loss_x 0.2475 (0.3933) loss_u 0.0805 (0.1556) acc_x 90.6250 (87.4844) acc_u 81.2500 (84.6250) gamma_v 0.0152 (0.0177) gamma_t 0.0833 (0.0463) loss_x_ind 0.9497 (2.6622) loss_im -1.8757 (-1.8999) loss_new 0.0115 (0.0548)\tlr 8.898950e-04\n",
      "epoch [1/30][300/500]\ttime 0.276 (0.274)\tdata 0.000 (0.002)\teta 1:07:12\tloss 0.7104 (4.1704) loss_x 0.3611 (0.3633) loss_u 0.0371 (0.1314) acc_x 87.5000 (88.1979) acc_u 81.2500 (84.6458) gamma_v 0.0210 (0.0179) gamma_t 0.0980 (0.0612) loss_x_ind 0.8417 (2.0575) loss_im -2.0135 (-1.9481) loss_new 0.0057 (0.0394)\tlr 2.991783e-03\n",
      "epoch [1/30][400/500]\ttime 0.278 (0.276)\tdata 0.000 (0.002)\teta 1:07:04\tloss -0.0049 (3.2605) loss_x 0.0473 (0.3428) loss_u 0.2298 (0.1201) acc_x 100.0000 (88.6250) acc_u 90.6250 (84.7812) gamma_v 0.0235 (0.0192) gamma_t 0.1018 (0.0714) loss_x_ind 0.2911 (1.6838) loss_im -1.8997 (-1.9719) loss_new 0.0032 (0.0308)\tlr 6.183221e-04\n",
      "epoch [1/30][500/500]\ttime 0.284 (0.278)\tdata 0.001 (0.001)\teta 1:07:10\tloss -0.7155 (2.6077) loss_x 0.1904 (0.3256) loss_u 0.0188 (0.1122) acc_x 90.6250 (89.1562) acc_u 90.6250 (84.9375) gamma_v 0.0254 (0.0199) gamma_t 0.1107 (0.0789) loss_x_ind 0.2316 (1.4227) loss_im -2.1123 (-1.9906) loss_new 0.0047 (0.0255)\tlr 8.898950e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 47,881\n",
      "* accuracy: 86.4%\n",
      "* error: 13.6%\n",
      "* macro_f1: 87.3%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,608\tacc: 99.0%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,228\tacc: 92.9%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,436\tacc: 94.6%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,704\tacc: 74.1%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,621\tacc: 98.5%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,904\tacc: 91.8%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,468\tacc: 94.3%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,205\tacc: 80.1%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,123\tacc: 90.6%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,177\tacc: 95.4%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,004\tacc: 94.5%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,403\tacc: 61.3%\n",
      "* average: 88.9%\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/prompt_learner/model-best.pth.tar\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/context_decoder/model-best.pth.tar\n",
      "epoch [2/30][100/500]\ttime 0.273 (0.289)\tdata 0.001 (0.004)\teta 1:09:17\tloss -0.7120 (-0.3411) loss_x 0.2496 (0.2446) loss_u 0.0307 (0.0630) acc_x 87.5000 (91.6875) acc_u 90.6250 (85.9062) gamma_v 0.0250 (0.0254) gamma_t 0.1154 (0.1126) loss_x_ind 0.3258 (0.3040) loss_im -2.0544 (-2.0899) loss_new 0.0024 (0.0028)\tlr 2.991783e-03\n",
      "epoch [2/30][200/500]\ttime 0.279 (0.284)\tdata 0.001 (0.002)\teta 1:07:47\tloss -0.4657 (-0.3257) loss_x 0.3522 (0.2363) loss_u 0.0412 (0.0654) acc_x 93.7500 (91.8281) acc_u 93.7500 (86.0781) gamma_v 0.0248 (0.0255) gamma_t 0.1182 (0.1145) loss_x_ind 0.1700 (0.3009) loss_im -1.9476 (-2.0947) loss_new 0.0024 (0.0025)\tlr 6.183221e-04\n",
      "epoch [2/30][300/500]\ttime 0.249 (0.280)\tdata 0.000 (0.002)\teta 1:06:19\tloss -0.2341 (-0.3431) loss_x 0.3328 (0.2319) loss_u 0.0534 (0.0660) acc_x 90.6250 (91.9271) acc_u 78.1250 (85.7917) gamma_v 0.0276 (0.0253) gamma_t 0.1131 (0.1154) loss_x_ind 0.2331 (0.2834) loss_im -2.1954 (-2.0904) loss_new 0.0024 (0.0028)\tlr 8.898950e-04\n",
      "epoch [2/30][400/500]\ttime 0.279 (0.277)\tdata 0.000 (0.001)\teta 1:05:05\tloss -1.4687 (-0.3788) loss_x 0.0977 (0.2312) loss_u 0.0290 (0.0660) acc_x 96.8750 (91.9219) acc_u 84.3750 (85.6328) gamma_v 0.0269 (0.0258) gamma_t 0.1183 (0.1164) loss_x_ind 0.1771 (0.2626) loss_im -2.1921 (-2.0965) loss_new 0.0026 (0.0026)\tlr 2.991783e-03\n",
      "epoch [2/30][500/500]\ttime 0.277 (0.278)\tdata 0.000 (0.001)\teta 1:04:48\tloss -0.6525 (-0.4141) loss_x 0.2631 (0.2274) loss_u 0.0836 (0.0644) acc_x 87.5000 (92.0812) acc_u 78.1250 (85.5687) gamma_v 0.0296 (0.0261) gamma_t 0.1204 (0.1172) loss_x_ind 0.1847 (0.2524) loss_im -2.0454 (-2.0934) loss_new 0.0024 (0.0027)\tlr 6.183221e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,297\n",
      "* accuracy: 87.2%\n",
      "* error: 12.8%\n",
      "* macro_f1: 87.9%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,606\tacc: 98.9%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,239\tacc: 93.2%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,375\tacc: 93.3%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 8,095\tacc: 77.8%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,615\tacc: 98.4%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,918\tacc: 92.4%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,446\tacc: 94.0%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,293\tacc: 82.3%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,101\tacc: 90.2%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,198\tacc: 96.4%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,977\tacc: 93.9%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,434\tacc: 61.9%\n",
      "* average: 89.4%\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/prompt_learner/model-best.pth.tar\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/context_decoder/model-best.pth.tar\n",
      "epoch [3/30][100/500]\ttime 0.251 (0.269)\tdata 0.000 (0.003)\teta 1:02:13\tloss -0.6609 (-0.5335) loss_x 0.1744 (0.2199) loss_u 0.0440 (0.0610) acc_x 93.7500 (92.2500) acc_u 87.5000 (84.4688) gamma_v 0.0296 (0.0291) gamma_t 0.1249 (0.1265) loss_x_ind 0.1213 (0.1894) loss_im -2.0660 (-2.1043) loss_new 0.0022 (0.0014)\tlr 8.898950e-04\n",
      "epoch [3/30][200/500]\ttime 0.252 (0.261)\tdata 0.000 (0.002)\teta 1:00:03\tloss -0.1156 (-0.5787) loss_x 0.0632 (0.2080) loss_u 0.1454 (0.0632) acc_x 100.0000 (92.6562) acc_u 84.3750 (85.3750) gamma_v 0.0279 (0.0287) gamma_t 0.1296 (0.1272) loss_x_ind 0.2807 (0.1821) loss_im -2.1626 (-2.1078) loss_new 0.0019 (0.0018)\tlr 2.991783e-03\n",
      "epoch [3/30][300/500]\ttime 0.250 (0.258)\tdata 0.001 (0.001)\teta 0:58:47\tloss -0.7760 (-0.5767) loss_x 0.2305 (0.2111) loss_u 0.0126 (0.0626) acc_x 93.7500 (92.5521) acc_u 90.6250 (85.4583) gamma_v 0.0321 (0.0291) gamma_t 0.1264 (0.1270) loss_x_ind 0.1780 (0.1794) loss_im -2.2100 (-2.1062) loss_new 0.0013 (0.0019)\tlr 6.183221e-04\n",
      "epoch [3/30][400/500]\ttime 0.274 (0.257)\tdata 0.000 (0.001)\teta 0:58:12\tloss -1.1136 (-0.6083) loss_x 0.0667 (0.2067) loss_u 0.0479 (0.0608) acc_x 96.8750 (92.7422) acc_u 78.1250 (85.5469) gamma_v 0.0324 (0.0295) gamma_t 0.1313 (0.1279) loss_x_ind 0.2343 (0.1739) loss_im -2.1126 (-2.1045) loss_new 0.0012 (0.0019)\tlr 8.898950e-04\n",
      "epoch [3/30][500/500]\ttime 0.275 (0.266)\tdata 0.001 (0.001)\teta 0:59:45\tloss -1.2984 (-0.6338) loss_x 0.2332 (0.2033) loss_u 0.0144 (0.0593) acc_x 93.7500 (92.8250) acc_u 90.6250 (85.6375) gamma_v 0.0331 (0.0303) gamma_t 0.1350 (0.1292) loss_x_ind 0.1600 (0.1683) loss_im -2.2288 (-2.1055) loss_new 0.0018 (0.0018)\tlr 2.991783e-03\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,483\n",
      "* accuracy: 87.5%\n",
      "* error: 12.5%\n",
      "* macro_f1: 88.2%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,604\tacc: 98.8%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,206\tacc: 92.3%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,274\tacc: 91.1%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,876\tacc: 75.7%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,616\tacc: 98.4%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,960\tacc: 94.5%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,528\tacc: 95.4%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,094\tacc: 77.3%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,197\tacc: 92.3%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,187\tacc: 95.9%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,021\tacc: 94.9%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,920\tacc: 70.7%\n",
      "* average: 89.8%\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/prompt_learner/model-best.pth.tar\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/context_decoder/model-best.pth.tar\n",
      "epoch [4/30][100/500]\ttime 0.279 (0.281)\tdata 0.000 (0.003)\teta 1:02:41\tloss -0.6342 (-0.7888) loss_x 0.1217 (0.1781) loss_u 0.0214 (0.0514) acc_x 96.8750 (93.5938) acc_u 87.5000 (85.9375) gamma_v 0.0321 (0.0326) gamma_t 0.1374 (0.1352) loss_x_ind 0.1204 (0.1385) loss_im -2.2152 (-2.1135) loss_new 0.0016 (0.0017)\tlr 6.183221e-04\n",
      "epoch [4/30][200/500]\ttime 0.250 (0.274)\tdata 0.000 (0.002)\teta 1:00:46\tloss -1.3915 (-0.7383) loss_x 0.0841 (0.1797) loss_u 0.0463 (0.0569) acc_x 96.8750 (93.7656) acc_u 81.2500 (85.4219) gamma_v 0.0309 (0.0326) gamma_t 0.1429 (0.1364) loss_x_ind 0.1466 (0.1412) loss_im -2.2158 (-2.1099) loss_new 0.0022 (0.0019)\tlr 8.898950e-04\n",
      "epoch [4/30][300/500]\ttime 0.248 (0.267)\tdata 0.000 (0.001)\teta 0:58:49\tloss -1.6105 (-0.7525) loss_x 0.0298 (0.1827) loss_u 0.0347 (0.0561) acc_x 100.0000 (93.6250) acc_u 90.6250 (85.5833) gamma_v 0.0329 (0.0327) gamma_t 0.1442 (0.1384) loss_x_ind 0.0883 (0.1366) loss_im -2.2038 (-2.1063) loss_new 0.0011 (0.0018)\tlr 2.991783e-03\n",
      "epoch [4/30][400/500]\ttime 0.251 (0.263)\tdata 0.001 (0.001)\teta 0:57:24\tloss -0.3570 (-0.7620) loss_x 0.2189 (0.1798) loss_u 0.0153 (0.0541) acc_x 90.6250 (93.6172) acc_u 81.2500 (85.7812) gamma_v 0.0315 (0.0323) gamma_t 0.1433 (0.1392) loss_x_ind 0.0674 (0.1347) loss_im -2.1248 (-2.1080) loss_new 0.0022 (0.0019)\tlr 6.183221e-04\n",
      "epoch [4/30][500/500]\ttime 0.277 (0.264)\tdata 0.001 (0.001)\teta 0:57:05\tloss -0.6496 (-0.7456) loss_x 0.2676 (0.1826) loss_u 0.0568 (0.0542) acc_x 90.6250 (93.5687) acc_u 87.5000 (85.7625) gamma_v 0.0336 (0.0326) gamma_t 0.1460 (0.1406) loss_x_ind 0.1210 (0.1344) loss_im -1.9971 (-2.1061) loss_new 0.0011 (0.0018)\tlr 8.898950e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,038\n",
      "* accuracy: 86.7%\n",
      "* error: 13.3%\n",
      "* macro_f1: 87.5%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,608\tacc: 99.0%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,155\tacc: 90.8%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,432\tacc: 94.5%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 8,245\tacc: 79.3%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,629\tacc: 98.7%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,959\tacc: 94.4%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,440\tacc: 93.9%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,407\tacc: 85.2%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,192\tacc: 92.2%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,116\tacc: 92.8%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,035\tacc: 95.3%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 2,820\tacc: 50.8%\n",
      "* average: 88.9%\n",
      "epoch [5/30][100/500]\ttime 0.269 (0.273)\tdata 0.000 (0.003)\teta 0:58:41\tloss -1.3318 (-0.8290) loss_x 0.1092 (0.1698) loss_u 0.0209 (0.0500) acc_x 96.8750 (93.9375) acc_u 87.5000 (86.0312) gamma_v 0.0368 (0.0354) gamma_t 0.1509 (0.1477) loss_x_ind 0.2226 (0.1162) loss_im -2.1194 (-2.1306) loss_new 0.0006 (0.0012)\tlr 2.991783e-03\n",
      "epoch [5/30][200/500]\ttime 0.272 (0.273)\tdata 0.001 (0.002)\teta 0:58:17\tloss -1.0956 (-0.8020) loss_x 0.2093 (0.1775) loss_u 0.0082 (0.0480) acc_x 90.6250 (93.8438) acc_u 90.6250 (85.8125) gamma_v 0.0340 (0.0353) gamma_t 0.1507 (0.1491) loss_x_ind 0.0571 (0.1145) loss_im -2.2482 (-2.1214) loss_new 0.0024 (0.0015)\tlr 6.183221e-04\n",
      "epoch [5/30][300/500]\ttime 0.269 (0.274)\tdata 0.001 (0.001)\teta 0:57:58\tloss -0.4253 (-0.8106) loss_x 0.2325 (0.1803) loss_u 0.0563 (0.0483) acc_x 87.5000 (93.6146) acc_u 81.2500 (85.9167) gamma_v 0.0347 (0.0350) gamma_t 0.1533 (0.1498) loss_x_ind 0.1216 (0.1152) loss_im -2.1618 (-2.1280) loss_new 0.0020 (0.0016)\tlr 8.898950e-04\n",
      "epoch [5/30][400/500]\ttime 0.295 (0.276)\tdata 0.001 (0.001)\teta 0:57:59\tloss -0.5139 (-0.8499) loss_x 0.0893 (0.1748) loss_u 0.0183 (0.0476) acc_x 96.8750 (93.6875) acc_u 84.3750 (86.1641) gamma_v 0.0386 (0.0353) gamma_t 0.1544 (0.1506) loss_x_ind 0.0639 (0.1122) loss_im -1.9234 (-2.1295) loss_new 0.0008 (0.0016)\tlr 2.991783e-03\n",
      "epoch [5/30][500/500]\ttime 0.276 (0.279)\tdata 0.000 (0.001)\teta 0:58:03\tloss -0.6902 (-0.8514) loss_x 0.1805 (0.1743) loss_u 0.0246 (0.0477) acc_x 90.6250 (93.6750) acc_u 84.3750 (86.0875) gamma_v 0.0385 (0.0357) gamma_t 0.1544 (0.1507) loss_x_ind 0.0341 (0.1093) loss_im -2.0823 (-2.1304) loss_new 0.0008 (0.0015)\tlr 6.183221e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,250\n",
      "* accuracy: 87.1%\n",
      "* error: 12.9%\n",
      "* macro_f1: 87.9%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,602\tacc: 98.8%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,230\tacc: 92.9%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,377\tacc: 93.3%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,901\tacc: 76.0%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,621\tacc: 98.5%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,898\tacc: 91.5%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,470\tacc: 94.4%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,373\tacc: 84.3%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,135\tacc: 90.9%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,179\tacc: 95.5%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,979\tacc: 93.9%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,485\tacc: 62.8%\n",
      "* average: 89.4%\n",
      "epoch [6/30][100/500]\ttime 0.277 (0.300)\tdata 0.001 (0.003)\teta 1:01:55\tloss -0.7286 (-0.9054) loss_x 0.2550 (0.1740) loss_u 0.0355 (0.0438) acc_x 90.6250 (93.5625) acc_u 90.6250 (86.0938) gamma_v 0.0392 (0.0375) gamma_t 0.1595 (0.1577) loss_x_ind 0.1088 (0.1006) loss_im -2.0826 (-2.1141) loss_new 0.0018 (0.0014)\tlr 8.898950e-04\n",
      "epoch [6/30][200/500]\ttime 0.281 (0.291)\tdata 0.001 (0.002)\teta 0:59:41\tloss -0.7856 (-0.8929) loss_x 0.0637 (0.1715) loss_u 0.0796 (0.0466) acc_x 96.8750 (93.6562) acc_u 78.1250 (85.8906) gamma_v 0.0443 (0.0380) gamma_t 0.1566 (0.1576) loss_x_ind 0.1740 (0.0980) loss_im -2.1605 (-2.1170) loss_new 0.0004 (0.0014)\tlr 2.991783e-03\n",
      "epoch [6/30][300/500]\ttime 0.280 (0.289)\tdata 0.001 (0.001)\teta 0:58:50\tloss -1.7804 (-0.8830) loss_x 0.0880 (0.1721) loss_u 0.0139 (0.0444) acc_x 100.0000 (93.7292) acc_u 90.6250 (86.1562) gamma_v 0.0409 (0.0388) gamma_t 0.1644 (0.1594) loss_x_ind 0.0845 (0.1001) loss_im -2.2273 (-2.1192) loss_new 0.0009 (0.0014)\tlr 6.183221e-04\n",
      "epoch [6/30][400/500]\ttime 0.270 (0.287)\tdata 0.001 (0.001)\teta 0:57:52\tloss -0.7616 (-0.8911) loss_x 0.1131 (0.1747) loss_u 0.0146 (0.0442) acc_x 96.8750 (93.7422) acc_u 90.6250 (86.1016) gamma_v 0.0398 (0.0396) gamma_t 0.1676 (0.1607) loss_x_ind 0.1050 (0.0997) loss_im -2.2924 (-2.1260) loss_new 0.0017 (0.0014)\tlr 8.898950e-04\n",
      "epoch [6/30][500/500]\ttime 0.297 (0.286)\tdata 0.001 (0.001)\teta 0:57:14\tloss -1.3013 (-0.8972) loss_x 0.2484 (0.1720) loss_u 0.0212 (0.0443) acc_x 96.8750 (93.8438) acc_u 90.6250 (85.9875) gamma_v 0.0422 (0.0397) gamma_t 0.1720 (0.1623) loss_x_ind 0.1182 (0.0976) loss_im -2.1976 (-2.1248) loss_new 0.0003 (0.0014)\tlr 2.991783e-03\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,766\n",
      "* accuracy: 88.0%\n",
      "* error: 12.0%\n",
      "* macro_f1: 88.8%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,608\tacc: 99.0%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,223\tacc: 92.7%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,301\tacc: 91.7%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 8,392\tacc: 80.7%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,617\tacc: 98.4%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,979\tacc: 95.4%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,442\tacc: 93.9%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,287\tacc: 82.2%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,141\tacc: 91.0%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,162\tacc: 94.8%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,021\tacc: 94.9%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,593\tacc: 64.8%\n",
      "* average: 90.0%\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/prompt_learner/model-best.pth.tar\n",
      "Checkpoint saved to output/visda17/DAMP/damp/_0.5_2.0_sr/seed_1/context_decoder/model-best.pth.tar\n",
      "epoch [7/30][100/500]\ttime 0.297 (0.289)\tdata 0.000 (0.003)\teta 0:57:18\tloss -1.0406 (-0.9216) loss_x 0.1670 (0.1722) loss_u 0.0282 (0.0447) acc_x 93.7500 (93.6875) acc_u 96.8750 (87.1562) gamma_v 0.0452 (0.0447) gamma_t 0.1689 (0.1691) loss_x_ind 0.1325 (0.0981) loss_im -2.0903 (-2.1175) loss_new 0.0007 (0.0007)\tlr 6.183221e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [7/30][200/500]\ttime 0.269 (0.285)\tdata 0.001 (0.002)\teta 0:56:08\tloss -1.4523 (-0.8920) loss_x 0.0758 (0.1801) loss_u 0.0196 (0.0429) acc_x 96.8750 (93.3438) acc_u 96.8750 (86.4531) gamma_v 0.0431 (0.0439) gamma_t 0.1720 (0.1703) loss_x_ind 0.0911 (0.0981) loss_im -2.2113 (-2.1224) loss_new 0.0012 (0.0008)\tlr 8.898950e-04\n",
      "epoch [7/30][300/500]\ttime 0.268 (0.281)\tdata 0.001 (0.001)\teta 0:54:48\tloss -1.2301 (-0.8658) loss_x 0.1744 (0.1758) loss_u 0.0058 (0.0447) acc_x 93.7500 (93.6146) acc_u 96.8750 (86.1875) gamma_v 0.0442 (0.0435) gamma_t 0.1776 (0.1717) loss_x_ind 0.2433 (0.0955) loss_im -2.0413 (-2.1222) loss_new 0.0006 (0.0008)\tlr 2.991783e-03\n",
      "epoch [7/30][400/500]\ttime 0.391 (0.285)\tdata 0.001 (0.001)\teta 0:55:06\tloss -1.2311 (-0.8756) loss_x 0.1299 (0.1734) loss_u 0.0029 (0.0437) acc_x 93.7500 (93.7500) acc_u 84.3750 (86.3281) gamma_v 0.0422 (0.0431) gamma_t 0.1771 (0.1730) loss_x_ind 0.0601 (0.0952) loss_im -2.0548 (-2.1310) loss_new 0.0016 (0.0009)\tlr 6.183221e-04\n",
      "epoch [7/30][500/500]\ttime 0.296 (0.288)\tdata 0.001 (0.001)\teta 0:55:10\tloss -0.1910 (-0.8902) loss_x 0.2118 (0.1733) loss_u 0.0735 (0.0431) acc_x 90.6250 (93.7562) acc_u 84.3750 (86.0938) gamma_v 0.0426 (0.0429) gamma_t 0.1760 (0.1731) loss_x_ind 0.0805 (0.0934) loss_im -2.1145 (-2.1318) loss_new 0.0006 (0.0010)\tlr 8.898950e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,545\n",
      "* accuracy: 87.6%\n",
      "* error: 12.4%\n",
      "* macro_f1: 88.4%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,611\tacc: 99.0%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,248\tacc: 93.5%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,325\tacc: 92.2%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 8,287\tacc: 79.7%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,612\tacc: 98.3%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,947\tacc: 93.8%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,435\tacc: 93.8%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,298\tacc: 82.5%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,145\tacc: 91.1%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,179\tacc: 95.5%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,993\tacc: 94.3%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,465\tacc: 62.5%\n",
      "* average: 89.7%\n",
      "epoch [8/30][100/500]\ttime 0.297 (0.292)\tdata 0.000 (0.003)\teta 0:55:23\tloss -0.5365 (-0.9342) loss_x 0.0992 (0.1741) loss_u 0.0440 (0.0392) acc_x 96.8750 (93.9375) acc_u 78.1250 (84.9375) gamma_v 0.0452 (0.0446) gamma_t 0.1833 (0.1776) loss_x_ind 0.1507 (0.0815) loss_im -1.8633 (-2.1167) loss_new 0.0006 (0.0011)\tlr 2.991783e-03\n",
      "epoch [8/30][200/500]\ttime 0.277 (0.292)\tdata 0.000 (0.002)\teta 0:54:56\tloss -0.9647 (-0.9468) loss_x 0.0732 (0.1618) loss_u 0.0269 (0.0390) acc_x 96.8750 (94.2812) acc_u 84.3750 (85.3594) gamma_v 0.0432 (0.0442) gamma_t 0.1797 (0.1789) loss_x_ind 0.0991 (0.0827) loss_im -2.1415 (-2.1185) loss_new 0.0022 (0.0011)\tlr 6.183221e-04\n",
      "epoch [8/30][300/500]\ttime 0.278 (0.289)\tdata 0.000 (0.001)\teta 0:53:54\tloss -1.3713 (-0.9585) loss_x 0.0935 (0.1618) loss_u 0.0410 (0.0381) acc_x 96.8750 (94.2083) acc_u 90.6250 (85.4271) gamma_v 0.0446 (0.0445) gamma_t 0.1920 (0.1816) loss_x_ind 0.1035 (0.0816) loss_im -2.2472 (-2.1210) loss_new 0.0008 (0.0012)\tlr 8.898950e-04\n",
      "epoch [8/30][400/500]\ttime 0.281 (0.287)\tdata 0.000 (0.001)\teta 0:53:05\tloss -1.0065 (-0.9574) loss_x 0.0994 (0.1661) loss_u 0.0129 (0.0368) acc_x 96.8750 (94.0781) acc_u 81.2500 (85.8203) gamma_v 0.0449 (0.0444) gamma_t 0.1876 (0.1834) loss_x_ind 0.0757 (0.0818) loss_im -1.9563 (-2.1303) loss_new 0.0012 (0.0011)\tlr 2.991783e-03\n",
      "epoch [8/30][500/500]\ttime 0.278 (0.286)\tdata 0.001 (0.001)\teta 0:52:22\tloss -0.9829 (-0.9708) loss_x 0.2298 (0.1645) loss_u 0.0779 (0.0374) acc_x 87.5000 (94.1750) acc_u 87.5000 (85.9688) gamma_v 0.0484 (0.0452) gamma_t 0.1878 (0.1843) loss_x_ind 0.0568 (0.0831) loss_im -2.1247 (-2.1340) loss_new 0.0013 (0.0010)\tlr 6.183221e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,403\n",
      "* accuracy: 87.4%\n",
      "* error: 12.6%\n",
      "* macro_f1: 88.4%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,613\tacc: 99.1%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,190\tacc: 91.8%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,295\tacc: 91.6%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,754\tacc: 74.6%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,617\tacc: 98.4%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,961\tacc: 94.5%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,563\tacc: 96.0%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,370\tacc: 84.2%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,126\tacc: 90.7%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,165\tacc: 94.9%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,001\tacc: 94.5%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,748\tacc: 67.6%\n",
      "* average: 89.8%\n",
      "epoch [9/30][100/500]\ttime 0.266 (0.294)\tdata 0.000 (0.003)\teta 0:53:26\tloss -1.0367 (-0.9512) loss_x 0.1563 (0.1607) loss_u 0.0412 (0.0373) acc_x 93.7500 (94.4688) acc_u 84.3750 (85.0938) gamma_v 0.0434 (0.0443) gamma_t 0.1939 (0.1911) loss_x_ind 0.1125 (0.0782) loss_im -2.1681 (-2.1292) loss_new 0.0007 (0.0008)\tlr 8.898950e-04\n",
      "epoch [9/30][200/500]\ttime 0.269 (0.282)\tdata 0.001 (0.002)\teta 0:50:46\tloss -1.1788 (-0.9819) loss_x 0.1946 (0.1512) loss_u 0.0085 (0.0383) acc_x 90.6250 (94.5156) acc_u 84.3750 (85.5781) gamma_v 0.0480 (0.0453) gamma_t 0.1914 (0.1904) loss_x_ind 0.1014 (0.0752) loss_im -2.1618 (-2.1352) loss_new 0.0006 (0.0007)\tlr 2.991783e-03\n",
      "epoch [9/30][300/500]\ttime 0.251 (0.277)\tdata 0.000 (0.001)\teta 0:49:19\tloss -0.5411 (-0.9828) loss_x 0.2982 (0.1571) loss_u 0.0787 (0.0373) acc_x 93.7500 (94.4688) acc_u 96.8750 (86.1042) gamma_v 0.0445 (0.0455) gamma_t 0.1973 (0.1917) loss_x_ind 0.0279 (0.0780) loss_im -2.2317 (-2.1398) loss_new 0.0016 (0.0008)\tlr 6.183221e-04\n",
      "epoch [9/30][400/500]\ttime 0.249 (0.270)\tdata 0.000 (0.001)\teta 0:47:42\tloss -1.2515 (-0.9664) loss_x 0.0923 (0.1596) loss_u 0.0816 (0.0382) acc_x 96.8750 (94.3438) acc_u 90.6250 (85.9688) gamma_v 0.0452 (0.0457) gamma_t 0.1992 (0.1926) loss_x_ind 0.0682 (0.0789) loss_im -2.1611 (-2.1362) loss_new 0.0009 (0.0009)\tlr 8.898950e-04\n",
      "epoch [9/30][500/500]\ttime 0.279 (0.273)\tdata 0.000 (0.001)\teta 0:47:42\tloss -0.6916 (-0.9742) loss_x 0.3789 (0.1607) loss_u 0.0759 (0.0381) acc_x 90.6250 (94.3000) acc_u 87.5000 (86.1250) gamma_v 0.0442 (0.0460) gamma_t 0.2048 (0.1942) loss_x_ind 0.1109 (0.0779) loss_im -2.2045 (-2.1401) loss_new 0.0012 (0.0009)\tlr 2.991783e-03\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,114\n",
      "* accuracy: 86.9%\n",
      "* error: 13.1%\n",
      "* macro_f1: 87.6%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,605\tacc: 98.9%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,233\tacc: 93.0%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,381\tacc: 93.4%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,975\tacc: 76.7%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,627\tacc: 98.6%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,920\tacc: 92.5%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,453\tacc: 94.1%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,362\tacc: 84.0%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,076\tacc: 89.6%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,203\tacc: 96.6%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,995\tacc: 94.3%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,284\tacc: 59.2%\n",
      "* average: 89.2%\n",
      "epoch [10/30][100/500]\ttime 0.251 (0.266)\tdata 0.000 (0.003)\teta 0:46:02\tloss -0.9935 (-0.9773) loss_x 0.1178 (0.1638) loss_u 0.0436 (0.0355) acc_x 93.7500 (93.9062) acc_u 78.1250 (86.5312) gamma_v 0.0500 (0.0484) gamma_t 0.2027 (0.2035) loss_x_ind 0.0829 (0.0780) loss_im -1.9771 (-2.1271) loss_new 0.0007 (0.0008)\tlr 6.183221e-04\n",
      "epoch [10/30][200/500]\ttime 0.305 (0.268)\tdata 0.001 (0.002)\teta 0:46:04\tloss -1.2553 (-0.9849) loss_x 0.1976 (0.1524) loss_u 0.0359 (0.0373) acc_x 93.7500 (94.2500) acc_u 84.3750 (86.5156) gamma_v 0.0469 (0.0492) gamma_t 0.1971 (0.2027) loss_x_ind 0.0702 (0.0800) loss_im -2.1619 (-2.1323) loss_new 0.0018 (0.0008)\tlr 8.898950e-04\n",
      "epoch [10/30][300/500]\ttime 0.255 (0.275)\tdata 0.000 (0.001)\teta 0:46:47\tloss -0.4234 (-0.9899) loss_x 0.1676 (0.1553) loss_u 0.0225 (0.0362) acc_x 90.6250 (94.2708) acc_u 90.6250 (86.6562) gamma_v 0.0492 (0.0492) gamma_t 0.2009 (0.2016) loss_x_ind 0.1529 (0.0782) loss_im -2.0432 (-2.1373) loss_new 0.0011 (0.0008)\tlr 2.991783e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [10/30][400/500]\ttime 0.276 (0.271)\tdata 0.000 (0.001)\teta 0:45:32\tloss -1.7403 (-0.9802) loss_x 0.0335 (0.1588) loss_u 0.0149 (0.0374) acc_x 100.0000 (94.2031) acc_u 78.1250 (86.4141) gamma_v 0.0467 (0.0492) gamma_t 0.2035 (0.2016) loss_x_ind 0.0700 (0.0779) loss_im -2.2998 (-2.1378) loss_new 0.0013 (0.0008)\tlr 6.183221e-04\n",
      "epoch [10/30][500/500]\ttime 0.293 (0.267)\tdata 0.000 (0.001)\teta 0:44:29\tloss 0.1110 (-0.9898) loss_x 0.1590 (0.1600) loss_u 0.0157 (0.0369) acc_x 96.8750 (94.1625) acc_u 78.1250 (86.3812) gamma_v 0.0494 (0.0496) gamma_t 0.2077 (0.2021) loss_x_ind 0.1480 (0.0763) loss_im -2.3068 (-2.1406) loss_new 0.0009 (0.0008)\tlr 8.898950e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,296\n",
      "* accuracy: 87.2%\n",
      "* error: 12.8%\n",
      "* macro_f1: 87.8%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,611\tacc: 99.0%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,241\tacc: 93.3%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,265\tacc: 90.9%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 8,107\tacc: 77.9%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,627\tacc: 98.6%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,999\tacc: 96.3%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,455\tacc: 94.1%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,253\tacc: 81.3%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,169\tacc: 91.6%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,172\tacc: 95.2%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,029\tacc: 95.1%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,368\tacc: 60.7%\n",
      "* average: 89.5%\n",
      "epoch [11/30][100/500]\ttime 0.281 (0.293)\tdata 0.001 (0.003)\teta 0:48:23\tloss -0.9778 (-0.9295) loss_x 0.1498 (0.1609) loss_u 0.0366 (0.0358) acc_x 93.7500 (94.4375) acc_u 90.6250 (85.4375) gamma_v 0.0490 (0.0487) gamma_t 0.2073 (0.2081) loss_x_ind 0.0744 (0.0643) loss_im -2.2062 (-2.1250) loss_new 0.0007 (0.0007)\tlr 2.991783e-03\n",
      "epoch [11/30][200/500]\ttime 0.471 (0.289)\tdata 0.002 (0.002)\teta 0:47:10\tloss -0.2538 (-0.9844) loss_x 0.2612 (0.1558) loss_u 0.0497 (0.0368) acc_x 90.6250 (94.5781) acc_u 81.2500 (85.4844) gamma_v 0.0490 (0.0487) gamma_t 0.2118 (0.2069) loss_x_ind 0.0739 (0.0677) loss_im -2.1639 (-2.1379) loss_new 0.0009 (0.0009)\tlr 6.183221e-04\n",
      "epoch [11/30][300/500]\ttime 0.268 (0.279)\tdata 0.001 (0.001)\teta 0:45:03\tloss -0.7511 (-0.9957) loss_x 0.0332 (0.1537) loss_u 0.0595 (0.0362) acc_x 100.0000 (94.6146) acc_u 84.3750 (85.8333) gamma_v 0.0513 (0.0501) gamma_t 0.2081 (0.2081) loss_x_ind 0.0671 (0.0682) loss_im -1.8878 (-2.1466) loss_new 0.0011 (0.0008)\tlr 8.898950e-04\n",
      "epoch [11/30][400/500]\ttime 0.252 (0.275)\tdata 0.001 (0.001)\teta 0:43:58\tloss -1.2430 (-1.0028) loss_x 0.1803 (0.1551) loss_u 0.0393 (0.0370) acc_x 96.8750 (94.4531) acc_u 78.1250 (86.0234) gamma_v 0.0504 (0.0509) gamma_t 0.2115 (0.2086) loss_x_ind 0.0394 (0.0678) loss_im -2.0207 (-2.1491) loss_new 0.0012 (0.0008)\tlr 2.991783e-03\n",
      "epoch [11/30][500/500]\ttime 0.269 (0.274)\tdata 0.000 (0.001)\teta 0:43:23\tloss -0.9231 (-1.0028) loss_x 0.0568 (0.1559) loss_u 0.0859 (0.0367) acc_x 100.0000 (94.4062) acc_u 81.2500 (86.1437) gamma_v 0.0520 (0.0508) gamma_t 0.2079 (0.2093) loss_x_ind 0.0657 (0.0689) loss_im -2.1126 (-2.1468) loss_new 0.0011 (0.0009)\tlr 6.183221e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 47,931\n",
      "* accuracy: 86.5%\n",
      "* error: 13.5%\n",
      "* macro_f1: 87.6%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,601\tacc: 98.8%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,222\tacc: 92.7%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,388\tacc: 93.6%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,613\tacc: 73.2%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,623\tacc: 98.6%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,983\tacc: 95.6%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,460\tacc: 94.2%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,404\tacc: 85.1%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,108\tacc: 90.3%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,163\tacc: 94.8%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,936\tacc: 92.9%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,430\tacc: 61.8%\n",
      "* average: 89.3%\n",
      "epoch [12/30][100/500]\ttime 0.268 (0.273)\tdata 0.003 (0.003)\teta 0:42:48\tloss -1.2782 (-1.0107) loss_x 0.1468 (0.1505) loss_u 0.0095 (0.0350) acc_x 96.8750 (94.3125) acc_u 93.7500 (86.3125) gamma_v 0.0564 (0.0501) gamma_t 0.2175 (0.2142) loss_x_ind 0.0660 (0.0755) loss_im -2.1036 (-2.1453) loss_new 0.0002 (0.0008)\tlr 8.898950e-04\n",
      "epoch [12/30][200/500]\ttime 0.252 (0.274)\tdata 0.000 (0.002)\teta 0:42:25\tloss -0.1500 (-1.0208) loss_x 0.1489 (0.1501) loss_u 0.0317 (0.0351) acc_x 96.8750 (94.5000) acc_u 68.7500 (86.0312) gamma_v 0.0542 (0.0520) gamma_t 0.2152 (0.2150) loss_x_ind 0.0814 (0.0657) loss_im -2.1669 (-2.1448) loss_new 0.0006 (0.0008)\tlr 2.991783e-03\n",
      "epoch [12/30][300/500]\ttime 0.277 (0.269)\tdata 0.000 (0.001)\teta 0:41:15\tloss -1.4728 (-1.0271) loss_x 0.0229 (0.1503) loss_u 0.0093 (0.0350) acc_x 100.0000 (94.5104) acc_u 84.3750 (86.0000) gamma_v 0.0566 (0.0522) gamma_t 0.2187 (0.2163) loss_x_ind 0.0637 (0.0638) loss_im -2.1649 (-2.1406) loss_new 0.0003 (0.0009)\tlr 6.183221e-04\n",
      "epoch [12/30][400/500]\ttime 0.268 (0.271)\tdata 0.000 (0.001)\teta 0:41:07\tloss -1.1902 (-1.0162) loss_x 0.1511 (0.1539) loss_u 0.0156 (0.0350) acc_x 93.7500 (94.3672) acc_u 93.7500 (85.9766) gamma_v 0.0571 (0.0527) gamma_t 0.2234 (0.2170) loss_x_ind 0.0968 (0.0637) loss_im -2.1657 (-2.1425) loss_new 0.0002 (0.0009)\tlr 8.898950e-04\n",
      "epoch [12/30][500/500]\ttime 0.250 (0.270)\tdata 0.001 (0.001)\teta 0:40:28\tloss -1.1898 (-1.0189) loss_x 0.0531 (0.1525) loss_u 0.0099 (0.0348) acc_x 96.8750 (94.4375) acc_u 90.6250 (86.1437) gamma_v 0.0527 (0.0528) gamma_t 0.2270 (0.2189) loss_x_ind 0.0274 (0.0626) loss_im -2.0353 (-2.1431) loss_new 0.0009 (0.0008)\tlr 2.991783e-03\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,646\n",
      "* accuracy: 87.8%\n",
      "* error: 12.2%\n",
      "* macro_f1: 88.4%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,606\tacc: 98.9%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,262\tacc: 93.9%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,297\tacc: 91.6%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 8,621\tacc: 82.9%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,622\tacc: 98.5%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,991\tacc: 96.0%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,369\tacc: 92.6%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,239\tacc: 81.0%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,181\tacc: 91.9%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,151\tacc: 94.3%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,985\tacc: 94.1%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,322\tacc: 59.9%\n",
      "* average: 89.6%\n",
      "epoch [13/30][100/500]\ttime 0.307 (0.297)\tdata 0.001 (0.003)\teta 0:44:00\tloss -0.9493 (-1.0325) loss_x 0.1153 (0.1515) loss_u 0.0513 (0.0336) acc_x 93.7500 (94.6562) acc_u 87.5000 (86.4062) gamma_v 0.0537 (0.0559) gamma_t 0.2243 (0.2247) loss_x_ind 0.0501 (0.0683) loss_im -2.2477 (-2.1472) loss_new 0.0007 (0.0006)\tlr 6.183221e-04\n",
      "epoch [13/30][200/500]\ttime 0.293 (0.302)\tdata 0.001 (0.002)\teta 0:44:14\tloss -0.8553 (-1.0064) loss_x 0.1416 (0.1539) loss_u 0.0450 (0.0352) acc_x 96.8750 (94.7500) acc_u 84.3750 (86.3125) gamma_v 0.0461 (0.0537) gamma_t 0.2229 (0.2248) loss_x_ind 0.0552 (0.0682) loss_im -2.0319 (-2.1396) loss_new 0.0027 (0.0010)\tlr 8.898950e-04\n",
      "epoch [13/30][300/500]\ttime 0.295 (0.303)\tdata 0.001 (0.001)\teta 0:43:52\tloss -1.0038 (-1.0258) loss_x 0.0738 (0.1508) loss_u 0.0208 (0.0340) acc_x 96.8750 (94.8438) acc_u 87.5000 (86.5312) gamma_v 0.0540 (0.0536) gamma_t 0.2234 (0.2255) loss_x_ind 0.0258 (0.0655) loss_im -2.1482 (-2.1401) loss_new 0.0006 (0.0009)\tlr 2.991783e-03\n",
      "epoch [13/30][400/500]\ttime 0.289 (0.300)\tdata 0.000 (0.001)\teta 0:42:58\tloss -0.7216 (-1.0170) loss_x 0.1100 (0.1516) loss_u 0.0548 (0.0342) acc_x 96.8750 (94.6328) acc_u 78.1250 (86.3750) gamma_v 0.0580 (0.0538) gamma_t 0.2215 (0.2253) loss_x_ind 0.0276 (0.0674) loss_im -2.0579 (-2.1413) loss_new 0.0005 (0.0009)\tlr 6.183221e-04\n",
      "epoch [13/30][500/500]\ttime 0.301 (0.300)\tdata 0.001 (0.001)\teta 0:42:28\tloss -0.8078 (-1.0088) loss_x 0.3531 (0.1536) loss_u 0.0159 (0.0355) acc_x 87.5000 (94.4688) acc_u 96.8750 (86.5062) gamma_v 0.0560 (0.0541) gamma_t 0.2302 (0.2272) loss_x_ind 0.0819 (0.0668) loss_im -2.0489 (-2.1421) loss_new 0.0014 (0.0009)\tlr 8.898950e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,369\n",
      "* accuracy: 87.3%\n",
      "* error: 12.7%\n",
      "* macro_f1: 88.0%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,605\tacc: 98.9%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,255\tacc: 93.7%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,336\tacc: 92.5%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,928\tacc: 76.2%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,638\tacc: 98.9%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,989\tacc: 95.9%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,488\tacc: 94.7%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,063\tacc: 76.6%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,200\tacc: 92.3%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,178\tacc: 95.5%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,026\tacc: 95.0%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,663\tacc: 66.0%\n",
      "* average: 89.7%\n",
      "epoch [14/30][100/500]\ttime 0.256 (0.293)\tdata 0.001 (0.003)\teta 0:40:59\tloss -1.1043 (-0.9981) loss_x 0.0881 (0.1568) loss_u 0.0284 (0.0349) acc_x 93.7500 (94.3125) acc_u 87.5000 (87.5000) gamma_v 0.0573 (0.0549) gamma_t 0.2374 (0.2370) loss_x_ind 0.0346 (0.0689) loss_im -2.1610 (-2.1568) loss_new 0.0004 (0.0009)\tlr 2.991783e-03\n",
      "epoch [14/30][200/500]\ttime 0.294 (0.293)\tdata 0.001 (0.002)\teta 0:40:32\tloss -1.0642 (-0.9784) loss_x 0.1926 (0.1552) loss_u 0.0243 (0.0352) acc_x 90.6250 (94.3281) acc_u 84.3750 (86.7500) gamma_v 0.0572 (0.0557) gamma_t 0.2380 (0.2369) loss_x_ind 0.0279 (0.0710) loss_im -2.0045 (-2.1455) loss_new 0.0009 (0.0009)\tlr 6.183221e-04\n",
      "epoch [14/30][300/500]\ttime 0.360 (0.294)\tdata 0.001 (0.001)\teta 0:40:13\tloss -0.8693 (-0.9767) loss_x 0.1516 (0.1533) loss_u 0.0545 (0.0350) acc_x 96.8750 (94.3229) acc_u 81.2500 (86.6667) gamma_v 0.0564 (0.0562) gamma_t 0.2413 (0.2378) loss_x_ind 0.1013 (0.0698) loss_im -2.2243 (-2.1439) loss_new 0.0004 (0.0008)\tlr 8.898950e-04\n",
      "epoch [14/30][400/500]\ttime 0.272 (0.292)\tdata 0.000 (0.001)\teta 0:39:25\tloss -1.3365 (-0.9814) loss_x 0.0902 (0.1510) loss_u 0.0086 (0.0354) acc_x 96.8750 (94.4453) acc_u 81.2500 (86.5469) gamma_v 0.0559 (0.0568) gamma_t 0.2387 (0.2382) loss_x_ind 0.0682 (0.0667) loss_im -2.1556 (-2.1439) loss_new 0.0010 (0.0008)\tlr 2.991783e-03\n",
      "epoch [14/30][500/500]\ttime 0.304 (0.292)\tdata 0.000 (0.001)\teta 0:38:53\tloss -1.0000 (-0.9975) loss_x 0.1531 (0.1473) loss_u 0.0418 (0.0356) acc_x 93.7500 (94.5750) acc_u 84.3750 (86.4250) gamma_v 0.0588 (0.0573) gamma_t 0.2355 (0.2380) loss_x_ind 0.0589 (0.0655) loss_im -2.1681 (-2.1456) loss_new 0.0008 (0.0007)\tlr 6.183221e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,026\n",
      "* accuracy: 86.7%\n",
      "* error: 13.3%\n",
      "* macro_f1: 87.7%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,597\tacc: 98.7%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,220\tacc: 92.7%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,341\tacc: 92.6%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,572\tacc: 72.8%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,627\tacc: 98.6%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,958\tacc: 94.4%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,491\tacc: 94.7%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,348\tacc: 83.7%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,196\tacc: 92.2%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,167\tacc: 95.0%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,992\tacc: 94.2%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,517\tacc: 63.4%\n",
      "* average: 89.4%\n",
      "epoch [15/30][100/500]\ttime 0.276 (0.293)\tdata 0.001 (0.003)\teta 0:38:37\tloss -1.0191 (-1.0743) loss_x 0.3462 (0.1421) loss_u 0.0061 (0.0339) acc_x 90.6250 (95.0312) acc_u 87.5000 (85.3438) gamma_v 0.0541 (0.0611) gamma_t 0.2312 (0.2314) loss_x_ind 0.0788 (0.0611) loss_im -2.2548 (-2.1530) loss_new 0.0017 (0.0006)\tlr 8.898950e-04\n",
      "epoch [15/30][200/500]\ttime 0.277 (0.285)\tdata 0.000 (0.002)\teta 0:37:06\tloss -1.1915 (-1.0522) loss_x 0.1158 (0.1464) loss_u 0.0374 (0.0324) acc_x 93.7500 (94.6875) acc_u 90.6250 (86.3125) gamma_v 0.0560 (0.0592) gamma_t 0.2427 (0.2359) loss_x_ind 0.0710 (0.0651) loss_im -1.9549 (-2.1494) loss_new 0.0010 (0.0007)\tlr 2.991783e-03\n",
      "epoch [15/30][300/500]\ttime 0.279 (0.284)\tdata 0.001 (0.001)\teta 0:36:26\tloss -0.8508 (-1.0326) loss_x 0.1306 (0.1459) loss_u 0.0418 (0.0334) acc_x 93.7500 (94.6562) acc_u 87.5000 (86.4792) gamma_v 0.0673 (0.0596) gamma_t 0.2394 (0.2383) loss_x_ind 0.0349 (0.0664) loss_im -2.2667 (-2.1490) loss_new 0.0003 (0.0007)\tlr 6.183221e-04\n",
      "epoch [15/30][400/500]\ttime 0.277 (0.283)\tdata 0.000 (0.001)\teta 0:35:48\tloss -0.7806 (-1.0326) loss_x 0.2142 (0.1459) loss_u 0.0517 (0.0337) acc_x 87.5000 (94.6406) acc_u 87.5000 (86.5000) gamma_v 0.0576 (0.0604) gamma_t 0.2448 (0.2395) loss_x_ind 0.0623 (0.0644) loss_im -2.0594 (-2.1516) loss_new 0.0009 (0.0007)\tlr 8.898950e-04\n",
      "epoch [15/30][500/500]\ttime 0.280 (0.282)\tdata 0.000 (0.001)\teta 0:35:18\tloss -1.4514 (-1.0303) loss_x 0.0554 (0.1465) loss_u 0.0260 (0.0339) acc_x 96.8750 (94.6625) acc_u 93.7500 (86.3500) gamma_v 0.0551 (0.0602) gamma_t 0.2536 (0.2414) loss_x_ind 0.0481 (0.0623) loss_im -2.2117 (-2.1513) loss_new 0.0016 (0.0007)\tlr 2.991783e-03\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 47,730\n",
      "* accuracy: 86.2%\n",
      "* error: 13.8%\n",
      "* macro_f1: 86.8%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,603\tacc: 98.8%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,166\tacc: 91.1%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,410\tacc: 94.0%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,992\tacc: 76.8%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,619\tacc: 98.5%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,947\tacc: 93.8%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,512\tacc: 95.1%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,318\tacc: 83.0%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 3,986\tacc: 87.6%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,205\tacc: 96.7%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 3,916\tacc: 92.4%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,056\tacc: 55.1%\n",
      "* average: 88.6%\n",
      "epoch [16/30][100/500]\ttime 0.299 (0.296)\tdata 0.001 (0.003)\teta 0:36:32\tloss -1.1626 (-1.0319) loss_x 0.2532 (0.1424) loss_u 0.0275 (0.0343) acc_x 90.6250 (94.9375) acc_u 81.2500 (86.0312) gamma_v 0.0625 (0.0651) gamma_t 0.2517 (0.2496) loss_x_ind 0.0426 (0.0686) loss_im -2.2170 (-2.1557) loss_new 0.0005 (0.0005)\tlr 6.183221e-04\n",
      "epoch [16/30][200/500]\ttime 0.263 (0.295)\tdata 0.001 (0.002)\teta 0:35:54\tloss -0.7483 (-1.0445) loss_x 0.1850 (0.1396) loss_u 0.0548 (0.0330) acc_x 96.8750 (95.0000) acc_u 84.3750 (86.0156) gamma_v 0.0617 (0.0628) gamma_t 0.2528 (0.2510) loss_x_ind 0.0323 (0.0643) loss_im -2.1983 (-2.1548) loss_new 0.0010 (0.0006)\tlr 8.898950e-04\n",
      "epoch [16/30][300/500]\ttime 0.278 (0.289)\tdata 0.001 (0.001)\teta 0:34:40\tloss -0.5371 (-1.0289) loss_x 0.3456 (0.1389) loss_u 0.0244 (0.0332) acc_x 84.3750 (94.9479) acc_u 84.3750 (85.7708) gamma_v 0.0652 (0.0627) gamma_t 0.2546 (0.2520) loss_x_ind 0.0484 (0.0615) loss_im -1.9985 (-2.1514) loss_new 0.0005 (0.0007)\tlr 2.991783e-03\n",
      "epoch [16/30][400/500]\ttime 0.257 (0.286)\tdata 0.000 (0.001)\teta 0:33:53\tloss -0.8646 (-1.0241) loss_x 0.3102 (0.1395) loss_u 0.0830 (0.0332) acc_x 84.3750 (94.8438) acc_u 87.5000 (86.0703) gamma_v 0.0632 (0.0624) gamma_t 0.2596 (0.2539) loss_x_ind 0.0533 (0.0628) loss_im -2.1075 (-2.1488) loss_new 0.0004 (0.0007)\tlr 6.183221e-04\n",
      "epoch [16/30][500/500]\ttime 0.281 (0.286)\tdata 0.000 (0.001)\teta 0:33:21\tloss -0.4229 (-1.0313) loss_x 0.0926 (0.1385) loss_u 0.1285 (0.0335) acc_x 96.8750 (94.9125) acc_u 87.5000 (86.1125) gamma_v 0.0651 (0.0626) gamma_t 0.2504 (0.2550) loss_x_ind 0.0908 (0.0619) loss_im -2.0799 (-2.1493) loss_new 0.0005 (0.0006)\tlr 8.898950e-04\n",
      "Do evaluation on test set\n",
      "=> result\n",
      "* total: 55,388\n",
      "* correct: 48,036\n",
      "* accuracy: 86.7%\n",
      "* error: 13.3%\n",
      "* macro_f1: 87.6%\n",
      "=> per-class result\n",
      "* class: 0 (aeroplane)\ttotal: 3,646\tcorrect: 3,604\tacc: 98.8%\n",
      "* class: 1 (bicycle)\ttotal: 3,475\tcorrect: 3,197\tacc: 92.0%\n",
      "* class: 2 (bus)\ttotal: 4,690\tcorrect: 4,323\tacc: 92.2%\n",
      "* class: 3 (car)\ttotal: 10,401\tcorrect: 7,511\tacc: 72.2%\n",
      "* class: 4 (horse)\ttotal: 4,691\tcorrect: 4,630\tacc: 98.7%\n",
      "* class: 5 (knife)\ttotal: 2,075\tcorrect: 1,983\tacc: 95.6%\n",
      "* class: 6 (motorcycle)\ttotal: 5,796\tcorrect: 5,486\tacc: 94.7%\n",
      "* class: 7 (person)\ttotal: 4,000\tcorrect: 3,286\tacc: 82.2%\n",
      "* class: 8 (plant)\ttotal: 4,549\tcorrect: 4,143\tacc: 91.1%\n",
      "* class: 9 (skateboard)\ttotal: 2,281\tcorrect: 2,194\tacc: 96.2%\n",
      "* class: 10 (train)\ttotal: 4,236\tcorrect: 4,036\tacc: 95.3%\n",
      "* class: 11 (truck)\ttotal: 5,548\tcorrect: 3,643\tacc: 65.7%\n",
      "* average: 89.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [17/30][100/500]\ttime 0.277 (0.292)\tdata 0.000 (0.003)\teta 0:33:31\tloss -1.6337 (-1.1106) loss_x 0.0901 (0.1369) loss_u 0.0272 (0.0306) acc_x 100.0000 (94.7188) acc_u 93.7500 (87.1562) gamma_v 0.0713 (0.0653) gamma_t 0.2567 (0.2558) loss_x_ind 0.0494 (0.0561) loss_im -2.1664 (-2.1726) loss_new 0.0002 (0.0004)\tlr 2.991783e-03\n",
      "epoch [17/30][200/500]\ttime 0.277 (0.289)\tdata 0.000 (0.002)\teta 0:32:44\tloss -0.9630 (-1.0666) loss_x 0.0464 (0.1309) loss_u 0.0579 (0.0345) acc_x 96.8750 (94.9688) acc_u 87.5000 (87.0000) gamma_v 0.0584 (0.0649) gamma_t 0.2614 (0.2565) loss_x_ind 0.0600 (0.0593) loss_im -2.1118 (-2.1534) loss_new 0.0007 (0.0004)\tlr 6.183221e-04\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hbcho991/DAMP/DAMP/train.py\", line 229, in <module>\n",
      "    main(args)\n",
      "  File \"/home/hbcho991/DAMP/DAMP/train.py\", line 155, in main\n",
      "    trainer.train()\n",
      "  File \"/home/hbcho991/DAMP/DAMP/trainers/damp.py\", line 717, in train\n",
      "    self.run_epoch()\n",
      "  File \"/home/hbcho991/DAMP/DAMP/trainers/damp.py\", line 760, in run_epoch\n",
      "    loss_summary = self.forward_backward(batch_x, batch_u)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hbcho991/DAMP/DAMP/trainers/damp.py\", line 855, in forward_backward\n",
      "    self.scaler.scale(loss).backward()\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/hbcho991/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 768, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!sh VisDA17.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44742c30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5417919a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af262272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b462d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2764da1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c91852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstvenv",
   "language": "python",
   "name": "firstvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
